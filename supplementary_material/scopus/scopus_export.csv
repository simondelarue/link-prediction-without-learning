Index,Authors,Author full names,Author(s) ID,Title,Year,Source title,Volume,Issue,Art. No.,Page start,Page end,Page count,Cited by,DOI,Link,Affiliations,Authors with affiliations,Abstract,Author Keywords,Index Keywords,Document Type,Publication Stage,Open Access,Source,EID
2,Zhang M.; Chen Y.,"Zhang, Muhan (57191868624); Chen, Yixin (57196271259)",57191868624; 57196271259,Link prediction based on graph neural networks,2018,Advances in Neural Information Processing Systems,2018-December,,,5165,5175,10,944,,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85064835122&partnerID=40&md5=e49d0d63acd21faf4b87d7d2be89b383,"Department of CSE, Washington University, St. Louis, United States","Zhang M., Department of CSE, Washington University, St. Louis, United States; Chen Y., Department of CSE, Washington University, St. Louis, United States","Link prediction is a key problem for network-structured data. Link prediction heuristics use some score functions, such as common neighbors and Katz index, to measure the likelihood of links. They have obtained wide practical uses due to their simplicity, interpretability, and for some of them, scalability. However, every heuristic has a strong assumption on when two nodes are likely to link, which limits their effectiveness on networks where these assumptions fail. In this regard, a more reasonable way should be learning a suitable heuristic from a given network instead of using predefined ones. By extracting a local subgraph around each target link, we aim to learn a function mapping the subgraph patterns to link existence, thus automatically learning a “heuristic” that suits the current network. In this paper, we study this heuristic learning paradigm for link prediction. First, we develop a novel -decaying heuristic theory. The theory unifies a wide range of heuristics in a single framework, and proves that all these heuristics can be well approximated from local subgraphs. Our results show that local subgraphs reserve rich information related to link existence. Second, based on the -decaying theory, we propose a new method to learn heuristics from local subgraphs using a graph neural network (GNN). Its experimental results show unprecedented performance, working consistently well on a wide range of problems. © 2018 Curran Associates Inc..All rights reserved.",,Forecasting; Heuristic methods; Function mapping; Graph neural networks; Heuristic learning; Interpretability; Link prediction; Practical use; Score function; Structured data; Graph theory,Conference paper,Final,,Scopus,2-s2.0-85064835122
3,Zhang C.; Song D.; Huang C.; Swami A.; Chawla N.V.,"Zhang, Chuxu (55879440900); Song, Dongjin (7402443773); Huang, Chao (57051644000); Swami, Ananthram (7006645443); Chawla, Nitesh V. (35077581400)",55879440900; 7402443773; 57051644000; 7006645443; 35077581400,Heterogeneous graph neural network,2019,Proceedings of the ACM SIGKDD International Conference on Knowledge Discovery and Data Mining,,,,793,803,10,835,10.1145/3292500.3330961,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85071146536&doi=10.1145%2f3292500.3330961&partnerID=40&md5=71c2a96c0a705b9f7c2fd025f2e67bcc,"University of Notre Dame; NEC Laboratories America, Inc; University of Notre Dame, JD Digits; US Army Research Laboratory","Zhang C., University of Notre Dame; Song D., NEC Laboratories America, Inc; Huang C., University of Notre Dame, JD Digits; Swami A., US Army Research Laboratory; Chawla N.V., University of Notre Dame","Representation learning in heterogeneous graphs aims to pursue a meaningful vector representation for each node so as to facilitate downstream applications such as link prediction, personalized recommendation, node classification, etc. This task, however, is challenging not only because of the demand to incorporate heterogeneous structural (graph) information consisting of multiple types of nodes and edges, but also due to the need for considering heterogeneous attributes or contents (e.?., text or image) associated with each node. Despite a substantial amount of effort has been made to homogeneous (or heterogeneous) graph embedding, attributed graph embedding as well as graph neural networks, few of them can jointly consider heterogeneous structural (graph) information as well as heterogeneous contents information of each node effectively. In this paper, we propose HetGNN, a heterogeneous graph neural network model, to resolve this issue. Specifically, we first introduce a random walk with restart strategy to sample a fixed size of strongly correlated heterogeneous neighbors for each node and group them based upon node types. Next, we design a neural network architecture with two modules to aggregate feature information of those sampled neighboring nodes. The first module encodes “deep” feature interactions of heterogeneous contents and generates content embedding for each node. The second module aggregates content (attribute) embeddings of different neighboring groups (types) and further combines them by considering the impacts of different groups to obtain the ultimate node embedding. Finally, we leverage a graph context loss and a mini-batch gradient descent procedure to train the model in an end-to-end manner. Extensive experiments on several datasets demonstrate that HetGNN can outperform state-of-the-art baselines in various graph mining tasks, i.e., link prediction, recommendation, node classification & clustering and inductive node classification & clustering. © 2019 Copyright held by the owner/author(s).",Graph embedding; Graph neural networks; Heterogeneous graphs,Aggregates; Classification (of information); Data mining; Embeddings; Gradient methods; Network architecture; Text processing; Downstream applications; Graph embeddings; Graph neural networks; Heterogeneous attributes; Heterogeneous graph; Personalized recommendation; Random walk with restart; Vector representations; Graph theory,Conference paper,Final,All Open Access; Bronze Open Access,Scopus,2-s2.0-85071146536
4,Ying R.; Morris C.; Hamilton W.L.; You J.; Ren X.; Leskovec J.,"Ying, Rex (57190049577); Morris, Christopher (58952450300); Hamilton, William L. (56096744700); You, Jiaxuan (57195955464); Ren, Xiang (58619993600); Leskovec, Jure (12241436100)",57190049577; 58952450300; 56096744700; 57195955464; 58619993600; 12241436100,Hierarchical graph representation learning with differentiable pooling,2018,Advances in Neural Information Processing Systems,2018-December,,,4800,4810,10,524,,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85064829198&partnerID=40&md5=d6dbacc228ddb9bcbb002d51bfaec475,"Stanford University, United States; TU Dortmund University, Germany; University of Southern California, United States","Ying R., Stanford University, United States; Morris C., TU Dortmund University, Germany; Hamilton W.L., Stanford University, United States; You J., Stanford University, United States; Ren X., University of Southern California, United States; Leskovec J., Stanford University, United States","Recently, graph neural networks (GNNs) have revolutionized the field of graph representation learning through effectively learned node embeddings, and achieved state-of-the-art results in tasks such as node classification and link prediction. However, current GNN methods are inherently flat and do not learn hierarchical representations of graphs-a limitation that is especially problematic for the task of graph classification, where the goal is to predict the label associated with an entire graph. Here we propose DIFFPOOL, a differentiable graph pooling module that can generate hierarchical representations of graphs and can be combined with various graph neural network architectures in an end-to-end fashion. DIFFPOOL learns a differentiable soft cluster assignment for nodes at each layer of a deep GNN, mapping nodes to a set of clusters, which then form the coarsened input for the next GNN layer. Our experimental results show that combining existing GNN methods with DIFFPOOL yields an average improvement of 5-10% accuracy on graph classification benchmarks, compared to all existing pooling approaches, achieving a new state-of-the-art on four out of five benchmark data sets. © 2018 Curran Associates Inc..All rights reserved.",,Classification (of information); Network architecture; Neural networks; Cluster assignment; Graph classification; Graph neural networks; Graph representation; Hierarchical graph representations; Hierarchical representation; Link prediction; State of the art; Graph theory,Conference paper,Final,,Scopus,2-s2.0-85064829198
5,Pareja A.; Domeniconi G.; Chen J.; Ma T.; Suzumura T.; Kanezashi H.; Kaler T.; Schardl T.B.; Leiserson C.E.,"Pareja, Aldo (57219480757); Domeniconi, Giacomo (56411905800); Chen, Jie (39761122000); Ma, Tengfei (57194786822); Suzumura, Toyotaro (6603022117); Kanezashi, Hiroki (55314505100); Kaler, Tim (36816123400); Schardl, Tao B. (36185999400); Leiserson, Charles E. (7004322864)",57219480757; 56411905800; 39761122000; 57194786822; 6603022117; 55314505100; 36816123400; 36185999400; 7004322864,EvolveGCN: Evolving graph convolutional networks for dynamic graphs,2020,AAAI 2020 - 34th AAAI Conference on Artificial Intelligence,,,,5363,5370,7,492,,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85106588865&partnerID=40&md5=a2e34e65506d62540a9fd11166d12463,MIT-IBM Watson AI Lab.; IBM Research; MIT CSAIL,"Pareja A., MIT-IBM Watson AI Lab., IBM Research; Domeniconi G., MIT-IBM Watson AI Lab., IBM Research; Chen J., MIT-IBM Watson AI Lab., IBM Research; Ma T., MIT-IBM Watson AI Lab., IBM Research; Suzumura T., MIT-IBM Watson AI Lab., IBM Research; Kanezashi H., MIT-IBM Watson AI Lab., IBM Research; Kaler T., MIT-IBM Watson AI Lab., MIT CSAIL; Schardl T.B., MIT-IBM Watson AI Lab., MIT CSAIL; Leiserson C.E., MIT-IBM Watson AI Lab., MIT CSAIL","Graph representation learning resurges as a trending research subject owing to the widespread use of deep learning for Euclidean data, which inspire various creative designs of neural networks in the non-Euclidean domain, particularly graphs. With the success of these graph neural networks (GNN) in the static setting, we approach further practical scenarios where the graph dynamically evolves. Existing approaches typically resort to node embeddings and use a recurrent neural network (RNN, broadly speaking) to regulate the embeddings and learn the temporal dynamics. These methods require the knowledge of a node in the full time span (including both training and testing) and are less applicable to the frequent change of the node set. In some extreme scenarios, the node sets at different time steps may completely differ. To resolve this challenge, we propose EvolveGCN, which adapts the graph convolutional network (GCN) model along the temporal dimension without resorting to node embeddings. The proposed approach captures the dynamism of the graph sequence through using an RNN to evolve the GCN parameters. Two architectures are considered for the parameter evolution. We evaluate the proposed approach on tasks including link prediction, edge classification, and node classification. The experimental results indicate a generally higher performance of EvolveGCN compared with related approaches. The code is available at https://github.com/IBM/EvolveGCN. Copyright © 2020, Association for the Advancement of Artificial Intelligence (www.aaai.org). All rights reserved.",,Convolution; Convolutional neural networks; Embeddings; Convolutional networks; Different time steps; Edge classification; Graph neural networks; Graph representation; Parameter evolution; Temporal dimensions; Training and testing; Recurrent neural networks,Conference paper,Final,,Scopus,2-s2.0-85106588865
6,Fu X.; Zhang J.; Meng Z.; King I.,"Fu, Xinyu (57217166179); Zhang, Jiani (57191754383); Meng, Ziqiao (57217164272); King, Irwin (7102275781)",57217166179; 57191754383; 57217164272; 7102275781,MAGNN: Metapath Aggregated Graph Neural Network for Heterogeneous Graph Embedding,2020,"The Web Conference 2020 - Proceedings of the World Wide Web Conference, WWW 2020",,,,2331,2341,10,472,10.1145/3366423.3380297,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85086564192&doi=10.1145%2f3366423.3380297&partnerID=40&md5=c818e1dd3ee20bfc390cdc9798620835,"Chinese University of Hong Kong, Hong Kong, Hong Kong","Fu X., Chinese University of Hong Kong, Hong Kong, Hong Kong; Zhang J., Chinese University of Hong Kong, Hong Kong, Hong Kong; Meng Z., Chinese University of Hong Kong, Hong Kong, Hong Kong; King I., Chinese University of Hong Kong, Hong Kong, Hong Kong","A large number of real-world graphs or networks are inherently heterogeneous, involving a diversity of node types and relation types. Heterogeneous graph embedding is to embed rich structural and semantic information of a heterogeneous graph into low-dimensional node representations. Existing models usually define multiple metapaths in a heterogeneous graph to capture the composite relations and guide neighbor selection. However, these models either omit node content features, discard intermediate nodes along the metapath, or only consider one metapath. To address these three limitations, we propose a new model named Metapath Aggregated Graph Neural Network (MAGNN) to boost the final performance. Specifically, MAGNN employs three major components, i.e., the node content transformation to encapsulate input node attributes, the intra-metapath aggregation to incorporate intermediate semantic nodes, and the inter-metapath aggregation to combine messages from multiple metapaths. Extensive experiments on three real-world heterogeneous graph datasets for node classification, node clustering, and link prediction show that MAGNN achieves more accurate prediction results than state-of-the-art baselines. © 2020 ACM.",Graph embedding; Graph neural network; Heterogeneous graph,Aggregates; Classification (of information); Embeddings; Graph structures; Semantics; World Wide Web; Accurate prediction; Graph neural networks; Heterogeneous graph; Intermediate node; Neighbor selection; Real-world graphs; Semantic information; State of the art; Graph theory,Conference paper,Final,All Open Access; Green Open Access,Scopus,2-s2.0-85086564192
7,Yun S.; Jeong M.; Kim R.; Kang J.; Kim H.J.,"Yun, Seongjun (57215719303); Jeong, Minbyul (57209640341); Kim, Raehyun (57202116370); Kang, Jaewoo (8914056400); Kim, Hyunwoo J. (56336378000)",57215719303; 57209640341; 57202116370; 8914056400; 56336378000,Graph transformer networks,2019,Advances in Neural Information Processing Systems,32,,,,,,462,,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85086569906&partnerID=40&md5=60b25030af844b5f67e06fe0445c4572,"Department of Computer Science and Engineering, Korea University, South Korea","Yun S., Department of Computer Science and Engineering, Korea University, South Korea; Jeong M., Department of Computer Science and Engineering, Korea University, South Korea; Kim R., Department of Computer Science and Engineering, Korea University, South Korea; Kang J., Department of Computer Science and Engineering, Korea University, South Korea; Kim H.J., Department of Computer Science and Engineering, Korea University, South Korea","Graph neural networks (GNNs) have been widely used in representation learning on graphs and achieved state-of-the-art performance in tasks such as node classification and link prediction. However, most existing GNNs are designed to learn node representations on the fixed and homogeneous graphs. The limitations especially become problematic when learning representations on a misspecified graph or a heterogeneous graph that consists of various types of nodes and edges. In this paper, we propose Graph Transformer Networks (GTNs) that are capable of generating new graph structures, which involve identifying useful connections between unconnected nodes on the original graph, while learning effective node representation on the new graphs in an end-to-end fashion. Graph Transformer layer, a core layer of GTNs, learns a soft selection of edge types and composite relations for generating useful multi-hop connections so-called meta-paths. Our experiments show that GTNs learn new graph structures, based on data and tasks without domain knowledge, and yield powerful node representation via convolution on the new graphs. Without domain-specific graph preprocessing, GTNs achieved the best performance in all three benchmark node classification tasks against the state-of-the-art methods that require pre-defined meta-paths from domain knowledge. © 2019 Neural information processing systems foundation. All rights reserved.",,Benchmarking; Graph theory; Graphic methods; Neural networks; Classification tasks; Domain knowledge; Graph neural networks; Heterogeneous graph; Link prediction; Multi-hop connections; State-of-the-art methods; State-of-the-art performance; Graph structures,Conference paper,Final,,Scopus,2-s2.0-85086569906
8,Ma Y.; Aggarwal C.C.; Wang S.; Tang J.,"Ma, Yao (57201255717); Aggarwal, Charu C. (7006797289); Wang, Suhang (57001918800); Tang, Jiliang (56245477300)",57201255717; 7006797289; 57001918800; 56245477300,Graph convolutional networks with eigenpooling,2019,Proceedings of the ACM SIGKDD International Conference on Knowledge Discovery and Data Mining,,,,723,731,8,197,10.1145/3292500.3330982,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85071181745&doi=10.1145%2f3292500.3330982&partnerID=40&md5=b43e08b015c793191ffb63b916a6e96f,"Michigan State University; IBM T. J. Watson Research Center; Pennsylvania State University, United States","Ma Y., Michigan State University; Aggarwal C.C., IBM T. J. Watson Research Center; Wang S., Pennsylvania State University, United States; Tang J., Michigan State University","Graph neural networks, which generalize deep neural network models to graph structured data, have attracted increasing attention in recent years. They usually learn node representations by transforming, propagating and aggregating node features and have been proven to improve the performance of many graph related tasks such as node classification and link prediction. To apply graph neural networks for the graph classification task, approaches to generate the graph representation from node representations are demanded. A common way is to globally combine the node representations. However, rich structural information is overlooked. Thus a hierarchical pooling procedure is desired to preserve the graph structure during the graph representation learning. There are some recent works on hierarchically learning graph representation analogous to the pooling step in conventional convolutional neural (CNN) networks. However, the local structural information is still largely neglected during the pooling process. In this paper, we introduce a pooling operator EigenPooling based on graph Fourier transform, which can utilize the node features and local structures during the pooling process. We then design pooling layers based on the pooling operator, which are further combined with traditional GCN convolutional layers to form a graph neural network framework EigenGCN for graph classification. Theoretical analysis is provided to understand EigenPooling from both local and global perspectives. Experimental results of the graph classification task on 6 commonly used benchmarks demonstrate the effectiveness of the proposed framework. © 2019 Association for Computing Machinery.",,Convolution; Data mining; Deep neural networks; Graphic methods; Multilayer neural networks; Convolutional networks; Graph classification; Graph Fourier transforms; Graph neural networks; Graph representation; Graph structured data; Neural network model; Structural information; Graph theory,Conference paper,Final,All Open Access; Bronze Open Access; Green Open Access,Scopus,2-s2.0-85071181745
9,Li Z.; Liu H.; Zhang Z.; Liu T.; Xiong N.N.,"Li, Zhifei (57211530031); Liu, Hai (57224917932); Zhang, Zhaoli (56450890000); Liu, Tingting (56558943300); Xiong, Neal N. (35231569200)",57211530031; 57224917932; 56450890000; 56558943300; 35231569200,Learning Knowledge Graph Embedding With Heterogeneous Relation Attention Networks,2022,IEEE Transactions on Neural Networks and Learning Systems,33,8,,3961,3973,12,165,10.1109/TNNLS.2021.3055147,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85100254379&doi=10.1109%2fTNNLS.2021.3055147&partnerID=40&md5=315682ed07741b96dc15d2730bd3dbed,"Central China Normal University, National Engineering Research Center for E-Learning, Wuhan, 430079, China; Hubei University, School of Education, Wuhan, 430062, China; Central China Normal University, National Engineering Laboratory for Educational Big Data, Wuhan, 430079, China; Northeastern State University, Department of Mathematics and Computer Science, Tahlequah, 74464, OK, United States","Li Z., Central China Normal University, National Engineering Research Center for E-Learning, Wuhan, 430079, China; Liu H., Central China Normal University, National Engineering Research Center for E-Learning, Wuhan, 430079, China; Zhang Z., Central China Normal University, National Engineering Research Center for E-Learning, Wuhan, 430079, China; Liu T., Hubei University, School of Education, Wuhan, 430062, China; Xiong N.N., Central China Normal University, National Engineering Laboratory for Educational Big Data, Wuhan, 430079, China, Northeastern State University, Department of Mathematics and Computer Science, Tahlequah, 74464, OK, United States","Knowledge graph (KG) embedding aims to study the embedding representation to retain the inherent structure of KGs. Graph neural networks (GNNs), as an effective graph representation technique, have shown impressive performance in learning graph embedding. However, KGs have an intrinsic property of heterogeneity, which contains various types of entities and relations. How to address complex graph data and aggregate multiple types of semantic information simultaneously is a critical issue. In this article, a novel heterogeneous GNNs framework based on attention mechanism is proposed. Specifically, the neighbor features of an entity are first aggregated under each relation-path. Then the importance of different relation-paths is learned through the relation features. Finally, each relation-path-based features with the learned weight values are aggregated to generate the embedding representation. Thus, the proposed method not only aggregates entity features from different semantic aspects but also allocates appropriate weights to them. This method can capture various types of semantic information and selectively aggregate informative features. The experiment results on three real-world KGs demonstrate superior performance when compared with several state-of-the-art methods. © 2012 IEEE.",Graph heterogeneity; graph neural networks (GNNs); KGs; knowledge graph (KG) embedding; link prediction,Aggregates; Knowledge representation; Semantics; Attention mechanisms; Critical issues; Graph neural networks; Graph representation; Intrinsic property; Knowledge graphs; Semantic information; State-of-the-art methods; article; attention network; embedding; learning; Embeddings,Article,Final,,Scopus,2-s2.0-85100254379
10,Ranjan E.; Sanyal S.; Talukdar P.,"Ranjan, Ekagra (57219590065); Sanyal, Soumya (57219586798); Talukdar, Partha (25652280700)",57219590065; 57219586798; 25652280700,ASAP: Adaptive structure aware pooling for learning hierarchical graph representations,2020,AAAI 2020 - 34th AAAI Conference on Artificial Intelligence,,,,5470,5477,7,151,,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85094803028&partnerID=40&md5=b65efa89f2898bba3998e03c738c3639,"Indian Institute of Technology, Guwahati, India; Indian Institute of Science, Bangalore, India","Ranjan E., Indian Institute of Technology, Guwahati, India; Sanyal S., Indian Institute of Science, Bangalore, India; Talukdar P., Indian Institute of Science, Bangalore, India","Graph Neural Networks (GNN) have been shown to work effectively for modeling graph structured data to solve tasks such as node classification, link prediction and graph classification. There has been some recent progress in defining the notion of pooling in graphs whereby the model tries to generate a graph level representation by downsampling and summarizing the information present in the nodes. Existing pooling methods either fail to effectively capture the graph substructure or do not easily scale to large graphs. In this work, we propose ASAP (Adaptive Structure Aware Pooling), a sparse and differentiable pooling method that addresses the limitations of previous graph pooling architectures. ASAP utilizes a novel self-attention network along with a modified GNN formulation to capture the importance of each node in a given graph. It also learns a sparse soft cluster assignment for nodes at each layer to effectively pool the subgraphs to form the pooled graph. Through extensive experiments on multiple datasets and theoretical analysis, we motivate our choice of the components used in ASAP. Our experimental results show that combining existing GNN architectures with ASAP leads to state-of-the-art results on multiple graph classification benchmarks. ASAP has an average improvement of 4%, compared to current sparse hierarchical state-of-the-art method. We make the source code of ASAP available to encourage reproducible research 1 Copyright © 2020, Association for the Advancement of Artificial Intelligence (www.aaai.org). All rights reserved.",,Graph theory; Network architecture; Neural networks; Adaptive structure; Cluster assignment; Graph classification; Graph neural networks; Graph structured data; Hierarchical graph representations; Hierarchical state; Reproducible research; Graph structures,Conference paper,Final,,Scopus,2-s2.0-85094803028
11,Luo D.; Cheng W.; Yu W.; Zong B.; Ni J.; Chen H.; Zhang X.,"Luo, Dongsheng (57202790937); Cheng, Wei (57218967449); Yu, Wenchao (57188803893); Zong, Bo (57203221691); Ni, Jingchao (56355100200); Chen, Haifeng (35241923100); Zhang, Xiang (55264772100)",57202790937; 57218967449; 57188803893; 57203221691; 56355100200; 35241923100; 55264772100,Learning to Drop: Robust Graph Neural Network via Topological Denoising,2021,WSDM 2021 - Proceedings of the 14th ACM International Conference on Web Search and Data Mining,,,,779,787,8,115,10.1145/3437963.3441734,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85102667185&doi=10.1145%2f3437963.3441734&partnerID=40&md5=36c56c0eef9169275a20470753890008,"Pennsylvania State University, United States; NEC Laboratories America","Luo D., Pennsylvania State University, United States; Cheng W., NEC Laboratories America; Yu W., NEC Laboratories America; Zong B., NEC Laboratories America; Ni J., NEC Laboratories America; Chen H., NEC Laboratories America; Zhang X., Pennsylvania State University, United States","Graph Neural Networks (GNNs) have shown to be powerful tools for graph analytics. The key idea is to recursively propagate and aggregate information along the edges of the given graph. Despite their success, however, the existing GNNs are usually sensitive to the quality of the input graph. Real-world graphs are often noisy and contain task-irrelevant edges, which may lead to suboptimal generalization performance in the learned GNN models. In this paper, we propose PTDNet, a parameterized topological denoising network, to improve the robustness and generalization performance of GNNs by learning to drop task-irrelevant edges. PTDNet prunes task-irrelevant edges by penalizing the number of edges in the sparsified graph with parameterized networks. To take into consideration the topology of the entire graph, the nuclear norm regularization is applied to impose the low-rank constraint on the resulting sparsified graph for better generalization. PTDNet can be used as a key component in GNN models to improve their performances on various tasks, such as node classification and link prediction. Experimental studies on both synthetic and benchmark datasets show that PTDNet can improve the performance of GNNs significantly and the performance gain becomes larger for more noisy datasets. © 2021 ACM.",deep learning; graph analysis; graph neural networks,Benchmarking; Data mining; Drops; Information retrieval; Neural networks; Websites; Benchmark datasets; Generalization performance; Graph neural networks; Link prediction; Nuclear norm regularizations; Performance Gain; Rank constraints; Real-world graphs; Topology,Conference paper,Final,All Open Access; Green Open Access,Scopus,2-s2.0-85102667185
12,Ma Y.; Guo Z.; Ren Z.; Tang J.; Yin D.,"Ma, Yao (57201255717); Guo, Ziyi (57218707976); Ren, Zhaocun (53985046100); Tang, Jiliang (56245477300); Yin, Dawei (35759826200)",57201255717; 57218707976; 53985046100; 56245477300; 35759826200,Streaming Graph Neural Networks,2020,SIGIR 2020 - Proceedings of the 43rd International ACM SIGIR Conference on Research and Development in Information Retrieval,,,,719,728,9,114,10.1145/3397271.3401092,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85090161208&doi=10.1145%2f3397271.3401092&partnerID=40&md5=438b599627b667a4b808b4b1b05b74e5,"Michigan State University, East Lansing, United States; JD.com, Beijing, China; Shangdong University, Qingdao, China; Baidu, Beijing, China","Ma Y., Michigan State University, East Lansing, United States; Guo Z., JD.com, Beijing, China; Ren Z., Shangdong University, Qingdao, China; Tang J., Michigan State University, East Lansing, United States; Yin D., Baidu, Beijing, China","Graphs are used to model pairwise relations between entities in many real-world scenarios such as social networks. Graph Neural Networks(GNNs) have shown their superior ability in learning representations for graph structured data, which leads to performance improvements in many graph related tasks such as link prediction, node classification and graph classification. Most of the existing graph neural networks models are designed for static graphs while many real-world graphs are inherently dynamic with new nodes and edges constantly emerging. Existing graph neural network models cannot utilize the dynamic information, which has been shown to enhance the performance of many graph analytic tasks such as community detection. Hence, in this paper, we propose DyGNN, a Dynamic Graph Neural Network model, which can model the dynamic information as the graph evolving. In particular, the proposed framework keeps updating node information by capturing the sequential information of edges (interactions), the time intervals between edges and information propagation coherently. Experimental results on various dynamic graphs demonstrate the effectiveness of the proposed framework. © 2020 ACM.",dynamic graphs; graph neural networks,Backpropagation; Graph structures; Graph theory; Graphic methods; Information dissemination; Information retrieval; Community detection; Dynamic information; Graph classification; Graph neural networks; Graph structured data; Information propagation; Real-world scenario; Sequential information; Neural networks,Conference paper,Final,All Open Access; Green Open Access,Scopus,2-s2.0-85090161208
13,Li P.; Wang Y.; Wang H.; Leskovec J.,"Li, Pan (55495089200); Wang, Yanbang (57221152146); Wang, Hongwei (57192964118); Leskovec, Jure (12241436100)",55495089200; 57221152146; 57192964118; 12241436100,Distance encoding: Design provably more powerful neural networks for graph representation learning,2020,Advances in Neural Information Processing Systems,2020-December,,,,,,107,,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85107901074&partnerID=40&md5=710d0b96dd1065ef91d8b9f097ca1ba0,"Department of Computer Science, Purdue University, United States; Department of Computer Science, Stanford University, United States","Li P., Department of Computer Science, Purdue University, United States; Wang Y., Department of Computer Science, Stanford University, United States; Wang H., Department of Computer Science, Stanford University, United States; Leskovec J., Department of Computer Science, Stanford University, United States","Learning representations of sets of nodes in a graph is crucial for applications ranging from node-role discovery to link prediction and molecule classification. Graph Neural Networks (GNNs) have achieved great success in graph representation learning. However, expressive power of GNNs is limited by the 1-Weisfeiler-Lehman (WL) test and thus GNNs generate identical representations for graph substructures that may in fact be very different. More powerful GNNs, proposed recently by mimicking higher-order-WL tests, only focus on representing entire graphs and they are computationally inefficient as they cannot utilize sparsity of the underlying graph. Here we propose and mathematically analyze a general class of structure-related features, termed Distance Encoding (DE). DE assists GNNs in representing any set of nodes, while providing strictly more expressive power than the 1-WL test. DE captures the distance between the node set whose representation is to be learned and each node in the graph. To capture the distance DE can apply various graph-distance measures such as shortest path distance or generalized PageRank scores. We propose two ways for GNNs to use DEs (1) as extra node features, and (2) as controllers of message aggregation in GNNs. Both approaches can utilize the sparse structure of the underlying graph, which leads to computational efficiency and scalability. We also prove that DE can distinguish node sets embedded in almost all regular graphs where traditional GNNs always fail. We evaluate DE on three tasks over six real networks: structural role prediction, link prediction, and triangle prediction. Results show that our models outperform GNNs without DE by up-to 15% in accuracy and AUROC. Furthermore, our models also significantly outperform other state-of-the-art methods especially designed for the above tasks. © 2020 Neural information processing systems foundation. All rights reserved.",,Computational efficiency; Encoding (symbols); Forecasting; Graph algorithms; Graph structures; Graph theory; Knowledge representation; Network coding; Expressive power; Graph neural networks; Graph representation; Link prediction; Message aggregation; State-of-the-art methods; Structure-related; Underlying graphs; Neural networks,Conference paper,Final,,Scopus,2-s2.0-85107901074
14,You J.; Ying R.; Leskovec J.,"You, Jiaxuan (57195955464); Ying, Rex (57190049577); Leskovec, Jure (12241436100)",57195955464; 57190049577; 12241436100,Position-aware graph neural networks,2019,"36th International Conference on Machine Learning, ICML 2019",2019-June,,,12372,12381,9,103,,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85078281873&partnerID=40&md5=f5b1ef5ccb8ba006495ab180bc55b232,"Department of Computer Science, Stanford University, Stanford, CA, United States","You J., Department of Computer Science, Stanford University, Stanford, CA, United States; Ying R., Department of Computer Science, Stanford University, Stanford, CA, United States; Leskovec J., Department of Computer Science, Stanford University, Stanford, CA, United States","Learning node embeddings that capture a node's position within the broader graph structure is crucial for many prediction tasks on graphs. However, existing Graph Neural Network (GNN) architectures have limited power in capturing the position/location of a given node with respect to all other nodes of the graph. Here we propose Position-aware Graph Neural Networks (P-GNNs), a new class of GNNs for computing position-aware node embeddings. P-GNN first samples sets of anchor nodes, computes the distance of a given target node to each anchor-set, and then learns a non-linear distance-weighted aggregation scheme over the anchor-sets. This way P-GNNs can capture positions/locations of nodes with respect to the anchor nodes. P-GNNs have several advantages: they are inductive, scalable, and can incorporate node feature information. We apply P-GNNs to multiple prediction tasks including link prediction and community detection. We show that P-GNNs consistently outperform state of the art GNNs, with up to 66% improvement in terms of the ROC AUC score. Copyright © 2019 ASME",,Embeddings; Forecasting; Machine learning; Aggregation schemes; Community detection; Feature information; Graph neural networks; Graph structures; Link prediction; Prediction tasks; State of the art; Graph theory,Conference paper,Final,,Scopus,2-s2.0-85078281873
15,Yin R.; Li K.; Zhang G.; Lu J.,"Yin, Ruiping (57613961200); Li, Kan (8711010900); Zhang, Guangquan (7405270696); Lu, Jie (7601559842)",57613961200; 8711010900; 7405270696; 7601559842,A deeper graph neural network for recommender systems,2019,Knowledge-Based Systems,185,,105020,,,,88,10.1016/j.knosys.2019.105020,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85071863524&doi=10.1016%2fj.knosys.2019.105020&partnerID=40&md5=71cedecde3d0094ab1318cc67732b846,"School of Computer Science and Technology, Beijing Institute of Technology, Beijing, China; Centre for Artificial Intelligence, University of Technology Sydney, Sydney, Australia","Yin R., School of Computer Science and Technology, Beijing Institute of Technology, Beijing, China, Centre for Artificial Intelligence, University of Technology Sydney, Sydney, Australia; Li K., School of Computer Science and Technology, Beijing Institute of Technology, Beijing, China; Zhang G., Centre for Artificial Intelligence, University of Technology Sydney, Sydney, Australia; Lu J., Centre for Artificial Intelligence, University of Technology Sydney, Sydney, Australia","Interaction data in recommender systems are usually represented by a bipartite user–item graph whose edges represent interaction behavior between users and items. The data sparsity problem, which is common in recommender systems, is the result of insufficient interaction data in the link prediction on graphs. The data sparsity problem can be alleviated by extracting more interaction behavior from the bipartite graph, however, stacking multiple layers will lead to over-smoothing, in which case, all nodes will converge to the same value. To address this issue, we propose a deeper graph neural network in this paper that can predict links on a bipartite user–item graph using information propagation. An attention mechanism is introduced to our method to address the problem that variable size inputs for each node on a bipartite graph. Our experimental results demonstrate that our proposed method outperforms five baselines, suggesting that the interactions extracted help to alleviate the data sparsity problem and improve recommendation accuracy. © 2019 Elsevier B.V.",Collaborative filtering; Graph neural network; Recommender systems; Representation learning,Backpropagation; Collaborative filtering; Data mining; Information dissemination; Recommender systems; Attention mechanisms; Bipartite graphs; Data sparsity problems; Graph neural networks; Information propagation; Interaction behavior; Recommendation accuracy; Representation learning; Graph theory,Article,Final,,Scopus,2-s2.0-85071863524
16,Mao X.; Wang W.; Xu H.; Wu Y.; Lan M.,"Mao, Xin (57214939376); Wang, Wenting (57204639242); Xu, Huimin (57214935179); Wu, Yuanbin (56093353000); Lan, Man (7102783244)",57214939376; 57204639242; 57214935179; 56093353000; 7102783244,Relational Reflection Entity Alignment,2020,"International Conference on Information and Knowledge Management, Proceedings",,,,1095,1104,9,80,10.1145/3340531.3412001,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85095865843&doi=10.1145%2f3340531.3412001&partnerID=40&md5=51cef8b97cead71389af4de473f6561e,"East China Normal University, Shanghai, China; Alibaba Group, Singapore","Mao X., East China Normal University, Shanghai, China; Wang W., Alibaba Group, Singapore; Xu H., Alibaba Group, Singapore; Wu Y., Alibaba Group, Singapore; Lan M., East China Normal University, Shanghai, China","Entity alignment aims to identify equivalent entity pairs from different Knowledge Graphs (KGs), which is essential in integrating multi-source KGs. Recently, with the introduction of GNNs into entity alignment, the architectures of recent models have become more and more complicated. We even find two counter-intuitive phenomena within these methods: (1) The standard linear transformation in GNNs is not working well. (2) Many advanced KG embedding models designed for link prediction task perform poorly in entity alignment. In this paper, we abstract existing entity alignment methods into a unified framework, Shape-Builder & Alignment, which not only successfully explains the above phenomena but also derives two key criteria for an ideal transformation operation. Furthermore, we propose a novel GNNs-based method, Relational Reflection Entity Alignment (RREA). RREA leverages Relational Reflection Transformation to obtain relation specific embeddings for each entity in a more efficient way. The experimental results on real-world datasets show that our model significantly outperforms the state-of-the-art methods, exceeding by 5.8%-10.9% on Hits@1. © 2020 ACM.",entity alignment; graph neural networks; knowledge graph,Embeddings; Knowledge management; Knowledge representation; Linear transformations; Mathematical transformations; Alignment methods; Knowledge graphs; Link prediction; Multi-Sources; Real-world datasets; Reflection transformations; State-of-the-art methods; Unified framework; Alignment,Conference paper,Final,All Open Access; Green Open Access,Scopus,2-s2.0-85095865843
17,Zhao C.; Li C.; Fu C.,"Zhao, Cheng (57202512273); Li, Chenliang (48761579500); Fu, Cong (57204468052)",57202512273; 48761579500; 57204468052,Cross-domain recommendation via preference propagation graphnet,2019,"International Conference on Information and Knowledge Management, Proceedings",,,,2165,2168,3,75,10.1145/3357384.3358166,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85075450983&doi=10.1145%2f3357384.3358166&partnerID=40&md5=b89393373f5262f5e70e447201c6b849,"State Key Laboratory of Information Engineering in Surveying, Mapping and Remote Sensing, Wuhan University, Wuhan, China; School of Cyber Science and Engineering, Wuhan University, Wuhan, China; State Key Lab of CAD and CG, Zhejiang University, Hangzhou, China","Zhao C., State Key Laboratory of Information Engineering in Surveying, Mapping and Remote Sensing, Wuhan University, Wuhan, China; Li C., School of Cyber Science and Engineering, Wuhan University, Wuhan, China; Fu C., State Key Lab of CAD and CG, Zhejiang University, Hangzhou, China","Recommendation can be framed as a graph link prediction task naturally. The user-item interaction graph built within a single domain often suffers from high sparsity. Thus, there has been a surge of approaches to alleviate the sparsity issue via cross-domain mutual augmentation. The SOTA cross-domain recommendation algorithms all try to bridge the gap via knowledge transfer in the latent space. We find there are mainly three problems in their formulations: 1) their knowledge transfer is unaware of the cross-domain graph structure. 2) their framework cannot capture high-order information propagation on the graph. 3) their cross-domain transfer formulations are generally more complicated to be optimized than the unified methods. In this paper, we propose the Preference Propagation GraphNet (PPGN) to address the above problems. Specifically, we construct a Cross-Domain Preference Matrix (CDPM) to model the interactions of different domains as a whole. Through the propagation layer of PPGN, we try to capture how user preferences propagate in the graph. Consequently, a joint objective for different domains is defined, and we simplify the cross-domain recommendation into a unified multi-task model. Extensive experiments on two pairs of real-world datasets show PPGN outperforms the SOTA algorithms significantly. © 2019 Association for Computing Machinery.",Deep Learning; Graph Neural Network; Recommendation Systems,Deep learning; Deep neural networks; Information dissemination; Knowledge management; Recommender systems; Cross-domain recommendations; Different domains; Graph neural networks; Graph structures; Information propagation; Interaction graphs; Knowledge transfer; Real-world datasets; Backpropagation,Conference paper,Final,,Scopus,2-s2.0-85075450983
18,You J.; Gomes-Selman J.M.; Ying R.; Leskovec J.,"You, Jiaxuan (57195955464); Gomes-Selman, Jonathan M. (57202511941); Ying, Rex (57190049577); Leskovec, Jure (12241436100)",57195955464; 57202511941; 57190049577; 12241436100,Identity-aware Graph Neural Networks,2021,"35th AAAI Conference on Artificial Intelligence, AAAI 2021",12B,,,10737,10745,8,74,,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85109528762&partnerID=40&md5=3c3650071a74c3251a7c96ff1e97594f,"Department of Computer Science, Stanford University, United States","You J., Department of Computer Science, Stanford University, United States; Gomes-Selman J.M., Department of Computer Science, Stanford University, United States; Ying R., Department of Computer Science, Stanford University, United States; Leskovec J., Department of Computer Science, Stanford University, United States","Message passing Graph Neural Networks (GNNs) provide a powerful modeling framework for relational data. However, the expressive power of existing GNNs is upper-bounded by the 1-Weisfeiler-Lehman (1-WL) graph isomorphism test, which means GNNs that are not able to predict node clustering coefficients and shortest path distances, and cannot differentiate between different d-regular graphs. Here we develop a class of message passing GNNs, named Identity-aware Graph Neural Networks (ID-GNNs), with greater expressive power than the 1-WL test. ID-GNN offers a minimal but powerful solution to limitations of existing GNNs. ID-GNN extends existing GNN architectures by inductively considering nodes’ identities during message passing. To embed a given node, ID-GNN first extracts the ego network centered at the node, then conducts rounds of heterogeneous message passing, where different sets of parameters are applied to the center node than to other surrounding nodes in the ego network. We further propose a simplified but faster version of ID-GNN that injects node identity information as augmented node features. Altogether, both versions of ID-GNN represent general extensions of message passing GNNs, where experiments show that transforming existing GNNs to ID-GNNs yields on average 40% accuracy improvement on challenging node, edge, and graph property prediction tasks; 3% accuracy improvement on node and graph classification benchmarks; and 15% ROC AUC improvement on real-world link prediction tasks. Additionally, ID-GNNs demonstrate improved or comparable performance over other task-specific graph networks. Copyright © 2021, Association for the Advancement of Artificial Intelligence (www.aaai.org). All rights reserved.",,Forecasting; Graph theory; Message passing; Accuracy Improvement; Ego networks; Expressive power; Graph isomorphism; Graph neural networks; Message-passing; Modelling framework; Node clustering; Prediction tasks; Relational data; Graph neural networks,Conference paper,Final,,Scopus,2-s2.0-85109528762
19,Zhu Z.; Zhang Z.; Xhonneux L.-P.; Tang J.,"Zhu, Zhaocheng (57205202174); Zhang, Zuobai (57214940250); Xhonneux, Louis-Pascal (57219635763); Tang, Jian (55713998400)",57205202174; 57214940250; 57219635763; 55713998400,Neural Bellman-Ford Networks: A General Graph Neural Network Framework for Link Prediction,2021,Advances in Neural Information Processing Systems,35,,,29476,29490,14,72,,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85129042222&partnerID=40&md5=be136ec2ea7417bfede287b2272b1ea5,"Mila - Québec AI Institute, Canada; Université de Montréal, Canada; HEC Montréal, Canada; CIFAR AI Chair, Canada","Zhu Z., Mila - Québec AI Institute, Canada, Université de Montréal, Canada; Zhang Z., Mila - Québec AI Institute, Canada, Université de Montréal, Canada; Xhonneux L.-P., Mila - Québec AI Institute, Canada, Université de Montréal, Canada; Tang J., Mila - Québec AI Institute, Canada, HEC Montréal, Canada, CIFAR AI Chair, Canada","Link prediction is a very fundamental task on graphs. Inspired by traditional path-based methods, in this paper we propose a general and flexible representation learning framework based on paths for link prediction. Specifically, we define the representation of a pair of nodes as the generalized sum of all path representations between the nodes, with each path representation as the generalized product of the edge representations in the path. Motivated by the Bellman-Ford algorithm for solving the shortest path problem, we show that the proposed path formulation can be efficiently solved by the generalized Bellman-Ford algorithm. To further improve the capacity of the path formulation, we propose the Neural Bellman-Ford Network (NBFNet), a general graph neural network framework that solves the path formulation with learned operators in the generalized Bellman-Ford algorithm. The NBFNet parameterizes the generalized Bellman-Ford algorithm with 3 neural components, namely INDICATOR, MESSAGE and AGGREGATE functions, which corresponds to the boundary condition, multiplication operator, and summation operator respectively1. The NBFNet covers many traditional path-based methods, and can be applied to both homogeneous graphs and multi-relational graphs (e.g., knowledge graphs) in both transductive and inductive settings. Experiments on both homogeneous graphs and knowledge graphs show that the proposed NBFNet outperforms existing methods by a large margin in both transductive and inductive settings, achieving new state-of-the-art results2 © 2021 Neural information processing systems foundation. All rights reserved.",,Forecasting; Graph theory; Graphic methods; Knowledge graph; Algorithm for solving; Bellman-Ford; Bellman-Ford algorithms; General graph; Graph neural networks; Knowledge graphs; Learning frameworks; Link prediction; Network frameworks; Path-based; Graph neural networks,Conference paper,Final,,Scopus,2-s2.0-85129042222
20,Min S.; Gao Z.; Peng J.; Wang L.; Qin K.; Fang B.,"Min, Shengjie (57215560428); Gao, Zhan (57216418441); Peng, Jing (57199828240); Wang, Liang (57875651700); Qin, Ke (24174646800); Fang, Bo (57221482936)",57215560428; 57216418441; 57199828240; 57875651700; 24174646800; 57221482936,STGSN — A Spatial–Temporal Graph Neural Network framework for time-evolving social networks,2021,Knowledge-Based Systems,214,,106746,,,,70,10.1016/j.knosys.2021.106746,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85099198840&doi=10.1016%2fj.knosys.2021.106746&partnerID=40&md5=3be64c832a71dcdc96ac424dd83d7d65,"University of Electronic Science and Technology of China, China; Sichuan University, China; Sichuan Provincial Public Security Department, China; ChinaCloud Information Technology Co., Ltd., China","Min S., University of Electronic Science and Technology of China, China, ChinaCloud Information Technology Co., Ltd., China; Gao Z., Sichuan University, China; Peng J., Sichuan Provincial Public Security Department, China; Wang L., Sichuan Provincial Public Security Department, China; Qin K., University of Electronic Science and Technology of China, China; Fang B., ChinaCloud Information Technology Co., Ltd., China","Social Network Analysis (SNA) has been a popular field of research since the early 1990s. Law enforcement agencies have been utilizing it as a tool for intelligence gathering and criminal investigation for decades. However, the graph nature of social networks makes it highly restricted to intelligence analysis tasks, such as role prediction (node classification), social relation inference (link prediction), and criminal group discovery (community detection), etc. In the past few years, many studies have focused on Graph Neural Network (GNN), which utilizes deep learning methods to solve graph-related problems. However, we have rarely seen GNNs tackle time-evolving social network problems, especially in the criminology field. The existing studies have commonly over-looked the temporal-evolution characteristics of social networks. In this paper, we propose a graph neural network framework, namely Spatial-Temporal Graph Social Network (STGSN), which models social networks from both spatial and temporal perspectives. Using a novel approach, we leverage the temporal attention mechanism to capture social networks’ temporal features. We design a method analyzing temporal attention distribution to improve the interpretation ability of our method. In the end, we conduct extensive experiments on six public datasets to prove our methods’ effectiveness. © 2021 Elsevier B.V.",Attention network; Criminal Network Analysis; Graph Neural Network; Social Network Analysis; Spatial–Temporal Graph Neural Network,Crime; Deep learning; Learning systems; Attention mechanisms; Community detection; Criminal investigation; Graph neural networks; Intelligence analysis; Intelligence gathering; Law-enforcement agencies; Temporal evolution; Neural networks,Article,Final,,Scopus,2-s2.0-85099198840
21,Baek J.; Kang M.; Hwang S.J.,"Baek, Jinheon (57219628188); Kang, Minki (57216615186); Hwang, Sung Ju (57687927300)",57219628188; 57216615186; 57687927300,ACCURATE LEARNING OF GRAPH REPRESENTATIONS WITH GRAPH MULTISET POOLING,2021,ICLR 2021 - 9th International Conference on Learning Representations,,,,,,,68,,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85132038165&partnerID=40&md5=be58af5b710d5378ea3cf35f48a679c4,"KAIST, South Korea; AITRICS, South Korea","Baek J., KAIST, South Korea; Kang M., KAIST, South Korea; Hwang S.J., KAIST, South Korea, AITRICS, South Korea","Graph neural networks have been widely used on modeling graph data, achieving impressive results on node classification and link prediction tasks. Yet, obtaining an accurate representation for a graph further requires a pooling function that maps a set of node representations into a compact form. A simple sum or average over all node representations considers all node features equally without consideration of their task relevance, and any structural dependencies among them. Recently proposed hierarchical graph pooling methods, on the other hand, may yield the same representation for two different graphs that are distinguished by the Weisfeiler-Lehman test, as they suboptimally preserve information from the node features. To tackle these limitations of existing graph pooling methods, we first formulate the graph pooling problem as a multiset encoding problem with auxiliary information about the graph structure, and propose a Graph Multiset Transformer (GMT) which is a multi-head attention based global pooling layer that captures the interaction between nodes according to their structural dependencies. We show that GMT satisfies both injectiveness and permutation invariance, such that it is at most as powerful as the Weisfeiler-Lehman graph isomorphism test. Moreover, our methods can be easily extended to the previous node clustering approaches for hierarchical graph pooling. Our experimental results show that GMT significantly outperforms state-of-the-art graph pooling methods on graph classification benchmarks with high memory and time efficiency, and obtains even larger performance gain on graph reconstruction and generation tasks. © 2021 ICLR 2021 - 9th International Conference on Learning Representations. All rights reserved.",,Benchmarking; Graph structures; Graph theory; Multilayer neural networks; Classification prediction; Graph data; Graph neural networks; Graph representation; Hierarchical graphs; Link prediction; Multi-sets; Pooling problem; Prediction tasks; Simple++; Graph neural networks,Conference paper,Final,,Scopus,2-s2.0-85132038165
22,Cai L.; Li J.; Wang J.; Ji S.,"Cai, Lei (57207372160); Li, Jundong (56186042700); Wang, Jie (57479579700); Ji, Shuiwang (18935244900)",57207372160; 56186042700; 57479579700; 18935244900,Line Graph Neural Networks for Link Prediction,2022,IEEE Transactions on Pattern Analysis and Machine Intelligence,44,9,,5103,5113,10,67,10.1109/TPAMI.2021.3080635,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85105853415&doi=10.1109%2fTPAMI.2021.3080635&partnerID=40&md5=f6b13fbb99063c4ff3a322d40020393f,"Washington State University, School of Electrical Engineering and Computer Science, Pullman, 99164, WA, United States; University of Virginia, School of Data Science, Department of Electrical and Computer Engineering, Department of Computer Science, Charlottesville, 22904, VA, United States; University of Science and Technology of China, Department of Electronic Engineering and Information Science, Hefei, Anhui, 230026, China; Texas AandM University, Department of Computer Science and Engineering, College Station, 77843, TX, United States","Cai L., Washington State University, School of Electrical Engineering and Computer Science, Pullman, 99164, WA, United States; Li J., University of Virginia, School of Data Science, Department of Electrical and Computer Engineering, Department of Computer Science, Charlottesville, 22904, VA, United States; Wang J., University of Science and Technology of China, Department of Electronic Engineering and Information Science, Hefei, Anhui, 230026, China; Ji S., Texas AandM University, Department of Computer Science and Engineering, College Station, 77843, TX, United States","We consider the graph link prediction task, which is a classic graph analytical problem with many real-world applications. With the advances of deep learning, current link prediction methods commonly compute features from subgraphs centered at two neighboring nodes and use the features to predict the label of the link between these two nodes. In this formalism, a link prediction problem is converted to a graph classification task. In order to extract fixed-size features for classification, graph pooling layers are necessary in the deep learning model, thereby incurring information loss. To overcome this key limitation, we propose to seek a radically different and novel path by making use of the line graphs in graph theory. In particular, each node in a line graph corresponds to a unique edge in the original graph. Therefore, link prediction problems in the original graph can be equivalently solved as a node classification problem in its corresponding line graph, instead of a graph classification task. Experimental results on fourteen datasets from different applications demonstrate that our proposed method consistently outperforms the state-of-The-Art methods, while it has fewer parameters and high training efficiency. © 1979-2012 IEEE.",Deep learning; graph analysis; graph neural networks; line graphs; link prediction,Classification (of information); Deep learning; Forecasting; Learning systems; Neural networks; Analytical problems; Graph classification; Information loss; Learning models; Link prediction; Neighboring nodes; State-of-the-art methods; Training efficiency; article; deep learning; prediction; Graph theory,Article,Final,All Open Access; Green Open Access,Scopus,2-s2.0-85105853415
23,Li Z.; Li J.; Nie R.; You Z.-H.; Bao W.,"Li, Zhengwei (57192308339); Li, Jiashu (57212577838); Nie, Ru (36241919200); You, Zhu-Hong (23062542900); Bao, Wenzheng (56285782100)",57192308339; 57212577838; 36241919200; 23062542900; 56285782100,A graph auto-encoder model for miRNA-disease associations prediction,2021,Briefings in Bioinformatics,22,4,bbaa240,,,,67,10.1093/bib/bbaa240,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85112167530&doi=10.1093%2fbib%2fbbaa240&partnerID=40&md5=a6a42b77e5e6a1cfe885cf2e947750d7,"Engineering Research Center of Mine Digitalization, Ministry of Education, School of Computer Science and Technology, China University of Mining and Technology, China; Xinjiang Technical Institute of Physics and Chemistry, Chinese Academy of Science, China; School of Information Engineering, Xuzhou University of Technology, China","Li Z., Engineering Research Center of Mine Digitalization, Ministry of Education, School of Computer Science and Technology, China University of Mining and Technology, China; Li J., Engineering Research Center of Mine Digitalization, Ministry of Education, School of Computer Science and Technology, China University of Mining and Technology, China; Nie R., Engineering Research Center of Mine Digitalization, Ministry of Education, School of Computer Science and Technology, China University of Mining and Technology, China; You Z.-H., Xinjiang Technical Institute of Physics and Chemistry, Chinese Academy of Science, China; Bao W., School of Information Engineering, Xuzhou University of Technology, China","Emerging evidence indicates that the abnormal expression of miRNAs involves in the evolution and progression of various human complex diseases. Identifying disease-related miRNAs as new biomarkers can promote the development of disease pathology and clinical medicine. However, designing biological experiments to validate disease-related miRNAs is usually time-consuming and expensive. Therefore, it is urgent to design effective computational methods for predicting potential miRNA-disease associations. Inspired by the great progress of graph neural networks in link prediction, we propose a novel graph auto-encoder model, named GAEMDA, to identify the potential miRNA-disease associations in an end-to-end manner. More specifically, the GAEMDA model applies a graph neural networks-based encoder, which contains aggregator function and multi-layer perceptron for aggregating nodes' neighborhood information, to generate the low-dimensional embeddings of miRNA and disease nodes and realize the effective fusion of heterogeneous information. Then, the embeddings of miRNA and disease nodes are fed into a bilinear decoder to identify the potential links between miRNA and disease nodes. The experimental results indicate that GAEMDA achieves the average area under the curve of 93.56 ± 0.44% under 5-fold cross-validation. Besides, we further carried out case studies on colon neoplasms, esophageal neoplasms and kidney neoplasms. As a result, 48 of the top 50 predicted miRNAs associated with these diseases are confirmed by the database of differentially expressed miRNAs in human cancers and microRNA deregulation in human disease database, respectively. The satisfactory prediction performance suggests that GAEMDA model could serve as a reliable tool to guide the following researches on the regulatory role of miRNAs. Besides, the source codes are available at https://github.com/chimianbuhetang/GAEMDA. © 2020 The Author(s) 2020. Published by Oxford University Press. All rights reserved. For Permissions, please email: journals.permissions@oup.com.",complex disease; graph auto-encoder; graph neural networks; heterogeneous graph; miRNA; miRNA-disease associations prediction,"Databases, Genetic; Gene Expression Regulation, Neoplastic; Humans; MicroRNAs; Models, Genetic; Neoplasms; Neural Networks, Computer; RNA, Neoplasm; Software; microRNA; RNA; biological model; biosynthesis; gene expression regulation; genetic database; genetics; human; metabolism; neoplasm; software",Article,Final,,Scopus,2-s2.0-85112167530
24,Pradhyumna P.; Shreya G.P.; Mohana,"Pradhyumna, P. (57288536100); Shreya, G.P. (57214791254); Mohana (57113679700)",57288536100; 57214791254; 57113679700,Graph Neural Network (GNN) in Image and Video Understanding Using Deep Learning for Computer Vision Applications,2021,"Proceedings of the 2nd International Conference on Electronics and Sustainable Communication Systems, ICESC 2021",,,,1183,1189,6,58,10.1109/ICESC51422.2021.9532631,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85116690815&doi=10.1109%2fICESC51422.2021.9532631&partnerID=40&md5=90179bb75d40cd0d30fa5b66f778d183,"RV College of Engineering®, Electronics and Telecommunication Engineering, Karnataka, Bengaluru, India","Pradhyumna P., RV College of Engineering®, Electronics and Telecommunication Engineering, Karnataka, Bengaluru, India; Shreya G.P., RV College of Engineering®, Electronics and Telecommunication Engineering, Karnataka, Bengaluru, India; Mohana, RV College of Engineering®, Electronics and Telecommunication Engineering, Karnataka, Bengaluru, India","Graph neural networks (GNNs) is an information - processing system that uses message passing among graph nodes. In recent years, GNN variants including graph attention network (GAT), graph convolutional network (GCN), and graph recurrent network (GRN) have shown revolutionary performance in computer vision applications using deep learning and artificial intelligence. These neural network model extensions, collect information in the form of graphs. GNN may be divided into three groups based on the challenges it solves: link prediction, node classification, graph classification. Machines can differentiate and recognise objects in image and video using standard CNNs. Extensive amount of research work needs to be done before robots can have same visual intuition as humans. GNN architectures, on the other hand, may be used to solve various image categorization and video challenges. The number of GNN applications in computer vision not limited, continues to expand. Human-object interaction, actin understanding, image categorization from a few shots and many more. In this paper use of GNN in image and video understanding, design aspects, architecture, applications and implementation challenges towards computer vision is described. GNN is a strong tool for analysing graph data and is still a relatively active area that needs further researches attention to solve many computer vision applications. © 2021 IEEE.",Atomic Visual Action(AVA); Convolutional Neural Network (CNN); Gated Adversarial Transformer (GAT); Graph Neural Networks (GNNs); Graph Parsing Neural Network (GPNN); Human-Object Interactions (HOI),Computer vision; Convolution; Convolutional neural networks; Graph theory; Message passing; Network architecture; Proteins; Recurrent neural networks; Atomic visual action; Convolutional neural network; Gated adversarial transformer; Graph neural network; Graph neural networks; Graph parsing; Graph parsing neural network; Human-object interaction; Neural-networks; Graph neural networks,Conference paper,Final,,Scopus,2-s2.0-85116690815
25,Huang J.; Shen H.; Hou L.; Cheng X.,"Huang, Junjie (57204639114); Shen, Huawei (21740199800); Hou, Liang (57211207038); Cheng, Xueqi (55855927900)",57204639114; 21740199800; 57211207038; 55855927900,Signed Graph Attention Networks,2019,Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics),11731 LNCS,,,566,577,11,57,10.1007/978-3-030-30493-5_53,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85072982169&doi=10.1007%2f978-3-030-30493-5_53&partnerID=40&md5=a2c08b6283757a428e9742bfe3c40fa0,"CAS Key Laboratory of Network Data Science and Technology, Institute of Computing Technology, Chinese Academy of Sciences, Beijing, China; University of Chinese Academy of Sciences, Beijing, China","Huang J., CAS Key Laboratory of Network Data Science and Technology, Institute of Computing Technology, Chinese Academy of Sciences, Beijing, China, University of Chinese Academy of Sciences, Beijing, China; Shen H., CAS Key Laboratory of Network Data Science and Technology, Institute of Computing Technology, Chinese Academy of Sciences, Beijing, China; Hou L., CAS Key Laboratory of Network Data Science and Technology, Institute of Computing Technology, Chinese Academy of Sciences, Beijing, China, University of Chinese Academy of Sciences, Beijing, China; Cheng X., CAS Key Laboratory of Network Data Science and Technology, Institute of Computing Technology, Chinese Academy of Sciences, Beijing, China","Graph or network data is ubiquitous in the real world, including social networks, information networks, traffic networks, biological networks and various technical networks. The non-Euclidean nature of graph data poses the challenge for modeling and analyzing graph data. Recently, Graph Neural Network (GNN) is proposed as a general and powerful framework to handle tasks on graph data, e.g., node embedding, link prediction and node classification. As a representative implementation of GNNs, Graph Attention Networks (GAT) is successfully applied in a variety of tasks on real datasets. However, GAT is designed to networks with only positive links and fails to handle signed networks which contain both positive and negative links. In this paper, we propose Signed Graph Attention Networks (SiGAT), generalizing GAT to signed networks. SiGAT incorporates graph motifs into GAT to capture two well-known theories in signed network research, i.e., balance theory and status theory. In SiGAT, motifs offer us the flexible structural pattern to aggregate and propagate messages on the signed network to generate node embeddings. We evaluate the proposed SiGAT method by applying it to the signed link prediction task. Experimental results on three real datasets demonstrate that SiGAT outperforms feature-based method, network embedding method and state-of-the-art GNN-based methods like signed graph convolutional networks (SGCN). © Springer Nature Switzerland AG 2019.",Graph Neural Network; Network embedding; Signed network,Embeddings; Information services; Neural networks; Biological networks; Convolutional networks; Feature-based method; Graph neural networks; Information networks; Network embedding; Signed networks; Structural pattern; Graph theory,Conference paper,Final,All Open Access; Green Open Access,Scopus,2-s2.0-85072982169
26,Cai L.; Ji S.,"Cai, Lei (57207372160); Ji, Shuiwang (18935244900)",57207372160; 18935244900,A multi-scale approach for graph link prediction,2020,AAAI 2020 - 34th AAAI Conference on Artificial Intelligence,,,,3308,3315,7,56,,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85090422368&partnerID=40&md5=7a920f21b8c5eafda078fe6343e4aed1,Washington State University; Texas AandM University,"Cai L., Washington State University; Ji S., Texas AandM University","Deep models can be made scale-invariant when trained with multi-scale information. Images can be easily made multi-scale, given their grid-like structures. Extending this to generic graphs poses major challenges. For example, in link prediction tasks, inputs are represented as graphs consisting of nodes and edges. Currently, the state-of-the-art model for link prediction uses supervised heuristic learning, which learns graph structure features centered on two target nodes. It then learns graph neural networks to predict the existence of links based on graph structure features. Thus, the performance of link prediction models highly depends on graph structure features. In this work, we propose a novel node aggregation method that can transform the enclosing subgraph into different scales and preserve the relationship between two target nodes for link prediction. A theory for analyzing the information loss during the re-scaling procedure is also provided. Graphs in different scales can provide scaleinvariant information, which enables graph neural networks to learn invariant features and improve link prediction performance. Our experimental results on 14 datasets from different areas demonstrate that our proposed method outperforms the state-of-the-art methods by employing multi-scale graphs without additional parameters. © 2020, Association for the Advancement of Artificial Intelligence.",,Forecasting; Graph theory; Graphic methods; Neural networks; Predictive analytics; Aggregation methods; Graph neural networks; Invariant features; Multi-scale approaches; Multi-scale informations; Scaling procedures; State-of-the-art methods; Structure features; Graph structures,Conference paper,Final,,Scopus,2-s2.0-85090422368
27,Liu Z.; Nguyen T.-K.; Fang Y.,"Liu, Zemin (57191689277); Nguyen, Trung-Kien (57753475300); Fang, Yuan (55469295200)",57191689277; 57753475300; 55469295200,Tail-GNN: Tail-Node Graph Neural Networks,2021,Proceedings of the ACM SIGKDD International Conference on Knowledge Discovery and Data Mining,,,,1109,1119,10,50,10.1145/3447548.3467276,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85114952378&doi=10.1145%2f3447548.3467276&partnerID=40&md5=05f4f16f23dac3e11774c3f34ffa4381,"Singapore Management University, Singapore, Singapore","Liu Z., Singapore Management University, Singapore, Singapore; Nguyen T.-K., Singapore Management University, Singapore, Singapore; Fang Y., Singapore Management University, Singapore, Singapore","The prevalence of graph structures in real-world scenarios enables important tasks such as node classification and link prediction. Graphs in many domains follow a long-tailed distribution in their node degrees, i.e., a significant fraction of nodes are tail nodes with a small degree. Although recent graph neural networks (GNNs) can learn powerful node representations, they treat all nodes uniformly and are not tailored to the large group of tail nodes. In particular, there is limited structural information (i.e., links) on tail nodes, resulting in inferior performance. Toward robust tail node embedding, in this paper we propose a novel graph neural network called Tail-GNN. It hinges on the novel concept of transferable neighborhood translation, to model the variable ties between a target node and its neighbors. On one hand, Tail-GNN learns a neighborhood translation from the structurally rich head nodes (i.e., high-degree nodes), which can be further transferred to the structurally limited tail nodes to enhance their representations. On the other hand, the ties with the neighbors are variable across different parts of the graph, and a global neighborhood translation is inflexible. Thus, we devise a node-wise adaptation to localize the global translation w.r.t. each node. Extensive experiments on five benchmark datasets demonstrate that our proposed Tail-GNN significantly outperforms the state-of-the-art baselines. © 2021 ACM.",graph neural networks; tail node embedding; transferable neighborhood translation,Data mining; Graph structures; Graph theory; Translation (languages); Benchmark datasets; Graph neural networks; High-degree nodes; Link prediction; Long-tailed distributions; Real-world scenario; State of the art; Structural information; Neural networks,Conference paper,Final,,Scopus,2-s2.0-85114952378
28,Yang M.; Zhou M.; Kalander M.; Huang Z.; King I.,"Yang, Menglin (57221996394); Zhou, Min (57220554998); Kalander, Marcus (57211870434); Huang, Zengfeng (42261693300); King, Irwin (7102275781)",57221996394; 57220554998; 57211870434; 42261693300; 7102275781,Discrete-time Temporal Network Embedding via Implicit Hierarchical Learning in Hyperbolic Space,2021,Proceedings of the ACM SIGKDD International Conference on Knowledge Discovery and Data Mining,,,,1975,1985,10,50,10.1145/3447548.3467422,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85114907122&doi=10.1145%2f3447548.3467422&partnerID=40&md5=809721c13e7eedaa0339dec8cd903b2d,"The Chinese University of Hong Kong, Hong Kong, Hong Kong","Yang M., The Chinese University of Hong Kong, Hong Kong, Hong Kong; Zhou M., The Chinese University of Hong Kong, Hong Kong, Hong Kong; Kalander M., The Chinese University of Hong Kong, Hong Kong, Hong Kong; Huang Z., The Chinese University of Hong Kong, Hong Kong, Hong Kong; King I., The Chinese University of Hong Kong, Hong Kong, Hong Kong","Representation learning over temporal networks has drawn considerable attention in recent years. Efforts are mainly focused on modeling structural dependencies and temporal evolving regularities in Euclidean space which, however, underestimates the inherent complex and hierarchical properties in many real-world temporal networks, leading to sub-optimal embeddings. To explore these properties of a complex temporal network, we propose a hyperbolic temporal graph network (HTGN) that fully takes advantage of the exponential capacity and hierarchical awareness of hyperbolic geometry. More specially, HTGN maps the temporal graph into hyperbolic space, and incorporates hyperbolic graph neural network and hyperbolic gated recurrent neural network, to capture the evolving behaviors and implicitly preserve hierarchical information simultaneously. Furthermore, in the hyperbolic space, we propose two important modules that enable HTGN to successfully model temporal networks: (1) hyperbolic temporal contextual self-attention (HTA) module to attend to historical states and (2) hyperbolic temporal consistency (HTC) module to ensure stability and generalization. Experimental results on multiple real-world datasets demonstrate the superiority of HTGN for temporal graph embedding, as it consistently outperforms competing methods by significant margins in various temporal link prediction tasks. Specifically, HTGN achieves AUC improvement up to 9.98% for link prediction and 11.4% for new link prediction. Moreover, the ablation study further validates the representational ability of hyperbolic geometry and the effectiveness of the proposed HTA and HTC modules. © 2021 ACM.",graph neural network; hyperbolic space; representation learning; temporal network,Complex networks; Data mining; Embeddings; Forecasting; Geometry; Hierarchical information; Hierarchical learning; Hyperbolic geometry; Hyperbolic graphs; Hyperbolic spaces; Real-world datasets; Temporal consistency; Temporal networks; Recurrent neural networks,Conference paper,Final,All Open Access; Green Open Access,Scopus,2-s2.0-85114907122
29,Qu L.; Zhu H.; Duan Q.; Shi Y.,"Qu, Liang (57210734138); Zhu, Huaisheng (57217169311); Duan, Qiqi (55919022300); Shi, Yuhui (7404964007)",57210734138; 57217169311; 55919022300; 7404964007,Continuous-Time Link Prediction via Temporal Dependent Graph Neural Network,2020,"The Web Conference 2020 - Proceedings of the World Wide Web Conference, WWW 2020",,,,3026,3032,6,47,10.1145/3366423.3380073,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85086585217&doi=10.1145%2f3366423.3380073&partnerID=40&md5=fa76ecc25758af0564b5c4959a2708c2,"Shenzhen Key Laboratory of Computational Intelligence Southern, University of Science and Technology, China","Qu L., Shenzhen Key Laboratory of Computational Intelligence Southern, University of Science and Technology, China; Zhu H., Shenzhen Key Laboratory of Computational Intelligence Southern, University of Science and Technology, China; Duan Q., Shenzhen Key Laboratory of Computational Intelligence Southern, University of Science and Technology, China; Shi Y., Shenzhen Key Laboratory of Computational Intelligence Southern, University of Science and Technology, China","Recently, graph neural networks (GNNs) have been shown to be an effective tool for learning the node representations of the networks and have achieved good performance on the semi-supervised node classification task. However, most existing GNNs methods fail to take networks' temporal information into account, therefore, cannot be well applied to dynamic network applications such as the continuous-time link prediction task. To address this problem, we propose a Temporal Dependent Graph Neural Network (TDGNN), a simple yet effective dynamic network representation learning framework which incorporates the network temporal information into GNNs. TDGNN introduces a novel Temporal Aggregator (TDAgg) to aggregate the neighbor nodes' features and edges' temporal information to obtain the target node representations. Specifically, it assigns the neighbor nodes aggregation weights using an exponential distribution to bias different edges' temporal information. The performance of the proposed method has been validated on six real-world dynamic network datasets for the continuous-time link prediction task. The experimental results show that the proposed method outperforms several state-of-the-art baselines. © 2020 ACM.",dynamic networks; graph neural networks; link prediction; network representation learning,Forecasting; Semi-supervised learning; World Wide Web; Aggregation weights; Classification tasks; Effective dynamics; Exponential distributions; Graph neural networks; Learning frameworks; State of the art; Temporal information; Continuous time systems,Conference paper,Final,,Scopus,2-s2.0-85086585217
30,Baek J.; Lee D.B.; Hwang S.J.,"Baek, Jinheon (57219628188); Lee, Dong Bok (57219692786); Hwang, Sung Ju (57687927300)",57219628188; 57219692786; 57687927300,Learning to extrapolate knowledge: Transductive few-shot out-of-graph link prediction,2020,Advances in Neural Information Processing Systems,2020-December,,,,,,45,,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85106684836&partnerID=40&md5=6744264608fc4b12c79e10f2f1d3dfbb,"KAIST; AITRICS, South Korea","Baek J., KAIST; Lee D.B., KAIST; Hwang S.J., KAIST, AITRICS, South Korea","Many practical graph problems, such as knowledge graph construction and drug-drug interaction prediction, require to handle multi-relational graphs. However, handling real-world multi-relational graphs with Graph Neural Networks (GNNs) is often challenging due to their evolving nature, as new entities (nodes) can emerge over time. Moreover, newly emerged entities often have few links, which makes the learning even more difficult. Motivated by this challenge, we introduce a realistic problem of few-shot out-of-graph link prediction, where we not only predict the links between the seen and unseen nodes as in a conventional out-of-knowledge link prediction task but also between the unseen nodes, with only few edges per node. We tackle this problem with a novel transductive meta-learning framework which we refer to as Graph Extrapolation Networks (GEN). GEN meta-learns both the node embedding network for inductive inference (seen-to-unseen) and the link prediction network for transductive inference (unseen-to-unseen). For transductive link prediction, we further propose a stochastic embedding layer to model uncertainty in the link prediction between unseen entities. We validate our model on multiple benchmark datasets for knowledge graph completion and drug-drug interaction prediction. The results show that our model significantly outperforms relevant baselines for out-of-graph link prediction tasks. © 2020 Neural information processing systems foundation. All rights reserved.",,Drug interactions; Embeddings; Extrapolation; Forecasting; Knowledge representation; Neural networks; Stochastic models; Stochastic systems; Uncertainty analysis; Benchmark datasets; Drug-drug interactions; Embedding network; Graph neural networks; Inductive inference; Meta-learning frameworks; Model uncertainties; Transductive inference; Graph theory,Conference paper,Final,,Scopus,2-s2.0-85106684836
31,Grover A.; Zweig A.; Ermon S.,"Grover, Aditya (56911848400); Zweig, Aaron (57190033893); Ermon, Stefano (35791579200)",56911848400; 57190033893; 35791579200,Graphite: Iterative generative modeling of graphs,2019,"36th International Conference on Machine Learning, ICML 2019",2019-June,,,4344,4356,12,44,,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85078185588&partnerID=40&md5=a57060320841181d24c21a685d8206a7,"Department of Computer Science, Stanford University, United States","Grover A., Department of Computer Science, Stanford University, United States; Zweig A., Department of Computer Science, Stanford University, United States; Ermon S., Department of Computer Science, Stanford University, United States","Graphs are a fundamental abstraction for modeling relational data. However, graphs are discrete and combinatorial in nature, and learning representations suitable for machine learning tasks poses statistical and computational challenges. In this work, we propose Graphite, an algorithmic framework for unsupervised learning of representations over nodes in large graphs using deep latent variable generative models. Our model parameterizes variational autoencoders (VAE) with graph neural networks, and uses a novel iterative graph refinement strategy inspired by low-rank approximations for decoding. On a wide variety of synthetic and benchmark datasets, Graphite outperforms competing approaches for the tasks of density estimation, link prediction, and node classification. Finally, we derive a theoretical connection between message passing in graph neural networks and mean-field variational inference. Copyright 2019 by the author(s).",,Approximation theory; Classification (of information); Graphic methods; Graphite; Machine learning; Message passing; Unsupervised learning; Algorithmic framework; Benchmark datasets; Computational challenges; Density estimation; Graph neural networks; Low rank approximations; Refinement strategy; Variational inference; Iterative decoding,Conference paper,Final,,Scopus,2-s2.0-85078185588
32,You J.; Du T.; Leskovec J.,"You, Jiaxuan (57195955464); Du, Tianyu (58587896400); Leskovec, Jure (12241436100)",57195955464; 58587896400; 12241436100,ROLAND: Graph Learning Framework for Dynamic Graphs,2022,Proceedings of the ACM SIGKDD International Conference on Knowledge Discovery and Data Mining,,,,2358,2366,8,45,10.1145/3534678.3539300,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85137145103&doi=10.1145%2f3534678.3539300&partnerID=40&md5=c173057f7735d72d9eb05ea6acd74b1b,"Stanford University, Stanford, CA, United States","You J., Stanford University, Stanford, CA, United States; Du T., Stanford University, Stanford, CA, United States; Leskovec J., Stanford University, Stanford, CA, United States","Graph Neural Networks (GNNs) have been successfully applied to many real-world static graphs. However, the success of static graphs has not fully translated to dynamic graphs due to the limitations in model design, evaluation settings, and training strategies. Concretely, existing dynamic GNNs do not incorporate state-of-the-art designs from static GNNs, which limits their performance. Current evaluation settings for dynamic GNNs do not fully reflect the evolving nature of dynamic graphs. Finally, commonly used training methods for dynamic GNNs are not scalable. Here we propose ROLAND, an effective graph representation learning framework for real-world dynamic graphs. At its core, the ROLAND framework can help researchers easily repurpose any static GNN to dynamic graphs. Our insight is to view the node embeddings at different GNN layers as hierarchical node states and then recurrently update them over time. We then introduce a live-update evaluation setting for dynamic graphs that mimics real-world use cases, where GNNs are making predictions and being updated on a rolling basis. Finally, we propose a scalable and efficient training approach for dynamic GNNs via incremental training and meta-learning. We conduct experiments over eight different dynamic graph datasets on future link prediction tasks. Models built using the ROLAND framework achieve on average 62.7% relative mean reciprocal rank (MRR) improvement over state-of-the-art baselines under the standard evaluation settings on three datasets. We find state-of-the-art baselines experience out-of-memory errors for larger datasets, while ROLAND can easily scale to dynamic graphs with 56 million edges. After re-implementing these baselines using the ROLAND training strategy, ROLAND models still achieve on average 15.5% relative MRR improvement over the baselines. © 2022 ACM.",dynamic graphs; graph neural networks; network analysis,Electric network analysis; Graphic methods; Arts designs; Design evaluation; Dynamic graph; Graph neural networks; Learning frameworks; Mean reciprocal ranks; Modeling designs; Real-world; State of the art; Training strategy; Graph neural networks,Conference paper,Final,All Open Access; Green Open Access,Scopus,2-s2.0-85137145103
33,Zhang M.; Li P.; Xia Y.; Wang K.; Jin L.,"Zhang, Muhan (57191868624); Li, Pan (55495089200); Xia, Yinglong (8939059900); Wang, Kai (57226035803); Jin, Long (57221608054)",57191868624; 55495089200; 8939059900; 57226035803; 57221608054,Labeling Trick: A Theory of Using Graph Neural Networks for Multi-Node Representation Learning,2021,Advances in Neural Information Processing Systems,11,,,9061,9073,12,39,,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85131874111&partnerID=40&md5=a0f2d19a409d41de8ec28f7ad8bf4891,"Institute for Artificial Intelligence, Peking University, China; Beijing Institute for General Artificial Intelligence, China; Department of Computer Science, Purdue University, United States; Facebook AI, United States","Zhang M., Institute for Artificial Intelligence, Peking University, China, Beijing Institute for General Artificial Intelligence, China; Li P., Department of Computer Science, Purdue University, United States; Xia Y., Facebook AI, United States; Wang K., Facebook AI, United States; Jin L., Facebook AI, United States","In this paper, we provide a theory of using graph neural networks (GNNs) for multi-node representation learning (where we are interested in learning a representation for a set of more than one node, such as link). We know that GNN is designed to learn single-node representations. When we want to learn a node set representation involving multiple nodes, a common practice in previous works is to directly aggregate the single-node representations obtained by a GNN into a joint node set representation. In this paper, we show a fundamental constraint of such an approach, namely the inability to capture the dependence between nodes in the node set, and argue that directly aggregating individual node representations does not lead to an effective joint representation for multiple nodes. Then, we notice that a few previous successful works for multi-node representation learning, including SEAL, Distance Encoding, and ID-GNN, all used node labeling. These methods first label nodes in the graph according to their relationships with the target node set before applying a GNN. Then, the node representations obtained in the labeled graph are aggregated into a node set representation. By investigating their inner mechanisms, we unify these node labeling techniques into a single and most general form—labeling trick. We prove that with labeling trick a sufficiently expressive GNN learns the most expressive node set representations, thus in principle solves any joint learning tasks over node sets. Experiments on one important two-node representation learning task, link prediction, verified our theory. Our work explains the superior performance of previous node-labeling-based methods, and establishes a theoretical foundation of using GNNs for multi-node representation learning. © 2021 Neural information processing systems foundation. All rights reserved.",,Graph theory; Learning systems; AS-links; Graph neural networks; Know-that; Labelings; Learn+; Learning tasks; Multi-nodes; Multiple nodes; Node sets; Set representation; Graph neural networks,Conference paper,Final,,Scopus,2-s2.0-85131874111
34,Chen T.; Sui Y.; Chen X.; Zhang A.; Wang Z.,"Chen, Tianlong (57221072108); Sui, Yongduo (57222257500); Chen, Xuxi (57219692857); Zhang, Aston (57689101300); Wang, Zhangyang (56288839400)",57221072108; 57222257500; 57219692857; 57689101300; 56288839400,A Unified Lottery Ticket Hypothesis for Graph Neural Networks,2021,Proceedings of Machine Learning Research,139,,,1695,1706,11,39,,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85161345561&partnerID=40&md5=171e49651912fae3b8477e26bbf74d3c,"Department of Electrical and Computer Engineering, University of Texas, Austin, United States; University of Science and Technology of China, China; AWS Deep Learning","Chen T., Department of Electrical and Computer Engineering, University of Texas, Austin, United States; Sui Y., University of Science and Technology of China, China; Chen X., Department of Electrical and Computer Engineering, University of Texas, Austin, United States; Zhang A., AWS Deep Learning; Wang Z., Department of Electrical and Computer Engineering, University of Texas, Austin, United States","With graphs rapidly growing in size and deeper graph neural networks (GNNs) emerging, the training and inference of GNNs become increasingly expensive. Existing network weight pruning algorithms cannot address the main space and computational bottleneck in GNNs, caused by the size and connectivity of the graph. To this end, this paper first presents a unified GNN sparsification (UGS) framework that simultaneously prunes the graph adjacency matrix and the model weights, for effectively accelerating GNN inference on large-scale graphs. Leveraging this new tool, we further generalize the recently popular lottery ticket hypothesis to GNNs for the first time, by defining a graph lottery ticket (GLT) as a pair of core sub-dataset and sparse sub-network, which can be jointly identified from the original GNN and the full dense graph by iteratively applying UGS. Like its counterpart in convolutional neural networks, GLT can be trained in isolation to match the performance of training with the full model and graph, and can be drawn from both randomly initialized and self-supervised pre-trained GNNs. Our proposal has been experimentally verified across various GNN architectures and diverse tasks, on both small-scale graph datasets (Cora, Citeseer and PubMed), and large-scale datasets from the challenging Open Graph Benchmark (OGB). Specifically, for node classification, our found GLTs achieve the same accuracies with 20% ∼ 98% MACs saving on small graphs and 25% ∼ 85% MACs saving on large ones. For link prediction, GLTs lead to 48% ∼ 97% and 70% MACs saving on small and large graph datasets, respectively, without compromising predictive performance. Codes are at https://github.com/VITA-Group/Unified-LTH-GNN. Copyright © 2021 by the author(s)",,Convolutional neural networks; Graph algorithms; Graph structures; Iterative methods; Large dataset; Computational bottlenecks; Graph adjacency matrices; Graph neural networks; Large-scales; Model weights; Network inference; Network weights; Pruning algorithms; Sparsification; Subnetworks; Graph neural networks,Conference paper,Final,,Scopus,2-s2.0-85161345561
35,Wu L.; Cui P.; Pei J.; Zhao L.; Song L.,"Wu, Lingfei (56937260100); Cui, Peng (34568700100); Pei, Jian (35273378100); Zhao, Liang (56355436400); Song, Le (55587150100)",56937260100; 34568700100; 35273378100; 56355436400; 55587150100,Graph Neural Networks,2022,"Graph Neural Networks: Foundations, Frontiers, and Applications",,,,27,37,10,39,10.1007/978-981-16-6054-2_3,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85162715959&doi=10.1007%2f978-981-16-6054-2_3&partnerID=40&md5=d04b599c3e29b8711ca959ef42e4e679,"JD Silicon Valley Research Center, Mountain View, United States; Department of Computer Science, Tsinghua University, China; School of Computing Science, Simon Fraser University, Burnaby, Canada; Department of Compute Science, Emory University, Atlanta, United States; Mohamed bin Zayed University of Artificial Intelligence, United Arab Emirates","Wu L., JD Silicon Valley Research Center, Mountain View, United States; Cui P., Department of Computer Science, Tsinghua University, China; Pei J., School of Computing Science, Simon Fraser University, Burnaby, Canada; Zhao L., Department of Compute Science, Emory University, Atlanta, United States; Song L., Mohamed bin Zayed University of Artificial Intelligence, United Arab Emirates","Deep Learning has become one of the most dominant approaches in Artificial Intelligence research today. Although conventional deep learning techniques have achieved huge successes on Euclidean data such as images, or sequence data such as text, there are many applications that are naturally or best represented with a graph structure. This gap has driven a tide in research for deep learning on graphs, among them Graph Neural Networks (GNNs) are the most successful in coping with various learning tasks across a large number of application domains. In this chapter, we will systematically organize the existing research of GNNs along three axes: foundations, frontiers, and applications. We will introduce the fundamental aspects of GNNs ranging from the popular models and their expressive powers, to the scalability, interpretability and robustness of GNNs. Then, we will discuss various frontier research, ranging from graph classification and link prediction, to graph generation and transformation, graph matching and graph structure learning. Based on them, we further summarize the basic procedures which exploit full use of various GNNs for a large number of applications. Finally, we provide the organization of our book and summarize the roadmap of the various research topics of GNNs. © The Editor(s) (if applicable) and The Author(s), under exclusive license to Springer Nature Singapore Pte Ltd. 2022.",,,Book chapter,Final,,Scopus,2-s2.0-85162715959
36,Shen Z.-A.; Luo T.; Zhou Y.-K.; Yu H.; Du P.-F.,"Shen, Zi-Ang (57214793652); Luo, Tao (57206634588); Zhou, Yuan-Ke (57208554119); Yu, Han (57214796144); Du, Pu-Feng (15759150300)",57214793652; 57206634588; 57208554119; 57214796144; 15759150300,Npi-gnn: Predicting ncrna-protein interactions with deep graph neural networks,2021,Briefings in Bioinformatics,22,5,bbab051,,,,39,10.1093/bib/bbab051,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85113850036&doi=10.1093%2fbib%2fbbab051&partnerID=40&md5=40ba97ed5b0690a7a208b7c1f6a50d07,"College of Intelligence and Computing, Tianjin University, Tianjin, 300350, China","Shen Z.-A., College of Intelligence and Computing, Tianjin University, Tianjin, 300350, China; Luo T., College of Intelligence and Computing, Tianjin University, Tianjin, 300350, China; Zhou Y.-K., College of Intelligence and Computing, Tianjin University, Tianjin, 300350, China; Yu H., College of Intelligence and Computing, Tianjin University, Tianjin, 300350, China; Du P.-F., College of Intelligence and Computing, Tianjin University, Tianjin, 300350, China","Noncoding RNAs (ncRNAs) play crucial roles in many biological processes. Experimental methods for identifying ncRNA-protein interactions (NPIs) are always costly and time-consuming. Many computational approaches have been developed as alternative ways. In this work, we collected five benchmarking datasets for predicting NPIs. Based on these datasets, we evaluated and compared the prediction performances of existing machine-learning based methods. Graph neural network (GNN) is a recently developed deep learning algorithm for link predictions on complex networks, which has never been applied in predicting NPIs. We constructed a GNN-based method, which is called Noncoding RNA-Protein Interaction prediction using Graph Neural Networks (NPI-GNN), to predict NPIs. The NPI-GNN method achieved comparable performance with state-of-The-Art methods in a 5-fold cross-validation. In addition, it is capable of predicting novel interactions based on network information and sequence information. We also found that insufficient sequence information does not affect the NPI-GNN prediction performance much, which makes NPI-GNN more robust than other methods. As far as we can tell, NPI-GNN is the first end-To-end GNN predictor for predicting NPIs. All benchmarking datasets in this work and all source codes of the NPI-GNN method have been deposited with documents in a GitHub repo (https://github.com/AshuiRUA/NPI-GNN). © 2021 The Author(s) 2021. Published by Oxford University Press. All rights reserved. For Permissions, please email: journals.permissions@oup.com.",Graph neural network; Ncrna-protein interaction; Noncoding rna,"Benchmarking; Datasets as Topic; Deep Learning; Humans; Internet; Protein Binding; Proteins; RNA, Untranslated; Sensitivity and Specificity; Software; protein; protein binding; untranslated RNA; benchmarking; genetics; human; information processing; Internet; metabolism; sensitivity and specificity; software",Article,Final,,Scopus,2-s2.0-85113850036
37,Yadati N.; Nitin V.; Nimishakavi M.; Yadav P.; Louis A.; Talukdar P.,"Yadati, Naganand (57214230745); Nitin, Vikram (57218717194); Nimishakavi, Madhav (57204937583); Yadav, Prateek (57223914772); Louis, Anand (36172230600); Talukdar, Partha (25652280700)",57214230745; 57218717194; 57204937583; 57223914772; 36172230600; 25652280700,NHP: Neural Hypergraph Link Prediction,2020,"International Conference on Information and Knowledge Management, Proceedings",,,,1705,1714,9,37,10.1145/3340531.3411870,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85095863369&doi=10.1145%2f3340531.3411870&partnerID=40&md5=b501f31ac0bb1f0cba9695f20f07ddfb,"Indian Institute of Science, Bangalore, India; Columbia University, New York, United States; Facebook Ai, London, United Kingdom; LinkedIn, Bangalore, India","Yadati N., Indian Institute of Science, Bangalore, India; Nitin V., Columbia University, New York, United States; Nimishakavi M., Facebook Ai, London, United Kingdom; Yadav P., LinkedIn, Bangalore, India; Louis A., Indian Institute of Science, Bangalore, India; Talukdar P., Indian Institute of Science, Bangalore, India","Link prediction insimple graphs is a fundamental problem in which new links between vertices are predicted based on the observed structure of the graph. However, in many real-world applications, there is a need to model relationships among vertices that go beyond pairwise associations. For example, in a chemical reaction, relationship among the reactants and products is inherently higher-order. Additionally, there is a need to represent the direction from reactants to products. Hypergraphs provide a natural way to represent such complex higher-order relationships. Graph Convolutional Network (GCN) has recently emerged as a powerful deep learning-based approach for link prediction over simple graphs. However, their suitability for link prediction in hypergraphs is underexplored - we fill this gap in this paper and propose Neural Hyperlink Predictor (NHP). NHP adapts GCNs for link prediction in hypergraphs. We propose two variants of NHP - NHP-U and NHP-D - for link prediction over undirected and directed hypergraphs, respectively. To the best of our knowledge, NHP-D is the first-ever method for link prediction over directed hypergraphs. An important feature of NHP is that it can also be used for hyperlinks in which dissimilar vertices interact (e.g. acids reacting with bases). Another attractive feature of NHP is that it can be used to predict unseen hyperlinks at test time (inductive hyperlink prediction). Through extensive experiments on multiple real-world datasets, we show NHP's effectiveness. © 2020 ACM.",directed hypergraph; graph neural network; knowledge graph canonicalisation; link prediction,Convolutional neural networks; Deep learning; Forecasting; Hypertext systems; Knowledge management; Convolutional networks; Directed hypergraphs; Higher-order; Important features; Learning-based approach; Link prediction; Model relationships; Real-world datasets; Graph theory,Conference paper,Final,,Scopus,2-s2.0-85095863369
38,Liu X.; Tan H.; Chen Q.; Lin G.,"Liu, Xiyang (57218714252); Tan, Huobin (36994921700); Chen, Qinghong (57218708391); Lin, Guangyan (12241496600)",57218714252; 36994921700; 57218708391; 12241496600,RAGAT: Relation Aware Graph Attention Network for Knowledge Graph Completion,2021,IEEE Access,9,,9340326,20840,20849,9,37,10.1109/ACCESS.2021.3055529,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85100473446&doi=10.1109%2fACCESS.2021.3055529&partnerID=40&md5=db5e85afaf8628f816918c0df09ae59e,"School of Software, Beihang University, Beijing, 100191, China","Liu X., School of Software, Beihang University, Beijing, 100191, China; Tan H., School of Software, Beihang University, Beijing, 100191, China; Chen Q., School of Software, Beihang University, Beijing, 100191, China; Lin G., School of Software, Beihang University, Beijing, 100191, China","Knowledge graph completion (KGC) is the task of predicting missing links based on known triples for knowledge graphs. Several recent works suggest that Graph Neural Networks (GNN) that exploit graph structures achieve promising performance on KGC. These models learn information called messages from neighboring entities and relations and then aggregate messages to update central entity representations. The drawback of existing GNN based models lies in that they tend to treat relations equally and learn fixed network parameters, overlooking the distinction of each relational information. In this work, we propose a Relation Aware Graph ATtention network (RAGAT) that constructs separate message functions for different relations, which aims at exploiting the heterogeneous characteristics of knowledge graphs. Specifically, we introduce relation specific parameters to augment the expressive capability of message functions, which enables the model to extract relational information in parameter space. To validate the effect of relation aware mechanism, RAGAT is implemented with a variety of relation aware message functions. Experiments show RAGAT outperforms state-of-the-art link prediction baselines on standard FB15k-237 and WN18RR datasets. © 2013 IEEE.",graph attention networks; Knowledge graph completion; knowledge graph embedding,Knowledge representation; Central-entity; Fixed networks; Graph neural networks; Heterogeneous characteristic; Knowledge graphs; Link prediction; Parameter spaces; State of the art; Graph structures,Article,Final,All Open Access; Gold Open Access,Scopus,2-s2.0-85100473446
39,Zhang W.; Mao J.; Cao Y.; Xu C.,"Zhang, Weifeng (57211331419); Mao, Jingwen (57219877000); Cao, Yi (57206889387); Xu, Congfu (8937504100)",57211331419; 57219877000; 57206889387; 8937504100,Multiplex Graph Neural Networks for Multi-behavior Recommendation,2020,"International Conference on Information and Knowledge Management, Proceedings",,,,2313,2316,3,36,10.1145/3340531.3412119,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85095865238&doi=10.1145%2f3340531.3412119&partnerID=40&md5=b0f1957f1ce6d5649ab61f681c8f46d8,"Zhejiang University, Hangzhou, China","Zhang W., Zhejiang University, Hangzhou, China; Mao J., Zhejiang University, Hangzhou, China; Cao Y., Zhejiang University, Hangzhou, China; Xu C., Zhejiang University, Hangzhou, China","This paper focuses on the multi-behavior recommendation problem, i.e., generating personalized recommendation based on multiple types of user behaviors. Methods proposed recently usually leverage the ordinal assumption, which means that users? different types of behaviors should take place in a fixed order. However, this assumption may be too strong in some scenarios. In this paper, a more general model named Multiplex Graph Neural Network (MGNN) is proposed as a remedy. MGNN tackles the multi-behavior recommendation problem from a novel perspective, i.e., the perspective of link prediction in multiplex networks. By taking advantage of both the multiplex network structure and graph representation learning techniques, MGNN learns shared embeddings and behavior-specific embeddings for users and items to model the collective effect of multiple types of behaviors. Experiments conducted on both ordinal-behavior datasets and generic-behavior datasets demonstrate the effectiveness of the proposed MGNN model. © 2020 ACM.",graph neural networks; multi-behavior recommendation; multiplex networks,Behavioral research; Embeddings; Knowledge management; Learning systems; Collective effects; Graph neural networks; Graph representation; Learning techniques; Link prediction; Multiplex networks; Personalized recommendation; User behaviors; Neural networks,Conference paper,Final,,Scopus,2-s2.0-85095865238
40,Hwang D.; Park J.; Kwon S.; Kim K.-M.; Ha J.-W.; Kim H.J.,"Hwang, Dasol (57219792692); Park, Jinyoung (57219795521); Kwon, Sunyoung (55903802600); Kim, Kyung-Min (57196121457); Ha, Jung-Woo (55430349200); Kim, Hyunwoo J. (56336378000)",57219792692; 57219795521; 55903802600; 57196121457; 55430349200; 56336378000,Self-supervised auxiliary learning with meta-paths for heterogeneous graphs,2020,Advances in Neural Information Processing Systems,2020-December,,,,,,36,,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85102793181&partnerID=40&md5=94025d1ad551c201464d8d99ae066314,"Korea University, South Korea; NAVER AI Lab.; NAVER CLOVA; Pusan National University, South Korea","Hwang D., Korea University, South Korea; Park J., Korea University, South Korea; Kwon S., Pusan National University, South Korea; Kim K.-M., NAVER AI Lab., NAVER CLOVA; Ha J.-W., NAVER AI Lab., NAVER CLOVA; Kim H.J., Korea University, South Korea","Graph neural networks have shown superior performance in a wide range of applications providing a powerful representation of graph-structured data. Recent works show that the representation can be further improved by auxiliary tasks. However, the auxiliary tasks for heterogeneous graphs, which contain rich semantic information with various types of nodes and edges, have less explored in the literature. In this paper, to learn graph neural networks on heterogeneous graphs we propose a novel self-supervised auxiliary learning method using meta-paths, which are composite relations of multiple edge types. Our proposed method is learning to learn a primary task by predicting meta-paths as auxiliary tasks. This can be viewed as a type of meta-learning. The proposed method can identify an effective combination of auxiliary tasks and automatically balance them to improve the primary task. Our methods can be applied to any graph neural networks in a plug-in manner without manual labeling or additional data. The experiments demonstrate that the proposed method consistently improves the performance of link prediction and node classification on heterogeneous graphs. © 2020 Neural information processing systems foundation. All rights reserved.",,Graph structures; Graph theory; Graphic methods; Learning systems; Semantics; Additional datum; Graph neural networks; Heterogeneous graph; Learning methods; Learning to learn; Link prediction; Representation of graphs; Semantic information; Neural networks,Conference paper,Final,,Scopus,2-s2.0-85102793181
41,Zhou F.; Cao C.,"Zhou, Fan (57191032864); Cao, Chengtai (57211952526)",57191032864; 57211952526,Overcoming Catastrophic Forgetting in Graph Neural Networks with Experience Replay,2021,"35th AAAI Conference on Artificial Intelligence, AAAI 2021",5B,,,4714,4722,8,35,,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85121154688&partnerID=40&md5=16a8ffa4e20223b61aa8f2169ffa2825,"University of Electronic Science and Technology of China, China","Zhou F., University of Electronic Science and Technology of China, China; Cao C., University of Electronic Science and Technology of China, China","Graph Neural Networks (GNNs) have recently received significant research attention due to their superior performance on a variety of graph-related learning tasks. Most of the current works focus on either static or dynamic graph settings, addressing a single particular task, e.g., node/graph classification, link prediction. In this work, we investigate the question: can GNNs be applied to continuously learning a sequence of tasks? Towards that, we explore the Continual Graph Learning (CGL) paradigm and present the Experience Replay based framework ER-GNN for CGL to alleviate the catastrophic forgetting problem in existing GNNs. ER-GNN stores knowledge from previous tasks as experiences and replays them when learning new tasks to mitigate the catastrophic forgetting issue. We propose three experience node selection strategies: mean of feature, coverage maximization, and influence maximization, to guide the process of selecting experience nodes. Extensive experiments on three benchmark datasets demonstrate the effectiveness of our ER-GNN and shed light on the incremental graph (non-Euclidean) structure learning. Copyright © 2021, Association for the Advancement of Artificial Intelligence (www.aaai.org). All rights reserved.",,Learning systems; 'current; Catastrophic forgetting; Dynamic graph; Experience replay; Graph classification; Graph neural networks; Learning tasks; Link prediction; Node graph; Performance; Graph neural networks,Conference paper,Final,,Scopus,2-s2.0-85121154688
42,Ahn S.J.; Kim M.,"Ahn, Seong Jin (57234585800); Kim, Myoungho (34975062900)",57234585800; 34975062900,Variational Graph Normalized AutoEncoders,2021,"International Conference on Information and Knowledge Management, Proceedings",,,,2827,2831,4,34,10.1145/3459637.3482215,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85119197053&doi=10.1145%2f3459637.3482215&partnerID=40&md5=bc78046c6c2761ceeaca7a89b11691e0,"Kaist, Daejeon, South Korea","Ahn S.J., Kaist, Daejeon, South Korea; Kim M., Kaist, Daejeon, South Korea","Link prediction is one of the key problems for graph-structured data. With the advancement of graph neural networks, graph autoencoders (GAEs) and variational graph autoencoders (VGAEs) have been proposed to learn graph embeddings in an unsupervised way. It has been shown that these methods are effective for link prediction tasks. However, they do not work well in link predictions when a node whose degree is zero (i.g., isolated node) is involved. We have found that GAEs/VGAEs make embeddings of isolated nodes close to zero regardless of their content features. In this paper, we propose a novel Variational Graph Normalized AutoEncoder (VGNAE) that utilize L2-normalization to derive better embeddings for isolated nodes. We show that our VGNAEs outperform the existing state-of-the-art models for link prediction tasks. The code is available at https://github.com/SeongJinAhn/VGNAE. © 2021 ACM.",graph convolutional networks; graph embedding; link prediction; normalization,Convolutional neural networks; Forecasting; Graph embeddings; Graph structures; Graph theory; Auto encoders; Convolutional networks; Embeddings; Graph convolutional network; Graph embeddings; Graph structured data; Isolated nodes; Link prediction; Normalisation; Prediction tasks; Graph neural networks,Conference paper,Final,All Open Access; Green Open Access,Scopus,2-s2.0-85119197053
43,Zhang M.; Wu S.; Yu X.; Liu Q.; Wang L.,"Zhang, Mengqi (57215545099); Wu, Shu (36245362600); Yu, Xueli (57218705348); Liu, Qiang (56818103100); Wang, Liang (57218666547)",57215545099; 36245362600; 57218705348; 56818103100; 57218666547,Dynamic Graph Neural Networks for Sequential Recommendation,2023,IEEE Transactions on Knowledge and Data Engineering,35,5,,4741,4753,12,34,10.1109/TKDE.2022.3151618,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85124820831&doi=10.1109%2fTKDE.2022.3151618&partnerID=40&md5=78880c951c0a177eb41aa7f8498f324a,"University of Chinese Academy of Sciences, School of Artificial Intelligence, Beijing, 101408, China; Chinese Academy of Sciences, Center for Research on Intelligent Perception and Computing (CRIPAC), Institute of Automation, Beijing, 100190, China; Beijing Institute for General Artificial Intelligence (BIGAI), Beijing, 100081, China","Zhang M., University of Chinese Academy of Sciences, School of Artificial Intelligence, Beijing, 101408, China, Chinese Academy of Sciences, Center for Research on Intelligent Perception and Computing (CRIPAC), Institute of Automation, Beijing, 100190, China; Wu S., University of Chinese Academy of Sciences, School of Artificial Intelligence, Beijing, 101408, China, Chinese Academy of Sciences, Center for Research on Intelligent Perception and Computing (CRIPAC), Institute of Automation, Beijing, 100190, China; Yu X., Beijing Institute for General Artificial Intelligence (BIGAI), Beijing, 100081, China; Liu Q., University of Chinese Academy of Sciences, School of Artificial Intelligence, Beijing, 101408, China, Chinese Academy of Sciences, Center for Research on Intelligent Perception and Computing (CRIPAC), Institute of Automation, Beijing, 100190, China; Wang L., University of Chinese Academy of Sciences, School of Artificial Intelligence, Beijing, 101408, China, Chinese Academy of Sciences, Center for Research on Intelligent Perception and Computing (CRIPAC), Institute of Automation, Beijing, 100190, China","Modeling user preference from his historical sequences is one of the core problems of sequential recommendation. Existing methods in this field are widely distributed from conventional methods to deep learning methods. However, most of them only model users' interests within their own sequences and ignore the dynamic collaborative signals among different user sequences, making it insufficient to explore users' preferences. We take inspiration from dynamic graph neural networks to cope with this challenge, modeling the user sequence and dynamic collaborative signals into one framework. We propose a new method named Dynamic Graph Neural Network for Sequential Recommendation (DGSR), which connects different user sequences through a dynamic graph structure, exploring the interactive behavior of users and items with time and order information. Furthermore, we design a Dynamic Graph Recommendation Network to extract user's preferences from the dynamic graph. Consequently, the next-item prediction task in sequential recommendation is converted into a link prediction between the user node and the item node in a dynamic graph. Extensive experiments on four public benchmarks show that DGSR outperforms several state-of-the-art methods. Further studies demonstrate the rationality and effectiveness of modeling user sequences through a dynamic graph. © 1989-2012 IEEE.",dynamic collaborative signals; dynamic graph neural networks; Sequential recommendation,Graph neural networks; Graph theory; Job analysis; Recommender systems; User profile; Collaboration; Collaborative signal; Dynamic collaborative signal; Dynamic graph; Dynamic graph neural network; Graph neural networks; Predictive models; Sequential recommendation; Task analysis; Deep learning,Article,Final,All Open Access; Bronze Open Access; Green Open Access,Scopus,2-s2.0-85124820831
44,Hu F.; Zhu Y.; Wu S.; Huang W.; Wang L.; Tan T.,"Hu, Fenyu (57219498672); Zhu, Yanqiao (57218708975); Wu, Shu (36245362600); Huang, Weiran (57219687083); Wang, Liang (57218666547); Tan, Tieniu (7402022125)",57219498672; 57218708975; 36245362600; 57219687083; 57218666547; 7402022125,GraphAIR: Graph representation learning with neighborhood aggregation and interaction,2021,Pattern Recognition,112,,107745,,,,34,10.1016/j.patcog.2020.107745,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85095986071&doi=10.1016%2fj.patcog.2020.107745&partnerID=40&md5=198b0153bb26e58ce8b984746059e6fc,"Center for Research on Intelligent Perception and Computing, Institute of Automation, Chinese Academy of Sciences, China; School of Artificial Intelligence, University of Chinese Academy of Sciences, China; The Chinese University of Hong Kong, Hong Kong","Hu F., Center for Research on Intelligent Perception and Computing, Institute of Automation, Chinese Academy of Sciences, China, School of Artificial Intelligence, University of Chinese Academy of Sciences, China; Zhu Y., Center for Research on Intelligent Perception and Computing, Institute of Automation, Chinese Academy of Sciences, China, School of Artificial Intelligence, University of Chinese Academy of Sciences, China; Wu S., Center for Research on Intelligent Perception and Computing, Institute of Automation, Chinese Academy of Sciences, China, School of Artificial Intelligence, University of Chinese Academy of Sciences, China; Huang W., The Chinese University of Hong Kong, Hong Kong; Wang L., Center for Research on Intelligent Perception and Computing, Institute of Automation, Chinese Academy of Sciences, China, School of Artificial Intelligence, University of Chinese Academy of Sciences, China; Tan T., Center for Research on Intelligent Perception and Computing, Institute of Automation, Chinese Academy of Sciences, China, School of Artificial Intelligence, University of Chinese Academy of Sciences, China","Graph representation learning is of paramount importance for a variety of graph analytical tasks, ranging from node classification to community detection. Recently, graph convolutional networks (GCNs) have been successfully applied for graph representation learning. These GCNs generate node representation by aggregating features from the neighborhoods, which follows the “neighborhood aggregation” scheme. In spite of having achieved promising performance on various tasks, existing GCN-based models have difficulty in well capturing complicated non-linearity of graph data. In this paper, we first theoretically prove that coefficients of the neighborhood interacting terms are relatively small in current models, which explains why GCNs barely outperforms linear models. Then, in order to better capture the complicated non-linearity of graph data, we present a novel GraphAIR framework which models the neighborhood interaction in addition to neighborhood aggregation. Comprehensive experiments conducted on benchmark tasks including node classification and link prediction using public datasets demonstrate the effectiveness of the proposed method. © 2020 Elsevier Ltd",Graph neural networks; Graph representation learning; Link prediction; Neighborhood aggregation; Neighborhood interaction; Node classification,Classification (of information); Convolutional neural networks; Knowledge representation; Community detection; Convolutional networks; Current models; Graph data; Graph representation; Link prediction; Neighborhood interactions; Graph structures,Article,Final,All Open Access; Green Open Access,Scopus,2-s2.0-85095986071
45,Ye Y.; Ji S.,"Ye, Yang (57219508930); Ji, Shihao (57207105926)",57219508930; 57207105926,Sparse Graph Attention Networks,2023,IEEE Transactions on Knowledge and Data Engineering,35,1,,905,916,11,34,10.1109/TKDE.2021.3072345,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85104197112&doi=10.1109%2fTKDE.2021.3072345&partnerID=40&md5=d81e0c27f76e78692714760029a41f0c,"Georgia State University, Department of Computer Science, Atlanta, 30303, GA, United States","Ye Y., Georgia State University, Department of Computer Science, Atlanta, 30303, GA, United States; Ji S., Georgia State University, Department of Computer Science, Atlanta, 30303, GA, United States","Graph Neural Networks (GNNs) have proved to be an effective representation learning framework for graph-structured data, and have achieved state-of-the-art performance on many practical predictive tasks, such as node classification, link prediction and graph classification. Among the variants of GNNs, Graph Attention Networks (GATs) learn to assign dense attention coefficients over all neighbors of a node for feature aggregation, and improve the performance of many graph learning tasks. However, real-world graphs are often very large and noisy, and GATs are prone to overfitting if not regularized properly. Even worse, the local aggregation mechanism of GATs may fail on disassortative graphs, where nodes within local neighborhood provide more noise than useful information for feature aggregation. In this paper, we propose Sparse Graph Attention Networks (SGATs) that learn sparse attention coefficients under an L0-norm regularization, and the learned sparse attentions are then used for all GNN layers, resulting in an edge-sparsified graph. By doing so, we can identify noisy/task-irrelevant edges, and thus perform feature aggregation on most informative neighbors. Extensive experiments on synthetic and real-world (assortative and disassortative) graph learning benchmarks demonstrate the superior performance of SGATs. In particular, SGATs can remove about 50-80 percent edges from large assortative graphs, such as PPI and Reddit, while retaining similar classification accuracies. On disassortative graphs, SGATs prune majority of noisy edges and outperform GATs in classification accuracies by significant margins. Furthermore, the removed edges can be interpreted intuitively and quantitatively. To the best of our knowledge, this is the first graph learning algorithm that shows significant redundancies in graphs and edge-sparsified graphs can achieve similar (on assortative graphs) or sometimes higher (on disassortative graphs) predictive performances than original graphs. Our code is available at https://github.com/Yangyeeee/SGAT. © 1989-2012 IEEE.",attention networks; Graph neural networks; sparsity learning,E-learning; Graph neural networks; Graph theory; Graphic methods; Job analysis; Learning algorithms; Personnel training; Redundancy; Attention network; Graph neural networks; Graph structured data; Learning frameworks; Noise measurements; Performance; Social networking (online); Sparse graphs; Sparsity learning; Task analysis; Benchmarking,Article,Final,All Open Access; Green Open Access,Scopus,2-s2.0-85104197112
46,Dai J.; Wu Y.; Gao Z.; Jia Y.,"Dai, Jindou (57223723987); Wu, Yuwei (56039724700); Gao, Zhi (57204786582); Jia, Yunde (7401503740)",57223723987; 56039724700; 57204786582; 7401503740,A Hyperbolic-to-Hyperbolic Graph Convolutional Network,2021,Proceedings of the IEEE Computer Society Conference on Computer Vision and Pattern Recognition,,,,154,163,9,33,10.1109/CVPR46437.2021.00022,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85119178771&doi=10.1109%2fCVPR46437.2021.00022&partnerID=40&md5=38265006f12e0f8c05ef0e2ba370311b,"Laboratory of Intelligent Information Technology, School of Computer Science, Beijing Institute of Technology (BIT), Beijing, 100081, China","Dai J., Laboratory of Intelligent Information Technology, School of Computer Science, Beijing Institute of Technology (BIT), Beijing, 100081, China; Wu Y., Laboratory of Intelligent Information Technology, School of Computer Science, Beijing Institute of Technology (BIT), Beijing, 100081, China; Gao Z., Laboratory of Intelligent Information Technology, School of Computer Science, Beijing Institute of Technology (BIT), Beijing, 100081, China; Jia Y., Laboratory of Intelligent Information Technology, School of Computer Science, Beijing Institute of Technology (BIT), Beijing, 100081, China","Hyperbolic graph convolutional networks (GCNs) demonstrate powerful representation ability to model graphs with hierarchical structure. Existing hyperbolic GCNs resort to tangent spaces to realize graph convolution on hyperbolic manifolds, which is inferior because tangent space is only a local approximation of a manifold. In this paper, we propose a hyperbolic-to-hyperbolic graph convolutional network (H2H-GCN) that directly works on hyperbolic manifolds. Specifically, we developed a manifold-preserving graph convolution that consists of a hyperbolic feature transformation and a hyperbolic neighborhood aggregation. The hyperbolic feature transformation works as linear transformation on hyperbolic manifolds. It ensures the transformed node representations still lie on the hyperbolic manifold by imposing the orthogonal constraint on the transformation sub-matrix. The hyperbolic neighborhood aggregation updates each node representation via the Einstein midpoint. The H2H-GCN avoids the distortion caused by tangent space approximations and keeps the global hyperbolic structure. Extensive experiments show that the H2H-GCN achieves substantial improvements on the link prediction, node classification, and graph classification tasks. © 2021 IEEE",,Computer vision; Convolutional neural networks; Graph neural networks; Linear transformations; Convolutional networks; Feature transformations; Hierarchical structures; Hyperbolic features; Hyperbolic graphs; Local approximation; Neighbourhood; Orthogonal constraints; Submatrix; Tangent space; Convolution,Conference paper,Final,All Open Access; Green Open Access,Scopus,2-s2.0-85119178771
47,Peng L.; Hu R.; Kong F.; Gan J.; Mo Y.; Shi X.; Zhu X.,"Peng, Liang (57197812577); Hu, Rongyao (57190387750); Kong, Fei (57345516200); Gan, Jiangzhang (57202938045); Mo, Yujie (57565419300); Shi, Xiaoshuang (56029222900); Zhu, Xiaofeng (55643999665)",57197812577; 57190387750; 57345516200; 57202938045; 57565419300; 56029222900; 55643999665,Reverse Graph Learning for Graph Neural Network,2022,IEEE Transactions on Neural Networks and Learning Systems,,,,,,,33,10.1109/TNNLS.2022.3161030,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85127754954&doi=10.1109%2fTNNLS.2022.3161030&partnerID=40&md5=71da6938ebe80d993c7e37d073cf673f,"Center for Future Media, and the School of Computer Science and Engineering, University of Electronic Science and Technology of China, Chengdu 611731, China.; Center for Future Media, and the School of Computer Science and Technology, University of Electronic Science and Technology of China, Chengdu 611731, China, and also with the School of Mathematical and Computational Sciences, Massey University at Auckland, Auckland 0745, New Zealand.; School of Computer Science and Engineering, University of Electronic Science and Technology of China, Chengdu 611731, China, and also with the Shenzhen Institute for Advanced Study, University of Electronic Science and Technology of China, Shenzhen 518000, China","Peng L., Center for Future Media, and the School of Computer Science and Engineering, University of Electronic Science and Technology of China, Chengdu 611731, China.; Hu R., Center for Future Media, and the School of Computer Science and Technology, University of Electronic Science and Technology of China, Chengdu 611731, China, and also with the School of Mathematical and Computational Sciences, Massey University at Auckland, Auckland 0745, New Zealand.; Kong F., Center for Future Media, and the School of Computer Science and Engineering, University of Electronic Science and Technology of China, Chengdu 611731, China.; Gan J., Center for Future Media, and the School of Computer Science and Technology, University of Electronic Science and Technology of China, Chengdu 611731, China, and also with the School of Mathematical and Computational Sciences, Massey University at Auckland, Auckland 0745, New Zealand.; Mo Y., Center for Future Media, and the School of Computer Science and Engineering, University of Electronic Science and Technology of China, Chengdu 611731, China.; Shi X., Center for Future Media, and the School of Computer Science and Engineering, University of Electronic Science and Technology of China, Chengdu 611731, China.; Zhu X., School of Computer Science and Engineering, University of Electronic Science and Technology of China, Chengdu 611731, China, and also with the Shenzhen Institute for Advanced Study, University of Electronic Science and Technology of China, Shenzhen 518000, China","Graph neural networks (GNNs) conduct feature learning by taking into account the local structure preservation of the data to produce discriminative features, but need to address the following issues, i.e., 1) the initial graph containing faulty and missing edges often affect feature learning and 2) most GNN methods suffer from the issue of out-of-example since their training processes do not directly generate a prediction model to predict unseen data points. In this work, we propose a reverse GNN model to learn the graph from the intrinsic space of the original data points as well as to investigate a new out-of-sample extension method. As a result, the proposed method can output a high-quality graph to improve the quality of feature learning, while the new method of out-of-sample extension makes our reverse GNN method available for conducting supervised learning and semi-supervised learning. Experimental results on real-world datasets show that our method outputs competitive classification performance, compared to state-of-the-art methods, in terms of semi-supervised node classification, out-of-sample extension, random edge attack, link prediction, and image retrieval. IEEE",Data models; Graph learning; graph neural network; Graph neural networks; Image edge detection; out-of-sample extension; Predictive models; Representation learning; robust learning.; Task analysis; Training,Classification (of information); Edge detection; Forecasting; Job analysis; Supervised learning; Graph learning; Graph neural networks; Image edge detection; Out-of-sample extension; Predictive models; Representation learning; Robust learning; Robust learning.; Task analysis; Graph neural networks,Article,Article in press,,Scopus,2-s2.0-85127754954
48,Liu Z.; Huang C.; Yu Y.; Dong J.,"Liu, Zhijun (57219876963); Huang, Chao (57051644000); Yu, Yanwei (12763209400); Dong, Junyu (22634069200)",57219876963; 57051644000; 12763209400; 22634069200,Motif-preserving dynamic attributed network embedding,2021,"The Web Conference 2021 - Proceedings of the World Wide Web Conference, WWW 2021",,,,1629,1638,9,32,10.1145/3442381.3449821,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85107940011&doi=10.1145%2f3442381.3449821&partnerID=40&md5=cb9555b621e22a24193bf66523f3d376,"Yantai University, China; JD Finance America Corporation, United States; Ocean University of China, China","Liu Z., Yantai University, China; Huang C., JD Finance America Corporation, United States; Yu Y., Ocean University of China, China; Dong J., Ocean University of China, China","Network embedding has emerged as a new learning paradigm to embed complex network into a low-dimensional vector space while preserving node proximities in both network structures and properties. It advances various network mining tasks, ranging from link prediction to node classification. However, most existing works primarily focus on static networks while many networks in real-life evolve over time with addition/deletion of links and nodes, naturally with associated attribute evolution. In this work, we present Motif-preserving Temporal Shift Network (MTSN), a novel dynamic network embedding framework that simultaneously models the local high-order structures and temporal evolution for dynamic attributed networks. Specifically, MTSN learns node representations by stacking the proposed TIME module to capture both local high-order structural proximities and node attributes by motif-preserving encoder and temporal dynamics by temporal shift operation in a dynamic attributed network. Finally, we perform extensive experiments on four real-world network datasets to demonstrate the superiority of MTSN against state-of-the-art network embedding baselines in terms of both effectiveness and efficiency. The source code of our method is available at: https://github.com/ZhijunLiu95/MTSN. Â© 2021 ACM.",Dynamic networks; Graph neural networks; Network embedding,Complex networks; Embeddings; Vector spaces; World Wide Web; Attribute evolutions; Effectiveness and efficiencies; High-order structure; Learning paradigms; Network embedding; Network structures; Real-world networks; Temporal evolution; HTTP,Conference paper,Final,,Scopus,2-s2.0-85107940011
49,Xia L.; Liang Y.; Zheng P.; Leng J.,"Xia, Liqiao (57223908515); Liang, Yongshi (58030671300); Zheng, Pai (56352424300); Leng, Jiewu (57188970257)",57223908515; 58030671300; 56352424300; 57188970257,Maintenance planning recommendation of complex industrial equipment based on knowledge graph and graph neural network,2023,Reliability Engineering and System Safety,232,,109068,,,,31,10.1016/j.ress.2022.109068,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85145964190&doi=10.1016%2fj.ress.2022.109068&partnerID=40&md5=79aa3808b45f16d4ab3a61930f22bcd8,"Department of Industrial and Systems Engineering, The Hong Kong Polytechnic University, Hong Kong; State Key Laboratory of Ultra-precision Machining Technology, Department of Industrial Systems and Engineering, The Hong Kong Polytechnic University, Hong Kong; State Key Laboratory of Precision Electronic Manufacturing Technology and Equipment, Guangdong University of Technology, Guangzhou, China","Xia L., Department of Industrial and Systems Engineering, The Hong Kong Polytechnic University, Hong Kong; Liang Y., Department of Industrial and Systems Engineering, The Hong Kong Polytechnic University, Hong Kong; Zheng P., Department of Industrial and Systems Engineering, The Hong Kong Polytechnic University, Hong Kong, State Key Laboratory of Ultra-precision Machining Technology, Department of Industrial Systems and Engineering, The Hong Kong Polytechnic University, Hong Kong; Leng J., State Key Laboratory of Precision Electronic Manufacturing Technology and Equipment, Guangdong University of Technology, Guangzhou, China","Maintenance planning is a significant part of predictive maintenance, which involves task planning, resource scheduling, and prevention. With large-scale sensor systems in modern factories, much data will be captured during monitoring and maintenance of complex industrial equipment. Accumulated data facilitates maintenance planning becomes more thorough and timely. Recently, a knowledge graph (KG) was offered to handle large-scale, unorganized maintenance data semantically, resulting in better data usage. Some prior studies have utilized KG for maintenance planning with semantic searching or graph structure-based algorithms, nevertheless neglecting the prediction of potential linkage. To fill this gap, a maintenance-oriented KG is established firstly based on a well-defined domain-specific ontology schema and accumulated maintenance data. Then, an Attention-Based Compressed Relational Graph Convolutional Network is proposed to predict potential solutions and explain fault in maintenance tasks. Lastly, a maintenance case of oil drilling equipment is carried out, where the proposed model is compared with other cutting-edge models to demonstrate its effectiveness in link prediction. This research is anticipated to shed light on future adoption of KG in maintenance planning recommendations. © 2022 Elsevier Ltd",Graph neural network; Knowledge graph; Link prediction; Maintenance management; Predictive maintenance,Complex networks; Construction equipment; Forecasting; Gas industry; Knowledge graph; Semantics; Graph neural networks; Industrial equipment; Knowledge graphs; Large-scale sensors; Link prediction; Maintenance management; Maintenance planning; Predictive maintenance; Resource-scheduling; Task planning; Maintenance,Article,Final,,Scopus,2-s2.0-85145964190
50,Hou Y.; Chen H.; Li C.; Cheng J.; Yang M.-C.,"Hou, Yifan (57210124459); Chen, Hongzhi (57195552823); Li, Changji (57210118136); Cheng, James (55492635700); Yang, Ming-Chang (55786573800)",57210124459; 57195552823; 57210118136; 55492635700; 55786573800,A representation learning framework for property graphs,2019,Proceedings of the ACM SIGKDD International Conference on Knowledge Discovery and Data Mining,,,,65,73,8,31,10.1145/3292500.3330948,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85071161675&doi=10.1145%2f3292500.3330948&partnerID=40&md5=e803d246c03826b4ad4335310dea0d19,"Department of Computer Science and Engineering, Chinese University of Hong Kong, Hong Kong","Hou Y., Department of Computer Science and Engineering, Chinese University of Hong Kong, Hong Kong; Chen H., Department of Computer Science and Engineering, Chinese University of Hong Kong, Hong Kong; Li C., Department of Computer Science and Engineering, Chinese University of Hong Kong, Hong Kong; Cheng J., Department of Computer Science and Engineering, Chinese University of Hong Kong, Hong Kong; Yang M.-C., Department of Computer Science and Engineering, Chinese University of Hong Kong, Hong Kong","Representation learning on graphs, also called graph embedding, has demonstrated its significant impact on a series of machine learning applications such as classification, prediction and recommendation. However, existing work has largely ignored the rich information contained in the properties (or attributes) of both nodes and edges of graphs in modern applications, e.g., those represented by property graphs. To date, most existing graph embedding methods either focus on plain graphs with only the graph topology, or consider properties on nodes only. We propose PGE, a graph representation learning framework that incorporates both node and edge properties into the graph embedding procedure. PGE uses node clustering to assign biases to differentiate neighbors of a node and leverages multiple data-driven matrices to aggregate the property information of neighbors sampled based on a biased strategy. PGE adopts the popular inductive model for neighborhood aggregation. We provide detailed analyses on the efficacy of our method and validate the performance of PGE by showing how PGE achieves better embedding results than the state-of-the-art graph embedding methods on benchmark applications such as node classification and link prediction over real-world datasets. © 2019 Association for Computing Machinery.",Graph embedding; Graph neural networks; Property graphs; Representation learning,Benchmarking; Classification (of information); Data mining; Embeddings; Graphic methods; Benchmark applications; Graph embeddings; Graph neural networks; Graph representation; Machine learning applications; Modern applications; Property graphs; Representation learning; Graph theory,Conference paper,Final,All Open Access; Green Open Access,Scopus,2-s2.0-85071161675
51,Li W.; Ni L.; Wang J.; Wang C.,"Li, Weimin (56113739500); Ni, Lin (57883707800); Wang, Jianjia (57192086170); Wang, Can (57209214867)",56113739500; 57883707800; 57192086170; 57209214867,Collaborative representation learning for nodes and relations via heterogeneous graph neural network,2022,Knowledge-Based Systems,255,,109673,,,,31,10.1016/j.knosys.2022.109673,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85137656460&doi=10.1016%2fj.knosys.2022.109673&partnerID=40&md5=802f3d24d88b35c6591c8553d3c4f998,"School of Computer Engineering and Science, Shanghai University, Shanghai, China; School of Information and Communication Technology, Griffith University, Australia","Li W., School of Computer Engineering and Science, Shanghai University, Shanghai, China; Ni L., School of Computer Engineering and Science, Shanghai University, Shanghai, China; Wang J., School of Computer Engineering and Science, Shanghai University, Shanghai, China; Wang C., School of Information and Communication Technology, Griffith University, Australia","Heterogeneous graphs, which consist of multiple types of nodes and edges, are highly suitable for characterizing real-world complex systems. In recent years, due to their strong capability of capturing rich semantics, heterogeneous graph neural networks (HGNNs) have proven to be a powerful technique for representation learning on heterogeneous graphs. However, most of the existing HGNNs only focus on learning node representations and ignore the learning of relation representations, which are complementary to node representations. To address this limitation, we propose a new HGNN model with Collaborative Representation Learning for Nodes and Relations (named CoNR) for link prediction task in this paper. Collaborative learning means that node representations and relation representations participate in and affect each other's learning process. Specifically, node representations are obtained through a delicate two-step attention mechanism incorporating relation representations that can hierarchically aggregate information within one relation and across different relations. For relation representations, a relation encoder based on node information is designed to encode node representations into relation representations. Therefore, in this framework, node representations and relation representations are mutually updated in a layer-wise manner and work together to facilitate the downstream tasks better. Extensive experimental results on different datasets show the excellent performance of the proposed CoNR. © 2022 Elsevier B.V.",Collaborative; Graph neural networks; Heterogeneous graph; Representation learning,Graph structures; Graph theory; Learning systems; Semantics; Collaborative; Collaborative learning; Collaborative representations; Graph neural networks; Heterogeneous graph; Link prediction; Neural network model; Prediction tasks; Real-world; Representation learning; Graph neural networks,Article,Final,,Scopus,2-s2.0-85137656460
52,Li P.; Wang Y.; Zhao H.; Hong P.; Liu H.,"Li, Peizhao (57204199911); Wang, Yifei (57207005080); Zhao, Han (57001574800); Hong, Pengyu (14630423200); Liu, Hongfu (54389423300)",57204199911; 57207005080; 57001574800; 14630423200; 54389423300,ON DYADIC FAIRNESS: EXPLORING AND MITIGATING BIAS IN GRAPH CONNECTIONS,2021,ICLR 2021 - 9th International Conference on Learning Representations,,,,,,,30,,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85150227492&partnerID=40&md5=ae3a64cda96da9d8e435ff80dc445847,"Brandeis University, United States; University of Illinois at Urbana-Champaign, United States","Li P., Brandeis University, United States; Wang Y., Brandeis University, United States; Zhao H., University of Illinois at Urbana-Champaign, United States; Hong P., Brandeis University, United States; Liu H., Brandeis University, United States","Disparate impact has raised serious concerns in machine learning applications and its societal impacts. In response to the need of mitigating discrimination, fairness has been regarded as a crucial property in algorithmic designs. In this work, we study the problem of disparate impact on graph-structured data. Specifically, we focus on dyadic fairness, which articulates a fairness concept that a predictive relationship between two instances should be independent of the sensitive attributes. Based on this, we theoretically relate the graph connections to dyadic fairness on link predictive scores in learning graph neural networks, and reveal that regulating weights on existing edges in a graph contributes to dyadic fairness conditionally. Subsequently, we propose our algorithm, FairAdj, to empirically learn a fair adjacency matrix with proper graph structural constraints for fair link prediction, and in the meanwhile preserve predictive accuracy as much as possible. Empirical validation demonstrates that our method delivers effective dyadic fairness in terms of various statistics, and at the same time enjoys a favorable fairness-utility tradeoff. © 2021 ICLR 2021 - 9th International Conference on Learning Representations. All rights reserved.",,Algorithmic design; Graph neural networks; Graph structured data; Learn+; Learning graphs; Machine learning applications; Predictive relationships; Property; Sensitive attribute; Societal impacts; Graph neural networks,Conference paper,Final,,Scopus,2-s2.0-85150227492
53,Zhang T.; Xiong Y.; Zhang J.; Zhang Y.; Jiao Y.; Zhu Y.,"Zhang, Tianqi (57219877007); Xiong, Yun (16044247100); Zhang, Jiawei (55954167400); Zhang, Yao (57195409000); Jiao, Yizhu (57211937974); Zhu, Yangyong (16178392400)",57219877007; 16044247100; 55954167400; 57195409000; 57211937974; 16178392400,CommDGI: Community Detection Oriented Deep Graph Infomax,2020,"International Conference on Information and Knowledge Management, Proceedings",,,,1843,1852,9,30,10.1145/3340531.3412042,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85095862709&doi=10.1145%2f3340531.3412042&partnerID=40&md5=cc249c58106d14bfa774ed019526fe32,"Fudan University, Shanghai, China; Fudan University and Shanghai Institute for Advanced Communication and Data Science, Shanghai, China","Zhang T., Fudan University, Shanghai, China; Xiong Y., Fudan University and Shanghai Institute for Advanced Communication and Data Science, Shanghai, China; Zhang J., Fudan University, Shanghai, China; Zhang Y., Fudan University, Shanghai, China; Jiao Y., Fudan University, Shanghai, China; Zhu Y., Fudan University and Shanghai Institute for Advanced Communication and Data Science, Shanghai, China","Graph Neural Networks(GNNs), like GCN and GAT, have achieved great success in a number of supervised or semi-supervised tasks including node classification and link prediction. These existing graph neural networks can effectively encode neighborhood information of graph nodes through their message aggregating mechanisms. However, there are some unsupervised and structure-related tasks like community detection, which is a fundamental problem in network analysis that finds densely-connected groups of nodes and separates them from others in graphs. It is still difficult for these general-purposed GNNs to learn the needed structural information in these particular problems. To overcome the shortcomings of general-purposed graph representation learning methods, we propose the Community Deep Graph Infomax (CommDGI), a graph neural network designed to handle community detection problems. Inspired by the success of deep graph infomax in self-supervised graph learning, we design a novel mutual information mechanism to capture neighborhood as well as community information in graphs. A trainable clustering layer is employed to learn the community partition in an end-to-end manner. Disentangled representation learning is applied in our graph neural network so that the model can improve interpretability and generalization. Throughout the whole learning process, joint optimization is applied to learn the community-related node representations. The experimental results show that our algorithm outperforms state-of-the-art community detection methods. © 2020 ACM.",community detection; graph clustering; graph neural networks; self-supervised learning,Graph structures; Graph theory; Knowledge management; Learning systems; Population dynamics; Community detection; Graph neural networks; Graph representation; In-network analysis; Joint optimization; Mutual informations; Neighborhood information; Structural information; Neural networks,Conference paper,Final,,Scopus,2-s2.0-85095862709
54,Deng Q.; Wang K.; Zhao M.; Zou Z.; Wu R.; Tao J.; Fan C.; Chen L.,"Deng, Qilin (57219876307); Wang, Kai (57219640326); Zhao, Minghao (57200560816); Zou, Zhene (57219876992); Wu, Runze (57001915300); Tao, Jianrong (57203392720); Fan, Changjie (57203398908); Chen, Liang (57188872930)",57219876307; 57219640326; 57200560816; 57219876992; 57001915300; 57203392720; 57203398908; 57188872930,Personalized Bundle Recommendation in Online Games,2020,"International Conference on Information and Knowledge Management, Proceedings",,,,2381,2388,7,30,10.1145/3340531.3412734,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85095864343&doi=10.1145%2f3340531.3412734&partnerID=40&md5=9f9371041d00c7efb9ce3b581f215530,"Fuxi Ai Lab, NetEase Games, Hangzhou, China; Sun Yat-Sen University, Guangzhou, China","Deng Q., Fuxi Ai Lab, NetEase Games, Hangzhou, China; Wang K., Fuxi Ai Lab, NetEase Games, Hangzhou, China; Zhao M., Fuxi Ai Lab, NetEase Games, Hangzhou, China; Zou Z., Fuxi Ai Lab, NetEase Games, Hangzhou, China; Wu R., Fuxi Ai Lab, NetEase Games, Hangzhou, China; Tao J., Fuxi Ai Lab, NetEase Games, Hangzhou, China; Fan C., Fuxi Ai Lab, NetEase Games, Hangzhou, China; Chen L., Sun Yat-Sen University, Guangzhou, China","In business domains, bundling is one of the most important marketing strategies to conduct product promotions, which is commonly used in online e-commerce and offline retailers. Existing recommender systems mostly focus on recommending individual items that users may be interested in. In this paper, we target at a practical but less explored recommendation problem named bundle recommendation, which aims to offer a combination of items to users. To tackle this specific recommendation problem in the context of the virtual mall in online games, we formalize it as a link prediction problem on a user-item-bundle tripartite graph constructed from the historical interactions, and solve it with a neural network model that can learn directly on the graph-structure data. Extensive experiments on three public datasets and one industrial game dataset demonstrate the effectiveness of the proposed method. Further, the bundle recommendation model has been deployed in production for more than one year in a popular online game developed by Netease Games, and the launch of the model yields more than 60% improvement on conversion rate of bundles, and a relative improvement of more than 15% on gross merchandise volume (GMV). © 2020 ACM.",bundle recommendation; deep learning; graph neural networks; link prediction; neural networks; recommender system,Electronic commerce; Graph structures; Knowledge management; Marketing; Recommender systems; Business domain; Conversion rates; Link prediction; Marketing strategy; Neural network model; Offline retailers; On-line games; Tripartite graphs; Social networking (online),Conference paper,Final,All Open Access; Green Open Access,Scopus,2-s2.0-85095864343
55,Zhang X.; He Y.; Brugnone N.; Perlmutter M.; Hirn M.,"Zhang, Xitong (57214694221); He, Yixuan (57223817636); Brugnone, Nathan (57215610023); Perlmutter, Michael (56372340300); Hirn, Matthew (35198171000)",57214694221; 57223817636; 57215610023; 56372340300; 35198171000,MagNet: A Neural Network for Directed Graphs,2021,Advances in Neural Information Processing Systems,32,,,27003,27015,12,29,,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85125761966&partnerID=40&md5=3287dc1dd9c908aee2ba4ed3f921a25b,"Michigan State University, Department of Computational Mathematics, Science and Engineering, East Lansing, MI, United States; University of Oxford, Department of Statistics, Oxford, United Kingdom; Michigan State University, Department of Community Sustainability, East Lansing, MI, United States; University of California, Los Angeles, Department of Mathematics, Los Angeles, CA, United States; Michigan State University, Department of Mathematics, East Lansing, MI, United States; Michigan State University, Center for Quantum Computing, Science and Engineering, East Lansing, MI, United States","Zhang X., Michigan State University, Department of Computational Mathematics, Science and Engineering, East Lansing, MI, United States; He Y., University of Oxford, Department of Statistics, Oxford, United Kingdom; Brugnone N., Michigan State University, Department of Computational Mathematics, Science and Engineering, East Lansing, MI, United States, Michigan State University, Department of Community Sustainability, East Lansing, MI, United States; Perlmutter M., University of California, Los Angeles, Department of Mathematics, Los Angeles, CA, United States; Hirn M., Michigan State University, Department of Computational Mathematics, Science and Engineering, East Lansing, MI, United States, Michigan State University, Department of Mathematics, East Lansing, MI, United States, Michigan State University, Center for Quantum Computing, Science and Engineering, East Lansing, MI, United States","The prevalence of graph-based data has spurred the rapid development of graph neural networks (GNNs) and related machine learning algorithms. Yet, despite the many datasets naturally modeled as directed graphs, including citation, website, and traffic networks, the vast majority of this research focuses on undirected graphs. In this paper, we propose MagNet, a GNN for directed graphs based on a complex Hermitian matrix known as the magnetic Laplacian. This matrix encodes undirected geometric structure in the magnitude of its entries and directional information in their phase. A “charge” parameter attunes spectral information to variation among directed cycles. We apply our network to a variety of directed graph node classification and link prediction tasks showing that MagNet performs well on all tasks and that its performance exceeds all other methods on a majority of such tasks. The underlying principles of MagNet are such that it can be adapted to other GNN architectures. © 2021 Neural information processing systems foundation. All rights reserved.",,Graph neural networks; Graphic methods; Learning algorithms; Machine learning; Magnets; Citation networks; Graph neural networks; Graph-based; Hermitian matrices; Laplacians; Machine learning algorithms; Neural-networks; Research focus; Traffic networks; Undirected graph; Directed graphs,Conference paper,Final,,Scopus,2-s2.0-85125761966
56,Roddenberry T.M.; Segarra S.,"Roddenberry, T. Mitchell (57216367080); Segarra, Santiago (23991716100)",57216367080; 23991716100,HodgeNet: Graph Neural Networks for Edge Data,2019,"Conference Record - Asilomar Conference on Signals, Systems and Computers",2019-November,,9049000,220,224,4,28,10.1109/IEEECONF44664.2019.9049000,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85083300635&doi=10.1109%2fIEEECONF44664.2019.9049000&partnerID=40&md5=d531a5cb3a5bdea73dac02dc0e299938,"Rice University, Department of Electrical and Computer Engineering, United States","Roddenberry T.M., Rice University, Department of Electrical and Computer Engineering, United States; Segarra S., Rice University, Department of Electrical and Computer Engineering, United States","Networks and network processes have emerged as powerful tools for modeling social interactions, disease propagation, and a variety of additional dynamics driven by relational structures. Recently, neural networks have been generalized to process data on graphs, thus being able to learn from the aforementioned network processes achieving cutting-edge performance in traditional tasks such as node classification and link prediction. However, these methods have all been formulated in a way suited only to data on the nodes of a graph. The application of these techniques to data supported on the edges of a graph, namely flow signals, has not been explored in detail. To bridge this gap, we propose the use of the so-called Hodge Laplacian combined with graph neural network architectures for the analysis of flow data. Specifically, we apply two graph neural network architectures to solve the problems of flow interpolation and source localization. © 2019 IEEE.",,Backpropagation; Computer circuits; Data flow graphs; Neural networks; Signal flow graphs; Disease propagation; Graph neural networks; Hodge Laplacian; Link prediction; Network process; Relational structures; Social interactions; Source localization; Network architecture,Conference paper,Final,All Open Access; Green Open Access,Scopus,2-s2.0-85083300635
57,Wu Y.; Ma K.; Cai Z.; Jin T.; Li B.; Zheng C.; Cheng J.; Yu F.,"Wu, Yidi (57208576813); Ma, Kaihao (57219619485); Cai, Zhenkun (57204766727); Jin, Tatiana (57208581827); Li, Boyang (57226853612); Zheng, Chenguang (57789895100); Cheng, James (55492635700); Yu, Fan (57206668451)",57208576813; 57219619485; 57204766727; 57208581827; 57226853612; 57789895100; 55492635700; 57206668451,Seastar: Vertex-centric programming for graph neural networks,2021,EuroSys 2021 - Proceedings of the 16th European Conference on Computer Systems,,,3456247,359,375,16,28,10.1145/3447786.3456247,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85105309749&doi=10.1145%2f3447786.3456247&partnerID=40&md5=511cb3edc100e827cb0900527683e21d,"The Chinese University of Hong Kong, Hong Kong; Huawei Technologies Co. Ltd","Wu Y., The Chinese University of Hong Kong, Hong Kong; Ma K., The Chinese University of Hong Kong, Hong Kong; Cai Z., The Chinese University of Hong Kong, Hong Kong; Jin T., The Chinese University of Hong Kong, Hong Kong; Li B., The Chinese University of Hong Kong, Hong Kong; Zheng C., The Chinese University of Hong Kong, Hong Kong; Cheng J., The Chinese University of Hong Kong, Hong Kong; Yu F., Huawei Technologies Co. Ltd","Graph neural networks (GNNs) have achieved breakthrough performance in graph analytics such as node classification, link prediction and graph clustering. Many GNN training frameworks have been developed, but they are usually designed as a set of manually written, GNN-specific operators plugged into existing deep learning systems, which incurs high memory consumption, poor data locality, and large semantic gap between algorithm design and implementation. This paper proposes the Seastar system, which presents a vertex-centric programming model for GNN training on GPU and provides idiomatic python constructs to enable easy development of novel homogeneous and heterogeneous GNN models. We also propose novel optimizations to produce highly efficient fused GPU kernels for forward and backward passes in GNN training. Compared with the state-of-the art GNN systems, DGL and PyG, Seastar achieves better usability, up to 2 and 8 times less memory consumption, and 14 and 3 times faster execution, respectively. © 2021 ACM.",Deep learning systems; Graph neural networks,Deep learning; Graph theory; Learning systems; Personnel training; Semantics; Breakthrough performance; Forward-and-backward; Graph neural networks; Memory consumption; Programming models; Specific operators; State of the art; Training framework; Neural networks,Conference paper,Final,,Scopus,2-s2.0-85105309749
58,Yun S.; Kim S.; Lee J.; Kang J.; Kim H.J.,"Yun, Seongjun (57215719303); Kim, Seoyoon (57219876436); Lee, Junhyun (57203927878); Kang, Jaewoo (8914056400); Kim, Hyunwoo J. (56336378000)",57215719303; 57219876436; 57203927878; 8914056400; 56336378000,Neo-GNNs: Neighborhood Overlap-aware Graph Neural Networks for Link Prediction,2021,Advances in Neural Information Processing Systems,17,,,13683,13694,11,27,,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85132029527&partnerID=40&md5=a743f9924b72ea0a08361b48d7a3522e,"Department of Computer Science and Engineering, Korea University, South Korea","Yun S., Department of Computer Science and Engineering, Korea University, South Korea; Kim S., Department of Computer Science and Engineering, Korea University, South Korea; Lee J., Department of Computer Science and Engineering, Korea University, South Korea; Kang J., Department of Computer Science and Engineering, Korea University, South Korea; Kim H.J., Department of Computer Science and Engineering, Korea University, South Korea","Graph Neural Networks (GNNs) have been widely applied to various fields for learning over graph-structured data. They have shown significant improvements over traditional heuristic methods in various tasks such as node classification and graph classification. However, since GNNs heavily rely on smoothed node features rather than graph structure, they often show poor performance than simple heuristic methods in link prediction where the structural information, e.g., overlapped neighborhoods, degrees, and shortest paths, is crucial. To address this limitation, we propose Neighborhood Overlap-aware Graph Neural Networks (Neo-GNNs) that learn useful structural features from an adjacency matrix and estimate overlapped neighborhoods for link prediction. Our Neo-GNNs generalize neighborhood overlap-based heuristic methods and handle overlapped multi-hop neighborhoods. Our extensive experiments on Open Graph Benchmark datasets (OGB) demonstrate that Neo-GNNs consistently achieve state-of-the-art performance in link prediction. © 2021 Neural information processing systems foundation. All rights reserved.",,Benchmarking; Forecasting; Graph theory; Graphic methods; Heuristic methods; Graph classification; Graph neural networks; Graph structured data; Graph structures; Link prediction; Neighbourhood; Poor performance; Short-path; Simple heuristics; Structural information; Graph neural networks,Conference paper,Final,,Scopus,2-s2.0-85132029527
59,Chen X.; Chen S.; Yao J.; Zheng H.; Zhang Y.; Tsang I.W.,"Chen, Xu (57211101732); Chen, Siheng (55314778300); Yao, Jiangchao (56939568800); Zheng, Huangjie (57192991594); Zhang, Ya (55914056200); Tsang, Ivor W. (7004570429)",57211101732; 55314778300; 56939568800; 57192991594; 55914056200; 7004570429,Learning on Attribute-Missing Graphs,2022,IEEE Transactions on Pattern Analysis and Machine Intelligence,44,2,,740,757,17,27,10.1109/TPAMI.2020.3032189,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85122778697&doi=10.1109%2fTPAMI.2020.3032189&partnerID=40&md5=b9efa1ea5869e2b2a797afd95923037e,"Shanghai Key Laboratory of Multimedia Processing and Transmissions, Cooperative Medianet Innovation Center, Shanghai Jiao Tong University, Shanghai, China; Mitsubishi Electric Research Laboratories, Cambridge, MA, United States; Alibaba Group, Hangzhou, China; Texas University, Austin, TX, United States; University of Technology Sydney, Sydney, NSW, Australia; Australian Artificial Intelligence Institute (AAII), University of Technology Sydney, 15 Broadway Ultimo, Sydney, 2007, NSW, Australia; Australian Artificial Intelligence Institute (AAII)., Australia","Chen X., Shanghai Key Laboratory of Multimedia Processing and Transmissions, Cooperative Medianet Innovation Center, Shanghai Jiao Tong University, Shanghai, China, Australian Artificial Intelligence Institute (AAII), University of Technology Sydney, 15 Broadway Ultimo, Sydney, 2007, NSW, Australia; Chen S., Mitsubishi Electric Research Laboratories, Cambridge, MA, United States; Yao J., Alibaba Group, Hangzhou, China; Zheng H., Texas University, Austin, TX, United States; Zhang Y., Shanghai Key Laboratory of Multimedia Processing and Transmissions, Cooperative Medianet Innovation Center, Shanghai Jiao Tong University, Shanghai, China; Tsang I.W., University of Technology Sydney, Sydney, NSW, Australia, Australian Artificial Intelligence Institute (AAII)., Australia","Graphs with complete node attributes have been widely explored recently. While in practice, there is a graph where attributes of only partial nodes could be available and those of the others might be entirely missing. This attribute-missing graph is related to numerous real-world applications and there are limited studies investigating the corresponding learning problems. Existing graph learning methods including the popular GNN cannot provide satisfied learning performance since they are not specified for attribute-missing graphs. Thereby, designing a new GNN for these graphs is a burning issue to the graph learning community. In this article, we make a shared-latent space assumption on graphs and develop a novel distribution matching-based GNN called structure-attribute transformer (SAT) for attribute-missing graphs. SAT leverages structures and attributes in a decoupled scheme and achieves the joint distribution modeling of structures and attributes by distribution matching techniques. It could not only perform the link prediction task but also the newly introduced node attribute completion task. Furthermore, practical measures are introduced to quantify the performance of node attribute completion. Extensive experiments on seven real-world datasets indicate SAT shows better performance than other methods on both link prediction and node attribute completion tasks. © 1979-2012 IEEE.",attribute-missing graphs; distribution matching; graph neural network; link prediction; node attribute completion; node classification,Forecasting; Graph neural networks; Graph theory; Learning systems; Attribute-missing graph; Distribution matching; Graph neural networks; Learning problem; Link prediction; Node attribute; Node attribute completion; Node classification; Performance; Real-world; Graphic methods,Article,Final,All Open Access; Green Open Access,Scopus,2-s2.0-85122778697
60,Wang J.; Ma A.; Ma Q.; Xu D.; Joshi T.,"Wang, Juexin (34979418400); Ma, Anjun (57201117266); Ma, Qin (36843466800); Xu, Dong (7404074295); Joshi, Trupti (34570184300)",34979418400; 57201117266; 36843466800; 7404074295; 34570184300,Inductive inference of gene regulatory network using supervised and semi-supervised graph neural networks,2020,Computational and Structural Biotechnology Journal,18,,,3335,3343,8,27,10.1016/j.csbj.2020.10.022,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85096122257&doi=10.1016%2fj.csbj.2020.10.022&partnerID=40&md5=05165169bb67271491e4016c3fe54664,"Department of Electrical Engineering and Computer Science, and Christopher S. Bond Life Science Center, University of Missouri, 65211, United States; Department of Biomedical Informatics, School of Medicine, Ohio State University, 43210, OH, United States; Department of Health Management and Informatics, Institute for Data Science and Informatics, University of Missouri, 65211, United States","Wang J., Department of Electrical Engineering and Computer Science, and Christopher S. Bond Life Science Center, University of Missouri, 65211, United States; Ma A., Department of Biomedical Informatics, School of Medicine, Ohio State University, 43210, OH, United States; Ma Q., Department of Biomedical Informatics, School of Medicine, Ohio State University, 43210, OH, United States; Xu D., Department of Electrical Engineering and Computer Science, and Christopher S. Bond Life Science Center, University of Missouri, 65211, United States; Joshi T., Department of Electrical Engineering and Computer Science, and Christopher S. Bond Life Science Center, University of Missouri, 65211, United States, Department of Health Management and Informatics, Institute for Data Science and Informatics, University of Missouri, 65211, United States","Discovering gene regulatory relationships and reconstructing gene regulatory networks (GRN) based on gene expression data is a classical, long-standing computational challenge in bioinformatics. Computationally inferring a possible regulatory relationship between two genes can be formulated as a link prediction problem between two nodes in a graph. Graph neural network (GNN) provides an opportunity to construct GRN by integrating topological neighbor propagation through the whole gene network. We propose an end-to-end gene regulatory graph neural network (GRGNN) approach to reconstruct GRNs from scratch utilizing the gene expression data, in both a supervised and a semi-supervised framework. To get better inductive generalization capability, GRN inference is formulated as a graph classification problem, to distinguish whether a subgraph centered at two nodes contains the link between the two nodes. A linked pair between a transcription factor (TF) and a target gene, and their neighbors are labeled as a positive subgraph, while an unlinked TF and target gene pair and their neighbors are labeled as a negative subgraph. A GNN model is constructed with node features from both explicit gene expression and graph embedding. We demonstrate a noisy starting graph structure built from partial information, such as Pearson's correlation coefficient and mutual information can help guide the GRN inference through an appropriate ensemble technique. Furthermore, a semi-supervised scheme is implemented to increase the quality of the classifier. When compared with established methods, GRGNN achieved state-of-the-art performance on the DREAM5 GRN inference benchmarks. GRGNN is publicly available at https://github.com/juexinwang/GRGNN. © 2020 The Author(s)",Gene regulatory; Graph neural networks; Inductive learning; Machine learning,Backpropagation; Benchmarking; Correlation methods; Graph structures; Graph theory; Learning systems; Transcription; transcription factor; Gene Expression Data; Gene regulatory; Gene regulatory networks; Graph neural networks; Inductive learning; Machine-learning; Network inference; Semi-supervised; Subgraphs; Target genes; Article; classifier; correlation coefficient; embedding; gene expression; gene regulatory network; graph neural network; inductive reasoning; machine learning; priority journal; semi supervised machine learning; supervised machine learning; Graph neural networks,Article,Final,All Open Access; Gold Open Access; Green Open Access,Scopus,2-s2.0-85096122257
61,Wang Z.; Ren Z.; He C.; Zhang P.; Hu Y.,"Wang, Zihan (57216695086); Ren, Zhaochun (53985046100); He, Chunyu (57211169326); Zhang, Peng (56202619100); Hu, Yue (56015484400)",57216695086; 53985046100; 57211169326; 56202619100; 56015484400,Robust embedding with multi-level structures for link prediction,2019,IJCAI International Joint Conference on Artificial Intelligence,2019-August,,,5240,5246,6,26,10.24963/ijcai.2019/728,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85074901939&doi=10.24963%2fijcai.2019%2f728&partnerID=40&md5=52b995fbd3dadbb9a97924b8515d85ee,"Institute of Information Engineering, Chinese Academy of Sciences, China; School of Cyber Security, University of Chinese, Academy of Sciences, China; Shandong University, China","Wang Z., Institute of Information Engineering, Chinese Academy of Sciences, China, School of Cyber Security, University of Chinese, Academy of Sciences, China; Ren Z., Shandong University, China; He C., Institute of Information Engineering, Chinese Academy of Sciences, China, School of Cyber Security, University of Chinese, Academy of Sciences, China; Zhang P., Institute of Information Engineering, Chinese Academy of Sciences, China, School of Cyber Security, University of Chinese, Academy of Sciences, China; Hu Y., Institute of Information Engineering, Chinese Academy of Sciences, China, School of Cyber Security, University of Chinese, Academy of Sciences, China","Knowledge Graph (KG) embedding has become crucial for the task of link prediction. Recent work applies encoder-decoder models to tackle this problem, where an encoder is formulated as a graph neural network (GNN) and a decoder is represented by an embedding method. These approaches enforce embedding techniques with structure information. Unfortunately, existing GNN-based frameworks still confront 3 severe problems: low representational power, stacking in a flat way, and poor robustness to noise. In this work, we propose a novel multi-level graph neural network (M-GNN) to address the above challenges. We first identify an injective aggregate scheme and design a powerful GNN layer using multi-layer perceptrons (MLPs). Then, we define graph coarsening schemes for various kinds of relations, and stack GNN layers on a series of coarsened graphs, so as to model hierarchical structures. Furthermore, attention mechanisms are adopted so that our approach can make predictions accurately even on the noisy knowledge graph. Results on WN18 and FB15k datasets show that our approach is effective in the standard link prediction task, significantly and consistently outperforming competitive baselines. Furthermore, robustness analysis on FB15k-237 dataset demonstrates that our proposed M-GNN is highly robust to sparsity and noise. © 2019 International Joint Conferences on Artificial Intelligence. All rights reserved.",,,Conference paper,Final,All Open Access; Bronze Open Access,Scopus,2-s2.0-85074901939
62,Long Y.; Wu M.; Liu Y.; Fang Y.; Kwoh C.K.; Chen J.; Luo J.; Li X.,"Long, Yahui (57191479602); Wu, Min (57610215100); Liu, Yong (55954393600); Fang, Yuan (55469295200); Kwoh, Chee Keong (35476211400); Chen, Jinmiao (57206950214); Luo, Jiawei (13205708100); Li, Xiaoli (35487931000)",57191479602; 57610215100; 55954393600; 55469295200; 35476211400; 57206950214; 13205708100; 35487931000,Pre-training graph neural networks for link prediction in biomedical networks,2022,Bioinformatics,38,8,,2254,2262,8,26,10.1093/bioinformatics/btac100,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85128705246&doi=10.1093%2fbioinformatics%2fbtac100&partnerID=40&md5=c106ae1876af66e8c5a8043ab68bd76d,"Singapore Immunology Network (SIgN), Agency for Science, Technology and Research, Singapore, Singapore; Institute for Infocomm Research, Agency for Science, Technology and Research, Singapore, Singapore; Joint NTU-UBC Research Centre of Excellence in Active Living for the Elderly, Singapore, Singapore; School of Information Systems, Singapore Management University, Singapore, 178902, Singapore; School of Computer Science and Engineering, Nanyang Technological University, Singapore, Singapore; College of Computer Science and Electronic Engineering, Hunan University, Changsha, China","Long Y., Singapore Immunology Network (SIgN), Agency for Science, Technology and Research, Singapore, Singapore; Wu M., Institute for Infocomm Research, Agency for Science, Technology and Research, Singapore, Singapore; Liu Y., Joint NTU-UBC Research Centre of Excellence in Active Living for the Elderly, Singapore, Singapore; Fang Y., School of Information Systems, Singapore Management University, Singapore, 178902, Singapore; Kwoh C.K., School of Computer Science and Engineering, Nanyang Technological University, Singapore, Singapore; Chen J., Singapore Immunology Network (SIgN), Agency for Science, Technology and Research, Singapore, Singapore; Luo J., College of Computer Science and Electronic Engineering, Hunan University, Changsha, China; Li X., Institute for Infocomm Research, Agency for Science, Technology and Research, Singapore, Singapore","Motivation: Graphs or networks are widely utilized to model the interactions between different entities (e.g. proteins, drugs, etc.) for biomedical applications. Predicting potential interactions/links in biomedical networks is important for understanding the pathological mechanisms of various complex human diseases, as well as screening compound targets for drug discovery. Graph neural networks (GNNs) have been utilized for link prediction in various biomedical networks, which rely on the node features extracted from different data sources, e.g. sequence, structure and network data. However, it is challenging to effectively integrate these data sources and automatically extract features for different link prediction tasks. Results: In this article, we propose a novel Pre-Training Graph Neural Networks-based framework named PT-GNN to integrate different data sources for link prediction in biomedical networks. First, we design expressive deep learning methods [e.g. convolutional neural network and graph convolutional network (GCN)] to learn features for individual nodes from sequence and structure data. Second, we further propose a GCN-based encoder to effectively refine the node features by modelling the dependencies among nodes in the network. Third, the node features are pre-trained based on graph reconstruction tasks. The pre-trained features can be used for model initialization in downstream tasks. Extensive experiments have been conducted on two critical link prediction tasks, i.e. synthetic lethality (SL) prediction and drug-target interaction (DTI) prediction. Experimental results demonstrate PT-GNN outperforms the state-of-the-art methods for SL prediction and DTI prediction. In addition, the pre-trained features benefit improving the performance and reduce the training time of existing models. © 2022 The Author(s) 2022. Published by Oxford University Press. All rights reserved.",,"Drug Development; Drug Discovery; Humans; Neural Networks, Computer; Proteins; protein; drug development; human",Article,Final,All Open Access; Bronze Open Access; Green Open Access,Scopus,2-s2.0-85128705246
63,Duddu V.; Boutet A.; Shejwalkar V.,"Duddu, Vasisht (57202859043); Boutet, Antoine (24469623300); Shejwalkar, Virat (57213519645)",57202859043; 24469623300; 57213519645,Quantifying privacy leakage in graph embedding,2020,ACM International Conference Proceeding Series,,,,76,85,9,25,10.1145/3448891.3448939,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85112703080&doi=10.1145%2f3448891.3448939&partnerID=40&md5=847c1c68ba4538d9506197c86473f18a,"Univ Lyon, INSA Lyon, Inria, CITI; University of Massachusetts Amherst","Duddu V., Univ Lyon, INSA Lyon, Inria, CITI; Boutet A., Univ Lyon, INSA Lyon, Inria, CITI; Shejwalkar V., University of Massachusetts Amherst","Graph embeddings have been proposed to map graph data to low dimensional space for downstream processing (e.g., node classification or link prediction). With the increasing collection of personal data, graph embeddings can be trained on private and sensitive data. For the first time, we quantify the privacy leakage in graph embeddings through three inference attacks targeting Graph Neural Networks. Our membership inference attack aims to infer whether a graph node corresponding to an individual user's data was a member of the model's private training data or not. We consider a blackbox setting where the adversary exploits the output prediction scores and a whitebox setting where the adversary has also access to the released node embeddings. Our attack provides accuracy up to 28% (blackbox) and 36% (whitebox) beyond the random guess by exploiting the distinguishable footprint between train and test data records left by the graph embedding. In our graph reconstruction attack, the adversary aims to reconstruct the target graph given the corresponding graph embeddings. Here, the adversary can reconstruct the graph with more than 80% of accuracy and infer the link between two nodes with ∼30% more accuracy than the random guess. Finally, we propose an attribute inference attack where the adversary aims to infer the sensitive node attributes corresponding to an individual user. We show that the strong correlation between the graph embeddings and node attributes allows the adversary to infer sensitive information (e.g., gender or location). © 2020 ACM.",Graph Embeddings; Graph Neural Networks; Inference Attacks; Privacy Leakage,Data privacy; Embeddings; Graph structures; Neural networks; Ubiquitous computing; Downstream-processing; Graph embeddings; Graph neural networks; Inference attacks; Low-dimensional spaces; Reconstruction attacks; Sensitive informations; Strong correlation; Graph theory,Conference paper,Final,All Open Access; Green Open Access,Scopus,2-s2.0-85112703080
64,Lin W.; Ji S.; Li B.,"Lin, Wanyu (57194830272); Ji, Shengxiang (57219975464); Li, Baochun (57216996445)",57194830272; 57219975464; 57216996445,Adversarial Attacks on Link Prediction Algorithms Based on Graph Neural Networks,2020,"Proceedings of the 15th ACM Asia Conference on Computer and Communications Security, ASIA CCS 2020",,,,370,380,10,25,10.1145/3320269.3384750,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85096368912&doi=10.1145%2f3320269.3384750&partnerID=40&md5=c9097d3ec640f42a3631232c62d489ec,"University of Toronto, Nserc Discovery Research Program, Toronto, Canada","Lin W., University of Toronto, Nserc Discovery Research Program, Toronto, Canada; Ji S., University of Toronto, Nserc Discovery Research Program, Toronto, Canada; Li B., University of Toronto, Nserc Discovery Research Program, Toronto, Canada","Link prediction is one of the fundamental problems for graph-structured data. However, a number of applications of link prediction, such as predicting commercial ties or memberships within a criminal organization, are adversarial, with another party aiming to minimize its effectiveness by manipulating observed information about the graph. In this paper, we focus on the feasibility of mounting adversarial attacks against link prediction algorithms based on graph neural networks. We first propose a greedy heuristic that exploits incremental computation to find attacks against a state-of-the-art link prediction algorithm, called SEAL. We then design an efficient variant of this algorithm that incorporates the link formation mechanism and Ǐ-decaying heuristic theory to design more effective adversarial attacks. We used real-world datasets and performed an extensive array of experiments to show that the performance of SEAL is negatively affected by a significant margin. More importantly, our experimental results have shown that our adversarial attacks mounted based on SEAL can be readily transferred to several existing link prediction heuristics in the literature. © 2020 ACM.",adversarial attacks; graph neural networks; link prediction,Computation theory; Forecasting; Graph algorithms; Graph structures; Seals; Formation mechanism; Graph neural networks; Graph structured data; Greedy heuristics; Incremental computation; Link prediction; Real-world datasets; State of the art; Neural networks,Conference paper,Final,,Scopus,2-s2.0-85096368912
65,Makarov I.; Korovina K.; Kiselev D.,"Makarov, Ilya (57203060623); Korovina, Ksenia (57205420792); Kiselev, Dmitrii (57218860326)",57203060623; 57205420792; 57218860326,JONNEE: Joint Network Nodes and Edges Embedding,2021,IEEE Access,9,,,144646,144659,13,24,10.1109/ACCESS.2021.3122100,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85124985032&doi=10.1109%2fACCESS.2021.3122100&partnerID=40&md5=9ac34fa2af6a2e7328737f1aabc56261,"HSE University, Moscow, 101000, Russian Federation; University of Ljubljana, Ljubljana, 1000, Slovenia; Artificial Intelligence Research Institute (AIRI), Moscow, 105064, Russian Federation","Makarov I., HSE University, Moscow, 101000, Russian Federation, University of Ljubljana, Ljubljana, 1000, Slovenia, Artificial Intelligence Research Institute (AIRI), Moscow, 105064, Russian Federation; Korovina K., HSE University, Moscow, 101000, Russian Federation; Kiselev D., HSE University, Moscow, 101000, Russian Federation, Artificial Intelligence Research Institute (AIRI), Moscow, 105064, Russian Federation","Recently, graph embedding models significantly improved the quality of graph machine learning tasks, such as node classification and link prediction. In this work, we propose a model called JONNEE (JOint Network Nodes and Edges Embedding), which learns node and edge embeddings under self-supervision via joint constraints in a given graph and its edge-to-vertex dual representation as a Line graph. The model uses two graph autoencoders with additional structural feature engineering and several regularization techniques to train for an adjacency matrix reconstruction task in an unsupervised setting. Experimental results show that our model performs on par with state-of-the-art undirected attribute graph embedding models and requires less number of epochs to achieve the same quality due to Line graph selfsupervision under a unified embedding framework. © 2021 Institute of Electrical and Electronics Engineers Inc.. All rights reserved.",Graph machine learning; graph neural networks; line graph; link prediction; network embedding; network representation learning; node classification,Machine learning; Network embeddings; Undirected graphs; Graph machine; Graph machine learning; Graph neural networks; Linegraph; Link prediction; Machine-learning; Network embedding; Network representation; Network representation learning; Node classification; Graph neural networks,Article,Final,All Open Access; Gold Open Access,Scopus,2-s2.0-85124985032
66,Kong K.; Li G.; Ding M.; Wu Z.; Zhu C.; Ghanem B.; Taylor G.; Goldstein T.,"Kong, Kezhi (57221113199); Li, Guohao (57215770103); Ding, Mucong (57207737399); Wu, Zuxuan (56377225900); Zhu, Chen (57217437192); Ghanem, Bernard (24331436200); Taylor, Gavin (25652359000); Goldstein, Tom (57225132014)",57221113199; 57215770103; 57207737399; 56377225900; 57217437192; 24331436200; 25652359000; 57225132014,Robust Optimization as Data Augmentation for Large-scale Graphs,2022,Proceedings of the IEEE Computer Society Conference on Computer Vision and Pattern Recognition,2022-June,,,60,69,9,25,10.1109/CVPR52688.2022.00016,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85139259519&doi=10.1109%2fCVPR52688.2022.00016&partnerID=40&md5=0b059f257ebb32e414aa706218d1c1e0,"University of Maryland, College Park, United States; King Abdullah University of Science and Technology, Saudi Arabia; Us Naval Academy, United States","Kong K., University of Maryland, College Park, United States; Li G., King Abdullah University of Science and Technology, Saudi Arabia; Ding M., University of Maryland, College Park, United States; Wu Z., University of Maryland, College Park, United States; Zhu C., University of Maryland, College Park, United States; Ghanem B., King Abdullah University of Science and Technology, Saudi Arabia; Taylor G., Us Naval Academy, United States; Goldstein T., University of Maryland, College Park, United States","Data augmentation helps neural networks generalize better by enlarging the training set, but it remains an open question how to effectively augment graph data to enhance the performance of GNNs (Graph Neural Networks). While most existing graph regularizers focus on manipulating graph topological structures by adding/removing edges, we offer a method to augment node features for better performance. We propose FLAG (Free Large-scale Adversarial Augmentation on Graphs), which iteratively augments node features with gradient-based adversarial perturbations during training. By making the model invariant to small fluctuations in input data, our method helps models generalize to out-of-distribution samples and boosts model performance at test time. FLAG is a general-purpose approach for graph data, which universally works in node classification, link prediction, and graph classification tasks. FLAG is also highly flexible and scalable, and is deployable with arbitrary GNN backbones and large-scale datasets. We demon-strate the efficacy and stability of our method through ex-tensive experiments and ablation studies. We also provide intuitive observations for a deeper understanding of our method. We open source our implementation at https://github.com/devnkong/FLAG. © 2022 IEEE.",Machine learning; Others,Computer vision; Graph algorithms; Graph neural networks; Graph structures; Iterative methods; Large dataset; Optimization; Data augmentation; Graph data; Graph neural networks; Large-scales; Machine-learning; Neural-networks; Other; Performance; Robust optimization; Training sets; Machine learning,Conference paper,Final,All Open Access; Green Open Access,Scopus,2-s2.0-85139259519
67,Gu W.; Gao F.; Li R.; Zhang J.,"Gu, Weiwei (57191866119); Gao, Fei (56984952300); Li, Ruiqi (56813951900); Zhang, Jiang (49362468600)",57191866119; 56984952300; 56813951900; 49362468600,Learning universal network representation via link prediction by graph convolutional neural network,2021,Journal of Social Computing,2,1,,43,51,8,23,10.23919/JSC.2021.0001,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85114813530&doi=10.23919%2fJSC.2021.0001&partnerID=40&md5=377d21da729da54db5ca16dfd5dc69c8,"College of Information Science and Technology, Beijing University of Chemical Technology, Beijing, 100029, China; School of Systems Science, Beijing Normal University, Beijing, 100875, China","Gu W., College of Information Science and Technology, Beijing University of Chemical Technology, Beijing, 100029, China; Gao F., School of Systems Science, Beijing Normal University, Beijing, 100875, China; Li R., College of Information Science and Technology, Beijing University of Chemical Technology, Beijing, 100029, China; Zhang J., School of Systems Science, Beijing Normal University, Beijing, 100875, China","Network representation learning algorithms, which aim at automatically encoding graphs into low-dimensional vector representations with a variety of node similarity definitions, have a wide range of downstream applications. Most existing methods either have low accuracies in downstream tasks or a very limited application field, such as article classification in citation networks. In this paper, we propose a novel network representation method, named Link Prediction based Network Representation (LPNR), which generalizes the latest graph neural network and optimizes a carefully designed objective function that preserves linkage structures. LPNR can not only learn meaningful node representations that achieve competitive accuracy in node centrality measurement and community detection but also achieve high accuracy in the link prediction task. Experiments prove the effectiveness of LPNR on three real-world networks. With the mini-batch and fixed sampling strategy, LPNR can learn the embedding of large graphs in a few hours. © The author(s) 2021.",Deep learning; Link prediction; Network representation,Convolutional neural networks; Deep learning; Forecasting; Learning algorithms; Deep learning; Dimensional vectors; Learn+; Link prediction; Low dimensional; Network representation; Node similarities; Prediction-based; Universal network; Vector representations; Graph neural networks,Article,Final,All Open Access; Gold Open Access,Scopus,2-s2.0-85114813530
68,Shao K.; Zhang Y.; Wen Y.; Zhang Z.; He S.; Bo X.,"Shao, Kanghao (57221309767); Zhang, Yunhao (57837777800); Wen, Yuqi (57195291765); Zhang, Zhongnan (56068760200); He, Song (56770438600); Bo, Xiaochen (7005391024)",57221309767; 57837777800; 57195291765; 56068760200; 56770438600; 7005391024,DTI-HETA: prediction of drug–target interactions based on GCN and GAT on heterogeneous graph,2022,Briefings in Bioinformatics,23,3,bbac109,,,,22,10.1093/bib/bbac109,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85130766923&doi=10.1093%2fbib%2fbbac109&partnerID=40&md5=a0b3244a573c6c3f28e39852ebaa61f5,"The Xiamen University, Xiamen, China; The Beijing Institute of Radiation Medicine, Beijing, China","Shao K., The Xiamen University, Xiamen, China; Zhang Y., The Xiamen University, Xiamen, China; Wen Y., The Beijing Institute of Radiation Medicine, Beijing, China; Zhang Z., The Xiamen University, Xiamen, China; He S., The Beijing Institute of Radiation Medicine, Beijing, China; Bo X., The Beijing Institute of Radiation Medicine, Beijing, China","Drug–target interaction (DTI) prediction plays an important role in drug repositioning, drug discovery and drug design. However, due to the large size of the chemical and genomic spaces and the complex interactions between drugs and targets, experimental identification of DTIs is costly and time-consuming. In recent years, the emerging graph neural network (GNN) has been applied to DTI prediction because DTIs can be represented effectively using graphs. However, some of these methods are only based on homogeneous graphs, and some consist of two decoupled steps that cannot be trained jointly. To further explore GNN-based DTI prediction by integrating heterogeneous graph information, this study regards DTI prediction as a link prediction problem and proposes an end-to-end model based on HETerogeneous graph with Attention mechanism (DTI-HETA). In this model, a heterogeneous graph is first constructed based on the drug–drug and target–target similarity matrices and the DTI matrix. Then, the graph convolutional neural network is utilized to obtain the embedded representation of the drugs and targets. To highlight the contribution of different neighborhood nodes to the central node in aggregating the graph convolution information, a graph attention mechanism is introduced into the node embedding process. Afterward, an inner product decoder is applied to predict DTIs. To evaluate the performance of DTI-HETA, experiments are conducted on two datasets. The experimental results show that our model is superior to the state-of-the-art methods. Also, the identification of novel DTIs indicates that DTI-HETA can serve as a powerful tool for integrating heterogeneous graph information to predict DTIs. © The Author(s) 2022. Published by Oxford University Press. All rights reserved.",DTI prediction; graph attention network; graph neural network; heterogeneous graph; link prediction,"Drug Development; Drug Interactions; Drug Repositioning; Neural Networks, Computer; Polymers; GAT; polymer; drug development; drug interaction; drug repositioning; procedures",Article,Final,,Scopus,2-s2.0-85130766923
69,Yu P.; Fu C.; Yu Y.; Huang C.; Zhao Z.; Dong J.,"Yu, Pengyang (57866255500); Fu, Chaofan (57866052400); Yu, Yanwei (12763209400); Huang, Chao (57051644000); Zhao, Zhongying (56171564000); Dong, Junyu (22634069200)",57866255500; 57866052400; 12763209400; 57051644000; 56171564000; 22634069200,Multiplex Heterogeneous Graph Convolutional Network,2022,Proceedings of the ACM SIGKDD International Conference on Knowledge Discovery and Data Mining,,,,2377,2387,10,22,10.1145/3534678.3539482,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85137142675&doi=10.1145%2f3534678.3539482&partnerID=40&md5=0ac0372bbe82362403c34fdd82ac4f05,"Ocean University of China, Qingdao, China; The University of Hong Kong, Hong Kong, Hong Kong; Shandong University of Science and Technology, Qingdao, China","Yu P., Ocean University of China, Qingdao, China; Fu C., Ocean University of China, Qingdao, China; Yu Y., Ocean University of China, Qingdao, China; Huang C., The University of Hong Kong, Hong Kong, Hong Kong; Zhao Z., Shandong University of Science and Technology, Qingdao, China; Dong J., Ocean University of China, Qingdao, China","Heterogeneous graph convolutional networks have gained great popularity in tackling various network analytical tasks on heterogeneous network data, ranging from link prediction to node classification. However, most existing works ignore the relation heterogeneity with multiplex network between multi-typed nodes and different importance of relations in meta-paths for node embedding, which can hardly capture the heterogeneous structure signals across different relations. To tackle this challenge, this work proposes a Multiplex Heterogeneous Graph Convolutional Network (MHGCN) for heterogeneous network embedding. Our MHGCN can automatically learn the useful heterogeneous meta-path interactions of different lengths in multiplex heterogeneous networks through multi-layer convolution aggregation. Additionally, we effectively integrate both multi-relation structural signals and attribute semantics into the learned node embeddings with both unsupervised and semi-supervised learning paradigms. Extensive experiments on five real-world datasets with various network analytical tasks demonstrate the significant superiority of MHGCN against state-of-the-art embedding baselines in terms of all evaluation metrics. The source code of our method is available at: https://github.com/NSSSJSS/MHGCN. © 2022 ACM.",graph convolutional networks; graph representation learning; multiplex heterogeneous networks; network embedding,Convolution; Graph neural networks; Graph structures; Graph theory; Network embeddings; Network layers; Semantics; Supervised learning; Convolutional networks; Embeddings; Graph convolutional network; Graph representation; Graph representation learning; Heterogeneous graph; Link prediction; Multiplex heterogeneous network; Network data; Network embedding; Heterogeneous networks,Conference paper,Final,All Open Access; Green Open Access,Scopus,2-s2.0-85137142675
70,Wang C.; An J.; Mu G.,"Wang, Changgang (57220956053); An, Jun (35931973700); Mu, Gang (7005165646)",57220956053; 35931973700; 7005165646,Power System Network Topology Identification Based on Knowledge Graph and Graph Neural Network,2021,Frontiers in Energy Research,8,,613331,,,,22,10.3389/fenrg.2020.613331,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85101963509&doi=10.3389%2ffenrg.2020.613331&partnerID=40&md5=b7db164d5bd995310f236893910f7af4,"Key Laboratory of Modern Power System Simulation and Control and Renewable Energy Technology, Ministry of Education (Northeast Electric Power University), Jilin, China; School of Electrical Engineering, Northeast Electric Power University, Jilin, China","Wang C., Key Laboratory of Modern Power System Simulation and Control and Renewable Energy Technology, Ministry of Education (Northeast Electric Power University), Jilin, China; An J., Key Laboratory of Modern Power System Simulation and Control and Renewable Energy Technology, Ministry of Education (Northeast Electric Power University), Jilin, China, School of Electrical Engineering, Northeast Electric Power University, Jilin, China; Mu G., School of Electrical Engineering, Northeast Electric Power University, Jilin, China","The automatic identification of the topology of power networks is important for the data-driven and situation-aware operation of power grids. Traditional methods of topology identification lack a data-tolerant mechanism, and the accuracy of their performance in terms of identification is thus affected by the quality of data. Topology identification is related to the link prediction problem. The graph neural network can be used to predict the state of unlabeled nodes (lines) through training on features of labeled nodes (lines) with fault tolerance. Inspired by the characteristics of the graph neural network, we applied it to topology identification in this study. We propose a method to identify the topology of a power network based on a knowledge graph and the graph neural network. Traditional knowledge graphs can quickly mine possible connections between entities and generate graph structure data, but in the case of errors or informational conflicts in the data, they cannot accurately determine whether the relationships between the entities really exist. The graph neural network can use data mining to determine whether a connection obtained between entities is based on their eigenvalues, and has a fault tolerance mechanism to adapt to errors and informational conflicts in the graph data, but needs the graph data as database. The combination of the knowledge graph and the graph neural network can compensate for the deficiency of the single knowledge graph method. We tested the proposed method by using the IEEE 118-bus system and a provincial network system. The results showed that our approach is feasible and highly fault tolerant. It can accurately identify network topology even in the presence of conflicting and missing measurement-related information. © Copyright © 2021 Wang, An and Mu.",graph neural network; knowledge graph; knowledge inference; power network; topology identification,Automation; Data mining; Eigenvalues and eigenfunctions; Electric network analysis; Electric power transmission networks; Fault tolerance; Graph structures; Knowledge representation; Topology; Fault tolerance mechanisms; Graph neural networks; IEEE 118-bus system; Knowledge graphs; Missing measurements; Power system networks; Topology identification; Traditional knowledge; Neural networks,Article,Final,All Open Access; Gold Open Access,Scopus,2-s2.0-85101963509
71,Yang C.; Wang C.; Lu Y.; Gong X.; Shi C.; Wang W.; Zhang X.,"Yang, Cheng (57001472900); Wang, Chunchen (57477989100); Lu, Yuanfu (57203114109); Gong, Xumeng (57477483700); Shi, Chuan (55447999200); Wang, Wei (56683299900); Zhang, Xu (57210644894)",57001472900; 57477989100; 57203114109; 57477483700; 55447999200; 56683299900; 57210644894,Few-shot link prediction in dynamic networks,2022,WSDM 2022 - Proceedings of the 15th ACM International Conference on Web Search and Data Mining,,,,1245,1255,10,22,10.1145/3488560.3498417,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85125806022&doi=10.1145%2f3488560.3498417&partnerID=40&md5=8fecd93967cb992dac3a55a33107eb5c,"Beijing University of Posts and Telecommunications, Beijing, China; Tencent Inc., WeChat Search Application Department, Beijing, China; Beijing Key Laboratory of Intelligent Telecommunications Software and Multimedia, Beijing, China","Yang C., Beijing University of Posts and Telecommunications, Beijing, China, Beijing Key Laboratory of Intelligent Telecommunications Software and Multimedia, Beijing, China; Wang C., Beijing University of Posts and Telecommunications, Beijing, China, Tencent Inc., WeChat Search Application Department, Beijing, China; Lu Y., Tencent Inc., WeChat Search Application Department, Beijing, China; Gong X., Beijing University of Posts and Telecommunications, Beijing, China; Shi C., Beijing University of Posts and Telecommunications, Beijing, China, Beijing Key Laboratory of Intelligent Telecommunications Software and Multimedia, Beijing, China; Wang W., Tencent Inc., WeChat Search Application Department, Beijing, China; Zhang X., Tencent Inc., WeChat Search Application Department, Beijing, China","Dynamic link prediction, which aims at forecasting future edges of a node in a dynamic network, is an important problem in network science and has a wide range of real-world applications. A key property of dynamic networks is that new nodes and links keep coming over time and these new nodes usually have only a few links at their arrivals. However, how to predict future links for these few-shot nodes in a dynamic network has not been well studied. Existing dynamic network representation learning methods were not specialized for few-shot scenarios and thus would lead to suboptimal performances. In this paper, we propose a novel model based on a meta-learning framework, dubbed as MetaDyGNN, for few-shot link prediction in dynamic networks. Specifically, we propose a meta-learner with hierarchical time interval-wise and node-wise adaptions to extract general knowledge behind this problem. We also design a simple and effective dynamic graph neural network (GNN) module to characterize the local structure of each node in meta-learning tasks. As a result, the learned general knowledge serves as model initializations, and can quickly adapt to new nodes with a fine-tuning process on only a few links. Experimental results show that our proposed MetaDyGNN significantly outperforms state-of-the-art methods on three publicly available datasets. © 2022 ACM.",Dynamic network; Few-shot prediction; Graph neural networks; Link prediction; Meta-learning,Graph neural networks; Learning systems; Dynamic links; Dynamic network; Few-shot prediction; General knowledge; Graph neural networks; In networks; Link prediction; Metalearning; Network science; Real-world; Forecasting,Conference paper,Final,,Scopus,2-s2.0-85125806022
72,Hu J.; Qian S.; Fang Q.; Wang Y.; Zhao Q.; Zhang H.; Xu C.,"Hu, Jun (57206971949); Qian, Shengsheng (56038690300); Fang, Quan (55441705700); Wang, Youze (57217246542); Zhao, Quan (57217872588); Zhang, Huaiwen (57192663800); Xu, Changsheng (56153258200)",57206971949; 56038690300; 55441705700; 57217246542; 57217872588; 57192663800; 56153258200,Efficient Graph Deep Learning in TensorFlow with tf_geometric,2021,MM 2021 - Proceedings of the 29th ACM International Conference on Multimedia,,,,3775,3778,3,22,10.1145/3474085.3478322,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85119354032&doi=10.1145%2f3474085.3478322&partnerID=40&md5=eddccaf3457478d8fe70f47c0338e020,"National Laboratory of Pattern Recognition, Institute of Automation, Chinese Academy of Sciences, China; School of Artificial Intelligence, University of Chinese Academy of Sciences, China; Hefei University of Technology, China; Key Laboratory of Artificial Intelligence Scenario Application and Intelligent System Evaluation, Ministry of Industry and Information Technology","Hu J., National Laboratory of Pattern Recognition, Institute of Automation, Chinese Academy of Sciences, China; Qian S., National Laboratory of Pattern Recognition, Institute of Automation, Chinese Academy of Sciences, China, School of Artificial Intelligence, University of Chinese Academy of Sciences, China; Fang Q., National Laboratory of Pattern Recognition, Institute of Automation, Chinese Academy of Sciences, China, School of Artificial Intelligence, University of Chinese Academy of Sciences, China; Wang Y., Hefei University of Technology, China; Zhao Q., Hefei University of Technology, China; Zhang H., National Laboratory of Pattern Recognition, Institute of Automation, Chinese Academy of Sciences, China, School of Artificial Intelligence, University of Chinese Academy of Sciences, China, Key Laboratory of Artificial Intelligence Scenario Application and Intelligent System Evaluation, Ministry of Industry and Information Technology; Xu C., National Laboratory of Pattern Recognition, Institute of Automation, Chinese Academy of Sciences, China, School of Artificial Intelligence, University of Chinese Academy of Sciences, China","We introduce tf_geometric1, an efficient and friendly library for graph deep learning, which is compatible with both TensorFlow 1.x and 2.x. It provides kernel libraries for building Graph Neural Networks (GNNs) as well as implementations of popular GNNs. The kernel libraries consist of infrastructures for building efficient GNNs, including graph data structures, graph map-reduce framework, graph mini-batch strategy, etc. These infrastructures enable tf_geometric to support single-graph computation, multi-graph computation, graph mini-batch, distributed training, etc.; therefore, tf_geometric can be used for a variety of graph deep learning tasks, such as node classification, link prediction, and graph classification. Based on the kernel libraries, tf_geometric implements a variety of popular GNN models. To facilitate the implementation of GNNs, tf_geometric also provides some other libraries for dataset management, graph sampling, etc. Different from existing popular GNN libraries, tf_geometric provides not only Object-Oriented Programming (OOP) APIs, but also Functional APIs, which enable tf_geometric to handle advanced tasks such as graph meta-learning. The APIs are friendly and suitable for both beginners and experts. © 2021 ACM.",graph deep learning; graph neural networks,Application programming interfaces (API); Deep neural networks; Functional programming; Libraries; Object oriented programming; Graph classification; Graph deep learning; Graph neural networks; Kernel libraries; Learning tasks; Link prediction; Map-reduce; Neural implementations; Neural network model; Single graph; Graph neural networks,Conference paper,Final,All Open Access; Green Open Access,Scopus,2-s2.0-85119354032
73,Munikoti S.; Das L.; Natarajan B.,"Munikoti, Sai (57217080819); Das, Laya (56315306900); Natarajan, Balasubramaniam (35617559600)",57217080819; 56315306900; 35617559600,Scalable graph neural network-based framework for identifying critical nodes and links in complex networks,2022,Neurocomputing,468,,,211,221,10,22,10.1016/j.neucom.2021.10.031,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85117955041&doi=10.1016%2fj.neucom.2021.10.031&partnerID=40&md5=581066e55ae7f549b9671c19faccb3f8,"Department of Electrical and Computer Engineering, Kansas State University, Manhattan, 66506, KS, United States; Reliability and Risk Engineering Lab, ETH Zurich, 8092, Zurich, Switzerland","Munikoti S., Department of Electrical and Computer Engineering, Kansas State University, Manhattan, 66506, KS, United States; Das L., Reliability and Risk Engineering Lab, ETH Zurich, 8092, Zurich, Switzerland; Natarajan B., Department of Electrical and Computer Engineering, Kansas State University, Manhattan, 66506, KS, United States","Identifying critical nodes and links in graphs is a crucial task. These nodes/links typically represent critical elements/communication links that play a key role in a system's performance. However, a majority of the methods available in the literature on the identification of critical nodes/links are based on an iterative approach that explores each node/link of a graph at a time, repeating for all nodes/links in the graph. Such methods suffer from high computational complexity and the resulting analysis is also network-specific. To overcome these challenges, this article proposes a scalable and generic graph neural network (GNN) based framework for identifying critical nodes/links in large complex networks. The proposed framework defines a GNN based model that learns the node/link criticality score on a small representative subset of nodes/links. An appropriately trained model can be employed to predict the scores of unseen nodes/links in large graphs and consequently identify the most critical ones. The scalability of the framework is demonstrated through prediction of nodes/links scores in large scale synthetic and real-world networks. The proposed approach is fairly accurate in approximating the criticality scores and offers a significant computational advantage over conventional approaches. © 2021 Elsevier B.V.",Graph neural network; Link prediction; Node prediction; Resilience; Robustness,Complex networks; Criticality (nuclear fission); Forecasting; Graph theory; Iterative methods; Critical elements; Critical links; Critical node; Graph neural networks; Link prediction; Network-based framework; Node prediction; Nodes and links; Resilience; Robustness; article; prediction; Graph neural networks,Article,Final,All Open Access; Bronze Open Access; Green Open Access,Scopus,2-s2.0-85117955041
74,Xiao Y.; Pei Q.; Xiao T.; Yao L.; Liu H.,"Xiao, Yang (57187414200); Pei, Qingqi (15763462800); Xiao, Tingting (57194699852); Yao, Lina (54406102800); Liu, Huan (57195323711)",57187414200; 15763462800; 57194699852; 54406102800; 57195323711,MutualRec: Joint friend and item recommendations with mutualistic attentional graph neural networks,2021,Journal of Network and Computer Applications,177,,102954,,,,21,10.1016/j.jnca.2020.102954,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85098955364&doi=10.1016%2fj.jnca.2020.102954&partnerID=40&md5=f4414da1f9005c1886ae0f922d8c63b6,"State Key Laboratory of Integrated Services Networks School of Cyber Engineering, Xidian University, Xi'an, 710071, China; School of Computer Science and Engineering, University of New South Wales, Sydney, 2052, NSW, Australia; School of Electronic and Information Engineering, Xi'an Jiaotong University, China","Xiao Y., State Key Laboratory of Integrated Services Networks School of Cyber Engineering, Xidian University, Xi'an, 710071, China; Pei Q., State Key Laboratory of Integrated Services Networks School of Cyber Engineering, Xidian University, Xi'an, 710071, China; Xiao T., State Key Laboratory of Integrated Services Networks School of Cyber Engineering, Xidian University, Xi'an, 710071, China; Yao L., School of Computer Science and Engineering, University of New South Wales, Sydney, 2052, NSW, Australia; Liu H., School of Electronic and Information Engineering, Xi'an Jiaotong University, China","Many social studies and practical cases suggest that people's consumption behaviors and social behaviors are not isolated but interrelated. However, most existing research either predicts users' consumption preference or recommends friends to users without dealing with them simultaneously. In this paper, we propose a novel framework called MutualRec that jointly accomplishes the two tasks based on graph neural networks, attention mechanisms, and mutualistic model. MutualRec first uses a spatial attention layer and a spectral attention layer to learn latent embeddings from observed data, and then merges them via a mutualistic attention layer. The first two layers can relieve data sparsity without violating users' preference sequence, while the last captures the relationship between user’ consumption and social behaviors. We demonstrate the effectiveness of MutualRec in both social recommendation and link prediction via extensive experiments. © 2020",Attention; Graph neural network; Joint recommendations; Mutualistic model; Social networks,Behavioral research; Attention mechanisms; Data sparsity; Graph neural networks; Link prediction; Observed data; Social behavior; Social study; Spatial attention; Neural networks,Article,Final,,Scopus,2-s2.0-85098955364
75,Jiang X.; Zhu R.; Ji P.; Li S.,"Jiang, Xiaodong (57215799859); Zhu, Ronghang (57226270251); Ji, Pengsheng (55531615600); Li, Sheng (55812663300)",57215799859; 57226270251; 55531615600; 55812663300,Co-Embedding of Nodes and Edges With Graph Neural Networks,2023,IEEE Transactions on Pattern Analysis and Machine Intelligence,45,6,,7075,7086,11,21,10.1109/TPAMI.2020.3029762,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85160203793&doi=10.1109%2fTPAMI.2020.3029762&partnerID=40&md5=ee679c121ac40b9fe1ed5684b44b52b6,"University of Georgia, Department of Statistics, Department of Computer Science, Athens, 30602, GA, United States; University of Georgia, Department of Computer Science, Athens, 30602, GA, United States; University of Georgia, Department of Statistics, Athens, 30602, GA, United States; University of Georgia, Department of Computer Science, Institute for Artificial Intelligence, Athens, 30602, GA, United States","Jiang X., University of Georgia, Department of Statistics, Department of Computer Science, Athens, 30602, GA, United States; Zhu R., University of Georgia, Department of Computer Science, Athens, 30602, GA, United States; Ji P., University of Georgia, Department of Statistics, Athens, 30602, GA, United States; Li S., University of Georgia, Department of Computer Science, Institute for Artificial Intelligence, Athens, 30602, GA, United States","Graph, as an important data representation, is ubiquitous in many real world applications ranging from social network analysis to biology. How to correctly and effectively learn and extract information from graph is essential for a large number of machine learning tasks. Graph embedding is a way to transform and encode the data structure in high dimensional and non-euclidean feature space to a low dimensional and structural space, which is easily exploited by other machine learning algorithms. We have witnessed a huge surge of such embedding methods, from statistical approaches to recent deep learning methods such as the graph convolutional networks (GCN). Deep learning approaches usually outperform the traditional methods in most graph learning benchmarks by building an end-to-end learning framework to optimize the loss function directly. However, most of the existing GCN methods can only perform convolution operations with node features, while ignoring the handy information in edge features, such as relations in knowledge graphs. To address this problem, we present CensNet, Convolution with Edge-Node Switching graph neural network, for learning tasks in graph-structured data with both node and edge features. CensNet is a general graph embedding framework, which embeds both nodes and edges to a latent feature space. By using line graph of the original undirected graph, the role of nodes and edges are switched, and two novel graph convolution operations are proposed for feature propagation. Experimental results on real-world academic citation networks and quantum chemistry graphs show that our approach achieves or matches the state-of-the-art performance in four graph learning tasks, including semi-supervised node classification, multi-task graph classification, graph regression, and link prediction. © 1979-2012 IEEE.",Graph embedding; graph neural networks; line graph; link prediction; node classification,Backpropagation; Classification (of information); Convolution; Deep learning; Graph embeddings; Graphic methods; Knowledge graph; Quantum chemistry; Quantum theory; Undirected graphs; Convolutional networks; Edge features; Feature space; Graph embeddings; Graph neural networks; Learning tasks; Linegraph; Link prediction; Node classification; Real-world; Graph neural networks,Article,Final,All Open Access; Green Open Access,Scopus,2-s2.0-85160203793
76,Rong Y.; Xu T.; Huang J.; Huang W.; Cheng H.; Ma Y.; Wang Y.; Derr T.; Wu L.; Ma T.,"Rong, Yu (56410469700); Xu, Tingyang (56515877000); Huang, Junzhou (57195386755); Huang, Wenbing (55899205200); Cheng, Hong (7404284983); Ma, Yao (57201255717); Wang, Yiqi (57217171165); Derr, Tyler (57198886641); Wu, Lingfei (56937260100); Ma, Tengfei (57194786822)",56410469700; 56515877000; 57195386755; 55899205200; 7404284983; 57201255717; 57217171165; 57198886641; 56937260100; 57194786822,"Deep Graph Learning: Foundations, Advances and Applications",2020,Proceedings of the ACM SIGKDD International Conference on Knowledge Discovery and Data Mining,,,,3555,3556,1,21,10.1145/3394486.3406474,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85090415418&doi=10.1145%2f3394486.3406474&partnerID=40&md5=57c6ee0d85ece5601c5ef085f655a3b7,"Tencent Ai Lab, Shenzhen, China; Tsinghua University, Beijing, China; Chinese University of Hong Kong, Shatin, Hong Kong; Michigan State University, East Lansing, MI, United States; Vanderbilt University, Nashville, TN, United States; Ibm Research Ai, Yorktown Heights, NY, United States","Rong Y., Tencent Ai Lab, Shenzhen, China; Xu T., Tencent Ai Lab, Shenzhen, China; Huang J., Tencent Ai Lab, Shenzhen, China; Huang W., Tsinghua University, Beijing, China; Cheng H., Chinese University of Hong Kong, Shatin, Hong Kong; Ma Y., Michigan State University, East Lansing, MI, United States; Wang Y., Michigan State University, East Lansing, MI, United States; Derr T., Vanderbilt University, Nashville, TN, United States; Wu L., Ibm Research Ai, Yorktown Heights, NY, United States; Ma T., Ibm Research Ai, Yorktown Heights, NY, United States","Many real data come in the form of non-grid objects, i.e. graphs, from social networks to molecules. Adaptation of deep learning from grid-alike data (e.g. images) to graphs has recently received unprecedented attention from both machine learning and data mining communities, leading to a new cross-domain field - -Deep Graph Learning (DGL). Instead of painstaking feature engineering, DGL aims to learn informative representations of graphs in an end-to-end manner. It has exhibited remarkable success in various tasks, such as node/graph classification, link prediction, etc. In this tutorial, we aim to provide a comprehensive introduction to deep graph learning. We first introduce the theoretical foundations on deep graph learning with a focus on describing various Graph Neural Network Models (GNNs). We then cover the key achievements of DGL in recent years. Specifically, we discuss the four topics: 1) training deep GNNs; 2) robustness of GNNs; 3) scalability of GNNs; and 4) self-supervised and unsupervised learning of GNNs. Finally, we will introduce the applications of DGL towards various domains, including but not limited to drug discovery, computer vision, medical image analysis, social network analysis, natural language processing and recommendation. © 2020 Owner/Author.",,Data mining; Graph theory; Learning systems; Medical imaging; Natural language processing systems; Social networking (online); Data mining community; Feature engineerings; Graph neural networks; Link prediction; NAtural language processing; Representations of graphs; Supervised and unsupervised learning; Theoretical foundations; Deep learning,Conference paper,Final,,Scopus,2-s2.0-85090415418
77,Xu S.; Yang C.; Shi C.; Fang Y.; Guo Y.; Yang T.; Zhang L.; Hu M.,"Xu, Siyong (57204508459); Yang, Cheng (57001472900); Shi, Chuan (55447999200); Fang, Yuan (55469295200); Guo, Yuxin (57340635900); Yang, Tianchi (57204945425); Zhang, Luhao (57215425975); Hu, Maodi (36026545100)",57204508459; 57001472900; 55447999200; 55469295200; 57340635900; 57204945425; 57215425975; 36026545100,Topic-aware Heterogeneous Graph Neural Network for Link Prediction,2021,"International Conference on Information and Knowledge Management, Proceedings",,,,2261,2270,9,19,10.1145/3459637.3482485,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85119204886&doi=10.1145%2f3459637.3482485&partnerID=40&md5=ff54181f025e7da422611d6b2de4d73d,"Beijing University of Posts and Telecommunications, Beijing, China; Singapore Management University, Singapore, Singapore; Meituan, Beijing, China","Xu S., Beijing University of Posts and Telecommunications, Beijing, China; Yang C., Beijing University of Posts and Telecommunications, Beijing, China; Shi C., Beijing University of Posts and Telecommunications, Beijing, China; Fang Y., Singapore Management University, Singapore, Singapore; Guo Y., Beijing University of Posts and Telecommunications, Beijing, China; Yang T., Beijing University of Posts and Telecommunications, Beijing, China; Zhang L., Meituan, Beijing, China; Hu M., Meituan, Beijing, China","Heterogeneous graphs (HGs), consisting of multiple types of nodes and links, can characterize a variety of real-world complex systems. Recently, heterogeneous graph neural networks (HGNNs), as a powerful graph embedding method to aggregate heterogeneous structure and attribute information, has earned a lot of attention. Despite the ability of HGNNs in capturing rich semantics which reveal different aspects of nodes, they still stay at a coarse-grained level which simply exploits structural characteristics. In fact, rich unstructured text content of nodes also carries latent but more fine-grained semantics arising from multi-facet topic-aware factors, which fundamentally manifest why nodes of different types would connect and form a specific heterogeneous structure. However, little effort has been devoted to factorizing them. In this paper, we propose a Topic-aware Heterogeneous Graph Neural Network, named THGNN, to hierarchically mine topic-aware semantics for learning multi-facet node representations for link prediction in HGs. Specifically, our model mainly applies an alternating two-step aggregation mechanism including intra-metapath decomposition and inter-metapath mergence, which can distinctively aggregate rich heterogeneous information according to the inferential topic-aware factors and preserve hierarchical semantics. Furthermore, a topic prior guidance module is also designed to keep the quality of multi-facet topic-aware embeddings relying on the global knowledge from unstructured text content in HGs. It helps to simultaneously improve both performance and interpretability. Experimental results on three real-world HGs demonstrate that our proposed model can effectively outperform the state-of-the-art methods in the link prediction task, and show the potential interpretability of learnt multi-facet topic-aware representations. © 2021 ACM.",graph neural networks; heterogeneous graph; link prediction; representation learning,Aggregates; Embeddings; Forecasting; Graph theory; Mercury compounds; Semantics; Graph neural networks; Heterogeneous graph; Heterogeneous structures; Interpretability; Link prediction; Nodes and links; Real-world; Representation learning; Text content; Unstructured texts; Graph neural networks,Conference paper,Final,All Open Access; Green Open Access,Scopus,2-s2.0-85119204886
78,Yan Z.; Ma T.; Gao L.; Tang Z.; Chen C.,"Yan, Zuoyu (57201525301); Ma, Tengfei (57194786822); Gao, Liangcai (25924927000); Tang, Zhi (57207756308); Chen, Chao (56098603000)",57201525301; 57194786822; 25924927000; 57207756308; 56098603000,Link Prediction with Persistent Homology: An Interactive View,2021,Proceedings of Machine Learning Research,139,,,11659,11669,10,19,,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85117796340&partnerID=40&md5=fdf3e7c4afa5388ae8ad08f4ca96f965,"Wangxuan Institute of Computer Technology, Peking University, Beijing, China; T. J. Watson Research Center, IBM, NY, United States; Department of Biomedical Informatics, Stony Brook University, New York, United States","Yan Z., Wangxuan Institute of Computer Technology, Peking University, Beijing, China; Ma T., T. J. Watson Research Center, IBM, NY, United States; Gao L., Wangxuan Institute of Computer Technology, Peking University, Beijing, China; Tang Z., Wangxuan Institute of Computer Technology, Peking University, Beijing, China; Chen C., Department of Biomedical Informatics, Stony Brook University, New York, United States","Link prediction is an important learning task for graph-structured data. In this paper, we propose a novel topological approach to characterize interactions between two nodes. Our topological feature, based on the extended persistent homology, encodes rich structural information regarding the multi-hop paths connecting nodes. Based on this feature, we propose a graph neural network method that outperforms state-of-the-arts on different benchmarks. As another contribution, we propose a novel algorithm to more efficiently compute the extended persistence diagrams for graphs. This algorithm can be generally applied to accelerate many other topological methods for graph learning tasks. Copyright © 2021 by the author(s)",,Arts computing; Graph algorithms; Graph structures; Connecting nodes; Feature-based; Graph structured data; Learning tasks; Link prediction; Multi-hop path; Persistent homology; Structural information; Topological approach; Topological features; Graph neural networks,Conference paper,Final,,Scopus,2-s2.0-85117796340
79,Wang Z.; Ji S.,"Wang, Zhengyang (57202439077); Ji, Shuiwang (18935244900)",57202439077; 18935244900,Second-Order Pooling for Graph Neural Networks,2023,IEEE Transactions on Pattern Analysis and Machine Intelligence,45,6,,6870,6880,10,19,10.1109/TPAMI.2020.2999032,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85160203469&doi=10.1109%2fTPAMI.2020.2999032&partnerID=40&md5=ae342ad634463f4bb6a6034bcdcf11a0,"Texas A&m University, Department of Computer Science and Engineering, College Station, 77843, TX, United States","Wang Z., Texas A&m University, Department of Computer Science and Engineering, College Station, 77843, TX, United States; Ji S., Texas A&m University, Department of Computer Science and Engineering, College Station, 77843, TX, United States","Graph neural networks have achieved great success in learning node representations for graph tasks such as node classification and link prediction. Graph representation learning requires graph pooling to obtain graph representations from node representations. It is challenging to develop graph pooling methods due to the variable sizes and isomorphic structures of graphs. In this work, we propose to use second-order pooling as graph pooling, which naturally solves the above challenges. In addition, compared to existing graph pooling methods, second-order pooling is able to use information from all nodes and collect second-order statistics, making it more powerful. We show that direct use of second-order pooling with graph neural networks leads to practical problems. To overcome these problems, we propose two novel global graph pooling methods based on second-order pooling; namely, bilinear mapping and attentional second-order pooling. In addition, we extend attentional second-order pooling to hierarchical graph pooling for more flexible use in GNNs. We perform thorough experiments on graph classification tasks to demonstrate the effectiveness and superiority of our proposed methods. Experimental results show that our methods improve the performance significantly and consistently. © 1979-2012 IEEE.",Graph neural networks; graph pooling; second-order statistics,Graph theory; AS graph; Classification prediction; Graph neural networks; Graph pooling; Graph representation; Link prediction; Second order statistics; Second orders; Structure of graph; Variable sizes; Graph neural networks,Article,Final,All Open Access; Green Open Access,Scopus,2-s2.0-85160203469
80,Kang C.; Zhang H.; Liu Z.; Huang S.; Yin Y.,"Kang, Chuanze (57244905800); Zhang, Han (57161255400); Liu, Zhuo (57219693430); Huang, Shenwei (36660946500); Yin, Yanbin (33368412800)",57244905800; 57161255400; 57219693430; 36660946500; 33368412800,LR-GNN: a graph neural network based on link representation for predicting molecular associations,2022,Briefings in Bioinformatics,23,1,bbab513,,,,19,10.1093/bib/bbab513,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85122009464&doi=10.1093%2fbib%2fbbab513&partnerID=40&md5=13eeea84a7b9631baf618cf7079430ef,"The College of Artificial Intelligence, Nankai University, China; The College of Computer Science, Nankai University, China; The Department of Food Science and Technology, University of Nebraska - Lincoln, United States","Kang C., The College of Artificial Intelligence, Nankai University, China; Zhang H., The College of Artificial Intelligence, Nankai University, China; Liu Z., The College of Artificial Intelligence, Nankai University, China; Huang S., The College of Computer Science, Nankai University, China; Yin Y., The Department of Food Science and Technology, University of Nebraska - Lincoln, United States","In biomedical networks, molecular associations are important to understand biological processes and functions. Many computational methods, such as link prediction methods based on graph neural networks (GNNs), have been successfully applied in discovering molecular relationships with biological significance. However, it remains a challenge to explore a method that relies on representation learning of links for accurately predicting molecular associations. In this paper, we present a novel GNN based on link representation (LR-GNN) to identify potential molecular associations. LR-GNN applies a graph convolutional network (GCN)-encoder to obtain node embedding. To represent associations between molecules, we design a propagation rule that captures the node embedding of each GCN-encoder layer to construct the link representation (LR). Furthermore, the LRs of all layers are fused in output by a designed layer-wise fusing rule, which enables LR-GNN to output more accurate results. Experiments on four biomedical network data, including lncRNA-disease association, miRNA-disease association, protein–protein interaction and drug–drug interaction, show that LR-GNN outperforms state-of-the-art methods and achieves robust performance. Case studies are also presented on two datasets to verify the ability to predict unknown associations. Finally, we validate the effectiveness of the LR by visualization. © The Author(s) 2021. Published by Oxford University Press. All rights reserved.",Biomedical networks; Graph neural network; Link representation; Molecular association prediction,"Algorithms; Biomedical Technology; Cell Communication; Computational Biology; Deep Learning; Drug Interactions; Humans; MicroRNAs; Neural Networks, Computer; Protein Interaction Domains and Motifs; Research Design; RNA, Long Noncoding; long untranslated RNA; microRNA; algorithm; biology; cell communication; drug interaction; human; medical technology; methodology; procedures; protein domain",Article,Final,,Scopus,2-s2.0-85122009464
81,Liu W.; Zhang Y.; Wang J.; He Y.; Caverlee J.; Chan P.P.K.; Yeung D.S.; Heng P.-A.,"Liu, Weiwen (57202889283); Zhang, Yin (57204712947); Wang, Jianling (57206482614); He, Yun (57188719427); Caverlee, James (8567605000); Chan, Patrick P. K. (7403497727); Yeung, Daniel S. (7103391375); Heng, Pheng-Ann (7006677755)",57202889283; 57204712947; 57206482614; 57188719427; 8567605000; 7403497727; 7103391375; 7006677755,Item Relationship Graph Neural Networks for E-Commerce,2022,IEEE Transactions on Neural Networks and Learning Systems,33,9,,4785,4799,14,20,10.1109/TNNLS.2021.3060872,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85102644197&doi=10.1109%2fTNNLS.2021.3060872&partnerID=40&md5=afe1700c56dcf1b885c3573cfea46703,"The Chinese University of Hong Kong, Department of Computer Science and Engineering, Hong Kong; Texas A and M University, Department of Computer Science and Engineering, College Station, 77843, TX, United States; South China University of Technology, School of Computer Science and Engineering, Guangzhou, 510006, China; Smc Society of Ieee, Hong Kong","Liu W., The Chinese University of Hong Kong, Department of Computer Science and Engineering, Hong Kong; Zhang Y., Texas A and M University, Department of Computer Science and Engineering, College Station, 77843, TX, United States; Wang J., Texas A and M University, Department of Computer Science and Engineering, College Station, 77843, TX, United States; He Y., Texas A and M University, Department of Computer Science and Engineering, College Station, 77843, TX, United States; Caverlee J., Texas A and M University, Department of Computer Science and Engineering, College Station, 77843, TX, United States; Chan P.P.K., South China University of Technology, School of Computer Science and Engineering, Guangzhou, 510006, China; Yeung D.S., Smc Society of Ieee, Hong Kong; Heng P.-A., The Chinese University of Hong Kong, Department of Computer Science and Engineering, Hong Kong","In a modern e-commerce recommender system, it is important to understand the relationships among products. Recognizing product relationships - such as complements or substitutes - accurately is an essential task for generating better recommendation results, as well as improving explainability in recommendation. Products and their associated relationships naturally form a product graph, yet existing efforts do not fully exploit the product graph's topological structure. They usually only consider the information from directly connected products. In fact, the connectivity of products a few hops away also contains rich semantics and could be utilized for improved relationship prediction. In this work, we formulate the problem as a multilabel link prediction task and propose a novel graph neural network-based framework, item relationship graph neural network (IRGNN), for discovering multiple complex relationships simultaneously. We incorporate multihop relationships of products by recursively updating node embeddings using the messages from their neighbors. An edge relational network is designed to effectively capture relational information between products. Extensive experiments are conducted on real-world product data, validating the effectiveness of IRGNN, especially on large and sparse product graphs. © 2012 IEEE.",Graph neural networks (GNNs); item relationship prediction; multihop relationships,Data mining; Edge detection; Graph neural networks; Semantics; Collaboration; Graph neural network; Graph neural networks; Image edge detection; Item relationship prediction; Multi-hops; Multihop relationship.; Predictive models; Spread-spectrum communication; Task analysis; article; electronic commerce; embedding; hops; prediction; semantics; Forecasting,Article,Final,,Scopus,2-s2.0-85102644197
82,Wu W.; Li B.; Luo C.; Nejdl W.,"Wu, Wei (57753165100); Li, Bin (55698653500); Luo, Chuan (55750203700); Nejdl, Wolfgang (57204338128)",57753165100; 55698653500; 55750203700; 57204338128,Hashing-accelerated graph neural networks for link prediction,2021,"The Web Conference 2021 - Proceedings of the World Wide Web Conference, WWW 2021",,,,2910,2920,10,18,10.1145/3442381.3449884,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85107938179&doi=10.1145%2f3442381.3449884&partnerID=40&md5=0430aa9cfae054881f73a1bffa3a482d,"Leibniz University Hannover, Germany; Fudan University, China; Microsoft Research Asia, China","Wu W., Leibniz University Hannover, Germany; Li B., Fudan University, China; Luo C., Microsoft Research Asia, China; Nejdl W., Leibniz University Hannover, Germany","Networks are ubiquitous in the real world. Link prediction, as one of the key problems for network-structured data, aims to predict whether there exists a link between two nodes. The traditional approaches are based on the explicit similarity computation between the compact node representation by embedding each node into a low-dimensional space. In order to efficiently handle the intensive similarity computation in link prediction, the hashing technique has been successfully used to produce the node representation in the Hamming space. However, the hashing-based link prediction algorithms face accuracy loss from the randomized hashing techniques or inefficiency from the learning to hash techniques in the embedding process. Currently, the Graph Neural Network (GNN) framework has been widely applied to the graph-related tasks in an end-to-end manner, but it commonly requires substantial computational resources and memory costs due to massive parameter learning, which makes the GNN-based algorithms impractical without the help of a powerful workhorse. In this paper, we propose a simple and effective model called #GNN, which balances the trade-off between accuracy and efficiency. #GNN is able to efficiently acquire node representation in the Hamming space for link prediction by exploiting the randomized hashing technique to implement message passing and capture high-order proximity in the GNN framework. Furthermore, we characterize the discriminative power of #GNN in probability. The extensive experimental results demonstrate that the proposed #GNN algorithm achieves accuracy comparable to the learning-based algorithms and outperforms the randomized algorithm, while running significantly faster than the learning-based algorithms. Also, the proposed algorithm shows excellent scalability on a large-scale network with the limited resources. Â© 2021 ACM.",Attributed Network; Graph Neural Networks; Hashing; Link Prediction,Economic and social effects; Embeddings; Forecasting; Graph algorithms; Learning algorithms; Message passing; World Wide Web; Computational resources; Discriminative power; Graph neural networks; Learning-based algorithms; Low-dimensional spaces; Randomized Algorithms; Similarity computation; Traditional approaches; Neural networks,Conference paper,Final,All Open Access; Green Open Access,Scopus,2-s2.0-85107938179
83,Wang Z.; Di S.; Chen L.,"Wang, Zhili (57370538100); Di, Shimin (57203394790); Chen, Lei (56442948300)",57370538100; 57203394790; 56442948300,AutoGEL: An Automated Graph Neural Network with Explicit Link Information,2021,Advances in Neural Information Processing Systems,29,,,24509,24522,13,18,,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85131951044&partnerID=40&md5=7308b1e5e126274659107bd63edd84f0,"Department of Computer Science and Engineering, Hong Kong University of Science and Technology, Hong Kong","Wang Z., Department of Computer Science and Engineering, Hong Kong University of Science and Technology, Hong Kong; Di S., Department of Computer Science and Engineering, Hong Kong University of Science and Technology, Hong Kong; Chen L., Department of Computer Science and Engineering, Hong Kong University of Science and Technology, Hong Kong","Recently, Graph Neural Networks (GNNs) have gained popularity in a variety of real-world scenarios. Despite the great success, the architecture design of GNNs heavily relies on manual labor. Thus, automated graph neural network (AutoGNN) has attracted interest and attention from the research community, which makes significant performance improvements in recent years. However, existing AutoGNN works mainly adopt an implicit way to model and leverage the link information in the graphs, which is not well regularized to the link prediction task on graphs, and limits the performance of AutoGNN for other graph tasks. In this paper, we present a novel AutoGNN work that explicitly models the link information, abbreviated to AutoGEL. In such a way, AutoGEL can handle the link prediction task and improve the performance of AutoGNNs on the node classification and graph classification task. Specifically, AutoGEL proposes a novel search space containing various design dimensions at both intra-layer and inter-layer designs and adopts a more robust differentiable search algorithm to further improve efficiency and effectiveness. Experimental results on benchmark data sets demonstrate the superiority of AutoGEL on several tasks. © 2021 Neural information processing systems foundation. All rights reserved.",,Architecture designs; Graph classification; Graph neural networks; Link informations; Link prediction; Manual labors; Performance; Prediction tasks; Real-world scenario; Research communities,Conference paper,Final,,Scopus,2-s2.0-85131951044
84,Wang H.; Yin H.; Zhang M.; Li P.,"Wang, Haorui (57219550868); Yin, Haoteng (57204471082); Zhang, Muhan (57191868624); Li, Pan (55495089200)",57219550868; 57204471082; 57191868624; 55495089200,EQUIVARIANT AND STABLE POSITIONAL ENCODING FOR MORE POWERFUL GRAPH NEURAL NETWORKS,2022,ICLR 2022 - 10th International Conference on Learning Representations,,,,,,,18,,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85150395012&partnerID=40&md5=0f47128004026d8823d3e670935d40c3,"School of Computer Science, Wuhan University, China; Department of Computer Science, Purdue University, United States; Institute for Artificial Intelligence, Peking University, China; BIGAI","Wang H., School of Computer Science, Wuhan University, China, Department of Computer Science, Purdue University, United States; Yin H., Department of Computer Science, Purdue University, United States; Zhang M., Institute for Artificial Intelligence, Peking University, China, BIGAI; Li P., Department of Computer Science, Purdue University, United States","Graph neural networks (GNN) have shown great advantages in many graph-based learning tasks but often fail to predict accurately for a task based on sets of nodes such as link/motif prediction and so on. Many works have recently proposed to address this problem by using random node features or node distance features. However, they suffer from either slow convergence, inaccurate prediction or high complexity. In this work, we revisit GNNs that allow using positional features of nodes given by positional encoding (PE) techniques such as Laplacian Eigenmap, Deepwalk, etc.. GNNs with PE often get criticized because they are not generalizable to unseen graphs (inductive) or stable. Here, we study these issues in a principled way and propose a provable solution, a class of GNN layers termed PEG with rigorous mathematical analysis. PEG uses separate channels to update the original node features and positional features. PEG imposes permutation equivariance w.r.t. the original node features and rotation equivariance w.r.t. the positional features simultaneously. Extensive link prediction experiments over 8 real-world networks demonstrate the advantages of PEG in generalization and scalability. © 2022 ICLR 2022 - 10th International Conference on Learning Representationss. All rights reserved.",,Encoding (symbols); Forecasting; Graph structures; Graph theory; Graphic methods; Network coding; AS-links; Distance feature; Encodings; Equivariance; Graph neural networks; Graph-based learning; High complexity; Learning tasks; Slow convergences; Task-based; Graph neural networks,Conference paper,Final,,Scopus,2-s2.0-85150395012
85,Wang T.; Wan X.; Yao S.,"Wang, Tianming (57192315251); Wan, Xiaojun (7202533498); Yao, Shaowei (57220547852)",57192315251; 7202533498; 57220547852,Better AMR-to-text generation with graph structure reconstruction,2020,IJCAI International Joint Conference on Artificial Intelligence,2021-January,,,3919,3925,6,17,,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85095520365&partnerID=40&md5=1b49dfde28eca6fea89e3aa4c6a9a4e8,"Wangxuan Institute of Computer Technology, Peking University, MOE Key Laboratory of Computational Linguistics, Peking University, China","Wang T., Wangxuan Institute of Computer Technology, Peking University, MOE Key Laboratory of Computational Linguistics, Peking University, China; Wan X., Wangxuan Institute of Computer Technology, Peking University, MOE Key Laboratory of Computational Linguistics, Peking University, China; Yao S., Wangxuan Institute of Computer Technology, Peking University, MOE Key Laboratory of Computational Linguistics, Peking University, China","AMR-to-text generation is a challenging task of generating texts from graph-based semantic representations. Recent studies formalize this task a graph-to-sequence learning problem and use various graph neural networks to model graph structure. In this paper, we propose a novel approach that generates texts from AMR graphs while reconstructing the input graph structures. Our model employs graph attention mechanism to aggregate information for encoding the inputs. Moreover, better node representations are learned by optimizing two simple but effective auxiliary reconstruction objectives: link prediction objective which requires predicting the semantic relationship between nodes, and distance prediction objective which requires predicting the distance between nodes. Experimental results on two benchmark datasets show that our proposed model improves considerably over strong baselines and achieves new state-of-the-art. © 2020 Inst. Sci. inf., Univ. Defence in Belgrade. All rights reserved.",,Forecasting; Graphic methods; Neural networks; Semantics; Attention mechanisms; Benchmark datasets; Graph neural networks; Semantic relationships; Semantic representation; Sequence learning; Structure reconstruction; Text generations; Graph structures,Conference paper,Final,,Scopus,2-s2.0-85095520365
86,Ferreira D.; Freitas A.,"Ferreira, Deborah (57219543660); Freitas, Andre (36631806600)",57219543660; 36631806600,Premise selection in natural language mathematical texts,2020,Proceedings of the Annual Meeting of the Association for Computational Linguistics,,,,7365,7374,9,17,,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85098377521&partnerID=40&md5=4a00d14779ebd82b58b3d5dfe4388565,"Department of Computer Science, University of Manchester","Ferreira D., Department of Computer Science, University of Manchester; Freitas A., Department of Computer Science, University of Manchester","The discovery of supporting evidence for addressing complex mathematical problems is a semantically challenging task, which is still unexplored in the field of natural language processing for mathematical text. The natural language premise selection task consists in using conjectures written in both natural language and mathematical formulae to recommend premises that most likely will be useful to prove a particular statement. We propose an approach to solve this task as a link prediction problem, using Deep Convolutional Graph Neural Networks. This paper also analyses how different baselines perform in this task and shows that a graph structure can provide higher F1-score, especially when considering multi-hop premise selection. © 2020 Association for Computational Linguistics",,Computational linguistics; Convolutional neural networks; Graph structures; Natural language processing systems; F1 scores; Graph neural networks; Graph structures; Language processing; Link prediction; Mathematical formulas; Mathematical problems; Most likely; Natural languages; Prediction problem; Graph neural networks,Conference paper,Final,,Scopus,2-s2.0-85098377521
87,Guo Z.; Wang F.; Yao K.; Liang J.; Wang Z.,"Guo, Zhihao (58364319100); Wang, Feng (57199195749); Yao, Kaixuan (57210816961); Liang, Jiye (55552159700); Wang, Zhiqiang (55841534600)",58364319100; 57199195749; 57210816961; 55552159700; 55841534600,Multi-scale variational graph autoencoder for link prediction,2022,WSDM 2022 - Proceedings of the 15th ACM International Conference on Web Search and Data Mining,,,,334,342,8,17,10.1145/3488560.3498531,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85125800768&doi=10.1145%2f3488560.3498531&partnerID=40&md5=acc49044a1c6bcb7605c4314db24ef9d,"School of Computer and Information Technology, Shanxi University, Shanxi, Taiyuan, China","Guo Z., School of Computer and Information Technology, Shanxi University, Shanxi, Taiyuan, China; Wang F., School of Computer and Information Technology, Shanxi University, Shanxi, Taiyuan, China; Yao K., School of Computer and Information Technology, Shanxi University, Shanxi, Taiyuan, China; Liang J., School of Computer and Information Technology, Shanxi University, Shanxi, Taiyuan, China; Wang Z., School of Computer and Information Technology, Shanxi University, Shanxi, Taiyuan, China","Link prediction has become a significant research problem in deep learning, and the graph-based autoencoder model is one of the most important methods to solve it. The existing graph-based autoencoder models only learn a single set of distributions, which cannot accurately represent the mixed distribution in real graph data. Meanwhile, existing learning models have been greatly restricted when the graph data has insufficient attribute information and inaccurate topology information. In this paper, we propose a novel graph embedding framework, termed multi-scale variational graph autoencoder (MSVGAE), which learns multiple sets of low-dimensional vectors of different dimensions through the graph encoder to represent the mixed probability distribution of the original graph data, and performs multiple sampling in each dimension. Furthermore, a self-supervised learning strategy (i.e., graph feature reconstruction auxiliary learning) is introduced to fully use the graph attribute information to help the graph structure learning. Experiment studies on real-world graphs demonstrate that the proposed model achieves state-of-the-art performance compared with other baseline methods in link prediction tasks. Besides, the robustness analysis shows that the proposed MSVGAE method has obvious advantages in the processes of graph data with insufficient attribute information and inaccurate topology information. © 2022 ACM.",Graph autoencoder; Graph neural networks; Link prediction; Self-supervised learning,Deep learning; Forecasting; Graph structures; Graphic methods; Probability distributions; Topology; Attribute information; Auto encoders; Graph autoencoder; Graph data; Graph neural networks; Graph-based; Learn+; Link prediction; Multi-scales; Self-supervised learning; Graph neural networks,Conference paper,Final,,Scopus,2-s2.0-85125800768
88,Ding M.; Kong K.; Li J.; Zhu C.; Dickerson J.; Huang F.; Goldstein T.,"Ding, Mucong (57207737399); Kong, Kezhi (57221113199); Li, Jingling (57201620706); Zhu, Chen (57217437192); Dickerson, John (55363539800); Huang, Furong (55485863200); Goldstein, Tom (14055829100)",57207737399; 57221113199; 57201620706; 57217437192; 55363539800; 55485863200; 14055829100,VQ-GNN: A Universal Framework to Scale-up Graph Neural Networks using Vector Quantization,2021,Advances in Neural Information Processing Systems,9,,,6733,6746,13,16,,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85131878171&partnerID=40&md5=11178a2c195ac17958120f7a320f233b,"Department of Computer Science, University of Maryland, United States","Ding M., Department of Computer Science, University of Maryland, United States; Kong K., Department of Computer Science, University of Maryland, United States; Li J., Department of Computer Science, University of Maryland, United States; Zhu C., Department of Computer Science, University of Maryland, United States; Dickerson J., Department of Computer Science, University of Maryland, United States; Huang F., Department of Computer Science, University of Maryland, United States; Goldstein T., Department of Computer Science, University of Maryland, United States","Most state-of-the-art Graph Neural Networks (GNNs) can be defined as a form of graph convolution which can be realized by message passing between direct neighbors or beyond. To scale such GNNs to large graphs, various neighbor-, layer-, or subgraph-sampling techniques are proposed to alleviate the “neighbor explosion” problem by considering only a small subset of messages passed to the nodes in a mini-batch. However, sampling-based methods are difficult to apply to GNNs that utilize many-hops-away or global context each layer, show unstable performance for different tasks and datasets, and do not speed up model inference. We propose a principled and fundamentally different approach, VQ-GNN, a universal framework to scale up any convolution-based GNNs using Vector Quantization (VQ) without compromising the performance. In contrast to sampling-based techniques, our approach can effectively preserve all the messages passed to a mini-batch of nodes by learning and updating a small number of quantized reference vectors of global node representations, using VQ within each GNN layer. Our framework avoids the “neighbor explosion” problem of GNNs using quantized representations combined with a low-rank version of the graph convolution matrix. We show that such a compact low-rank version of the gigantic convolution matrix is sufficient both theoretically and experimentally. In company with VQ, we design a novel approximated message passing algorithm and a nontrivial back-propagation rule for our framework. Experiments on various types of GNN backbones demonstrate the scalability and competitive performance of our framework on large-graph node classification and link prediction benchmarks. © 2021 Neural information processing systems foundation. All rights reserved.",,Backpropagation; Benchmarking; Convolution; Graph theory; Message passing; Vector quantization; Convolution matrix; Explosion problems; Graph neural networks; Large graphs; Message-passing; Performance; Scale-up; State of the art; Subgraphs; Vector quantisation; Graph neural networks,Conference paper,Final,,Scopus,2-s2.0-85131878171
89,Zhang G.; Li M.; Deng H.; Xu X.; Liu X.; Zhang W.,"Zhang, Guangzhan (57224616592); Li, Menglu (57216838601); Deng, Huan (57434397800); Xu, Xinran (57216702809); Liu, Xuan (57389196900); Zhang, Wen (57190273716)",57224616592; 57216838601; 57434397800; 57216702809; 57389196900; 57190273716,SGNNMD: Signed graph neural network for predicting deregulation types of miRNA-disease associations,2022,Briefings in Bioinformatics,23,1,bbab464,,,,16,10.1093/bib/bbab464,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85123451896&doi=10.1093%2fbib%2fbbab464&partnerID=40&md5=d23a90b03c88273c2769826862e8971e,"College of Informatics, Huazhong Agricultural University, Wuhan, 430070, China","Zhang G., College of Informatics, Huazhong Agricultural University, Wuhan, 430070, China; Li M., College of Informatics, Huazhong Agricultural University, Wuhan, 430070, China; Deng H., College of Informatics, Huazhong Agricultural University, Wuhan, 430070, China; Xu X., College of Informatics, Huazhong Agricultural University, Wuhan, 430070, China; Liu X., College of Informatics, Huazhong Agricultural University, Wuhan, 430070, China; Zhang W., College of Informatics, Huazhong Agricultural University, Wuhan, 430070, China","MiRNAs are a class of small non-coding RNA molecules that play an important role in many biological processes, and determining miRNA-disease associations can benefit drug development and clinical diagnosis. Although great efforts have been made to develop miRNA-disease association prediction methods, few attention has been paid to in-depth classification of miRNA-disease associations, e.g. up/down-regulation of miRNAs in diseases. In this paper, we regard known miRNA-disease associations as a signed bipartite network, which has miRNA nodes, disease nodes and two types of edges representing up/down-regulation of miRNAs in diseases, and propose a signed graph neural network method (SGNNMD) for predicting deregulation types of miRNA-disease associations. SGNNMD extracts subgraphs around miRNA-disease pairs from the signed bipartite network and learns structural features of subgraphs via a labeling algorithm and a neural network, and then combines them with biological features (i.e. miRNA-miRNA functional similarity and disease-disease semantic similarity) to build the prediction model. In the computational experiments, SGNNMD achieves highly competitive performance when compared with several baselines, including the signed graph link prediction methods, multi-relation prediction methods and one existing deregulation type prediction method. Moreover, SGNNMD has good inductive capability and can generalize to miRNAs/diseases unseen during the training. © 2021 The Author(s) 2021. Published by Oxford University Press. All rights reserved.",graph convolutional network; miRNA-disease associations; signed network; subgraph,"Algorithms; Computational Biology; Down-Regulation; MicroRNAs; Neural Networks, Computer; microRNA; algorithm; biology; down regulation; genetics; procedures",Article,Final,,Scopus,2-s2.0-85123451896
90,Zhou H.; Zheng D.; Nisa I.; Ioannidis V.; Song X.; Karypis G.,"Zhou, Hongkuan (57221064874); Zheng, Da (55342815200); Nisa, Israt (57193706160); Ioannidis, Vasileios (57193748200); Song, Xiang (57220896162); Karypis, George (15069396800)",57221064874; 55342815200; 57193706160; 57193748200; 57220896162; 15069396800,TGL: A General Framework for Temporal GNN Training on Billion-Scale Graphs,2022,Proceedings of the VLDB Endowment,15,8,,1572,1580,8,16,10.14778/3529337.3529342,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85137831977&doi=10.14778%2f3529337.3529342&partnerID=40&md5=079bc6779fc933f68ee04e7d330c716e,"University of Southern California, United States; AWS AI, United States","Zhou H., University of Southern California, United States; Zheng D., AWS AI, United States; Nisa I., AWS AI, United States; Ioannidis V., AWS AI, United States; Song X., AWS AI, United States; Karypis G., AWS AI, United States","Many real world graphs contain time domain information. Temporal Graph Neural Networks capture temporal information as well as structural and contextual information in the generated dynamic node embeddings. Researchers have shown that these embeddings achieve state-of-the-art performance in many different tasks. In this work, we propose TGL, a unified framework for large-scale offline Temporal Graph Neural Network training where users can compose various Temporal Graph Neural Networks with simple configuration files. TGL comprises five main components, a temporal sampler, a mailbox, a node memory module, a memory updater, and a message passing engine. We design a Temporal-CSR data structure and a parallel sampler to efficiently sample temporal neighbors to form training mini-batches. We propose a novel random chunk scheduling technique that mitigates the problem of obsolete node memory when training with a large batch size. To address the limitations of current TGNNs only being evaluated on small-scale datasets, we introduce two large-scale real-world datasets with 0.2 and 1.3 billion temporal edges. We evaluate the performance of TGL on four small-scale datasets with a single GPU and the two large datasets with multiple GPUs for both link prediction and node classification tasks. We compare TGL with the open-sourced code of five methods and show that TGL achieves similar or better accuracy with an average of 13× speedup. Our temporal parallel sampler achieves an average of 173× speedup on a multi-core CPU compared with the baselines. On a 4-GPU machine, TGL can train one epoch of more than one billion temporal edges within 1-10 hours. To the best of our knowledge, this is the first work that proposes a general framework for large-scale Temporal Graph Neural Networks training on multiple GPUs. © 2022, American Mathematical Society. All rights reserved.",,Classification (of information); Graph neural networks; Large dataset; Message passing; Program processors; Time domain analysis; Domain informations; Embeddings; Graph neural networks; Large-scales; Multiple GPUs; Neural networks trainings; Real-world graphs; Small scale; Temporal graphs; Time domain; Embeddings,Conference paper,Final,,Scopus,2-s2.0-85137831977
91,Wu Y.; Song Y.; Huang H.; Ye F.; Xie X.; Jin H.,"Wu, Yao (57221579760); Song, Yu (57221161135); Huang, Hong (57149409900); Ye, Fanghua (57195127057); Xie, Xing (57221820833); Jin, Hai (56434989100)",57221579760; 57221161135; 57149409900; 57195127057; 57221820833; 56434989100,Enhancing Graph Neural Networks via auxiliary training for semi-supervised node classification,2021,Knowledge-Based Systems,220,,106884,,,,16,10.1016/j.knosys.2021.106884,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85102114608&doi=10.1016%2fj.knosys.2021.106884&partnerID=40&md5=a4f510a44d5082226738e804d551be67,"National Engineering Research Center for Big Data Technology and System, Services Computing Technology and System Lab, Cluster and Grid Computing Lab, Huazhong University of Science and Technology, Wuhan, China; University College London, London, United Kingdom; Microsoft Research Asia, Beijing, China","Wu Y., National Engineering Research Center for Big Data Technology and System, Services Computing Technology and System Lab, Cluster and Grid Computing Lab, Huazhong University of Science and Technology, Wuhan, China; Song Y., National Engineering Research Center for Big Data Technology and System, Services Computing Technology and System Lab, Cluster and Grid Computing Lab, Huazhong University of Science and Technology, Wuhan, China; Huang H., National Engineering Research Center for Big Data Technology and System, Services Computing Technology and System Lab, Cluster and Grid Computing Lab, Huazhong University of Science and Technology, Wuhan, China; Ye F., University College London, London, United Kingdom; Xie X., Microsoft Research Asia, Beijing, China; Jin H., National Engineering Research Center for Big Data Technology and System, Services Computing Technology and System Lab, Cluster and Grid Computing Lab, Huazhong University of Science and Technology, Wuhan, China","Graph Neural Networks (GNNs) have been successfully applied to graph analysis tasks. As a canonical task in graph analysis, node classification has achieved promising results with GNNs. However, training GNNs remains challenging when training samples are limited. For the node classification task, only the known node labels are used as supervision information to train GNNs, while the implicit information of pairwise relationships between nodes is neglected. The label-to-label relationship of node pairs is explicit in labeled nodes and not utilized. Moreover, it is found that the link relationship in a graph is correlated with the labels between nodes in some graphs, like information network. Based on that, we can extract and establish labels for pairwise nodes. With the supervision of labeled pairwise nodes, it can force the predicted labels to conform to the observed pairwise relationships and provide some useful information to boost performance. In view of this, we utilize pairwise relationships by introducing the auxiliary task, node pair classification or link prediction, and propose a novel training framework for enhancing GNNs, namely EGNN. Via jointly training node classification with the auxiliary task, our framework achieves higher classification accuracy for general GNNs models with only a little extra computational cost. Moreover, the adaptive dynamic weighting strategy is designed to balance the training pace of different tasks automatically. We conduct extensive experiments, and the evaluation results suggest the superiority of our framework. © 2021 Elsevier B.V.",Auxiliary task; Graph neural networks; Node classification; Semi-supervised learning,Graph theory; Information services; Supervised learning; Auxiliary task; Classification tasks; Graph analysis; Graph neural networks; Implicit informations; Node classification; Node pairs; Semi-supervised; Semi-supervised learning; Training sample; Classification (of information),Article,Final,,Scopus,2-s2.0-85102114608
92,Li W.; Zhang X.; Wang Y.; Yan Z.; Peng R.,"Li, Weidong (57211275765); Zhang, Xinyu (57197844597); Wang, Yaqian (57211277840); Yan, Zhihuan (57211275117); Peng, Rong (7102381513)",57211275765; 57197844597; 57211277840; 57211275117; 7102381513,Graph2Seq: Fusion Embedding Learning for Knowledge Graph Completion,2019,IEEE Access,7,,8886405,157960,157971,11,16,10.1109/ACCESS.2019.2950230,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85077960920&doi=10.1109%2fACCESS.2019.2950230&partnerID=40&md5=817c83a397d975b7c61d7bacb2d91137,"School of Computer Science, Wuhan University, Wuhan, 430072, China","Li W., School of Computer Science, Wuhan University, Wuhan, 430072, China; Zhang X., School of Computer Science, Wuhan University, Wuhan, 430072, China; Wang Y., School of Computer Science, Wuhan University, Wuhan, 430072, China; Yan Z., School of Computer Science, Wuhan University, Wuhan, 430072, China; Peng R., School of Computer Science, Wuhan University, Wuhan, 430072, China","Knowledge Graph (KG) usually contains billions of facts about the real world, where a fact is represented as a triplet in the form of (head entity, relation, tail entity). KG is a complex network and consists of numerous nodes (entities) and edges (relations). Given that most KGs are noisy and far from being complete, KG analysis and completion methods are becoming more and more important. Knowledge graph embedding (KGE) aims to embed entities and relations in a low dimensional and continuous vector space, which is proven to be a quite efficient and effective method in knowledge graph completion tasks. KGE models devise various kinds of score functions to evaluate each fact in KG, which assign high points for true facts and low points for invalid ones. In a KG of the real world, some nodes may have hundreds of links with other nodes. There is a wealth of information around an entity, and the surrounding information (i.e., the sub-graph structure information) of one entity can make a significant contribution to predicting new facts. However, many previous works including, translational approaches such as Trans(E, H, R, and D), factorization approaches such as DistMult, ComplEx, and other deep learning approaches such as NTN, ConvE, concentrate on rating each fact in an isolated and separated way and lack a specially designed mechanism to learn the sub-graph structure information of the entity in KG. To conquer this challenge, we leverage the information fusion mechanism (Graph2Seq) used in graph neural network which is specially designed for graph-structured data, to learn fusion embeddings for entities in KG. And a novel fusion embedding learning KGE model (referred as G2SKGE) which aims to learn the sub-graph structure information of the entity in KG is proposed. With empirical experiments on four benchmark datasets, our proposed model achieves promising results and outperforms the state-of-the-art models. © 2019 IEEE.",graph neural network; information fusion; Knowledge graph completion; link prediction,Deep learning; Embeddings; Graphic methods; Information fusion; Vector spaces; Benchmark datasets; Empirical experiments; Factorization approach; Graph neural networks; Graph structured data; Knowledge graphs; Link prediction; Wealth of information; Complex networks,Article,Final,All Open Access; Gold Open Access,Scopus,2-s2.0-85077960920
93,Nguyen D.Q.; Tong V.; Phung D.; Nguyen D.Q.,"Nguyen, Dai Quoc (56283158300); Tong, Vinh (57223911262); Phung, Dinh (7003397144); Nguyen, Dat Quoc (35932254600)",56283158300; 57223911262; 7003397144; 35932254600,Node co-occurrence based graph neural networks for knowledge graph link prediction,2022,WSDM 2022 - Proceedings of the 15th ACM International Conference on Web Search and Data Mining,,,,1589,1592,3,16,10.1145/3488560.3502183,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85125801029&doi=10.1145%2f3488560.3502183&partnerID=40&md5=2e960478f1746e172bf53e4abd2a2d15,"Oracle Labs, Brisbane, Australia; VinAI Research, Hanoi, Viet Nam; Monash University, Melbourne, Australia","Nguyen D.Q., Oracle Labs, Brisbane, Australia; Tong V., VinAI Research, Hanoi, Viet Nam; Phung D., Monash University, Melbourne, Australia; Nguyen D.Q., VinAI Research, Hanoi, Viet Nam","We introduce a novel embedding model, named NoGE, which aims to integrate co-occurrence among entities and relations into graph neural networks to improve knowledge graph completion (i.e., link prediction). Given a knowledge graph, NoGE constructs a single graph considering entities and relations as individual nodes. NoGE then computes weights for edges among nodes based on the co-occurrence of entities and relations. Next, NoGE proposes Dual Quaternion Graph Neural Networks (DualQGNN) and utilizes DualQGNN to update vector representations for entity and relation nodes. NoGE then adopts a score function to produce the triple scores. Comprehensive experimental results show that NoGE obtains state-of-the-art results on three new and difficult benchmark datasets CoDEx for knowledge graph completion. © 2022 ACM.",Graph neural networks; Knowledge graph completion; Knowledge graph embeddings; Quaternion,Graph embeddings; Graph neural networks; Graph structures; Graph theory; Co-occurrence; Dual quaternion; Graph embeddings; Graph neural networks; Knowledge graph completion; Knowledge graph embedding; Knowledge graphs; Link prediction; Quaternion; Knowledge graph,Conference paper,Final,All Open Access; Green Open Access,Scopus,2-s2.0-85125801029
94,Sun X.; Yin H.; Liu B.; Chen H.; Meng Q.; Han W.; Cao J.,"Sun, Xiangguo (57203371177); Yin, Hongzhi (55007318200); Liu, Bo (55574235161); Chen, Hongxu (57213704736); Meng, Qing (57211445194); Han, Wang (57224581667); Cao, Jiuxin (14618987100)",57203371177; 55007318200; 55574235161; 57213704736; 57211445194; 57224581667; 14618987100,Multi-level hyperedge distillation for social linking prediction on sparsely observed networks,2021,"The Web Conference 2021 - Proceedings of the World Wide Web Conference, WWW 2021",,,,2934,2945,11,16,10.1145/3442381.3449912,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85107931056&doi=10.1145%2f3442381.3449912&partnerID=40&md5=a696e5f6c0fc07f32e197276311f5ecf,"Southeast University, China; University of Queensland, Australia; University of Technology Sydney, Australia","Sun X., Southeast University, China; Yin H., University of Queensland, Australia; Liu B., Southeast University, China; Chen H., University of Technology Sydney, Australia; Meng Q., Southeast University, China; Han W., Southeast University, China; Cao J., Southeast University, China","Social linking prediction is one of the most fundamental problems in online social networks and has attracted researchers' persistent attention. Most of the existing works predict unobserved links using graph neural networks (GNNs) to learn node embeddings upon pair-wise relations. Despite promising results given enough observed links, these models are still challenging to achieve heart-stirring performance when observed links are extremely limited. The main reason is that they only focus on the smoothness of node representations on pair-wise relations. Unfortunately, this assumption may fall when the networks do not have enough observed links to support it. To this end, we go beyond pair-wise relations and propose a new and novel framework using hypergraph neural networks with multi-level hyperedge distillation strategies. To break through the limitations of sparsely observed links, we introduce the hypergraph to uncover higher-level relations, which is exceptionally crucial to deduce unobserved links. A hypergraph allows one edge to connect multiple nodes, making it easier to learn better higher-level relations for link prediction. To overcome the restrictions of manually designed hypergraphs, which is constant in most hypergraph researches, we propose a new method to learn high-quality hyperedges using three novel hyperedges distillation strategies automatically. The generated hyperedges are hierarchical and follow the power-law distribution, which can significantly improve the link prediction performance. To predict unobserved links, we present a novel hypergraph neural networks named HNN. HNN takes the multi-level hypergraphs as input and makes the node embeddings smooth on hyperedges instead of pair-wise links only. Extensive evaluations on four real-world datasets demonstrate our model's superior performance over state-of-the-art baselines, especially when the observed links are extremely reduced. Â© 2021 ACM.",Hypergraph learning; Linking prediction; Sparsely observed networks,Distillation; Distilleries; Embeddings; Forecasting; Graph theory; Social networking (online); World Wide Web; Graph neural networks; Link prediction; Multiple nodes; On-line social networks; Power law distribution; Real-world datasets; Social linking; State of the art; Neural networks,Conference paper,Final,,Scopus,2-s2.0-85107931056
95,Salha-Galvan G.; Lutzeyer J.F.; Dasoulas G.; Hennequin R.; Vazirgiannis M.,"Salha-Galvan, Guillaume (57224852512); Lutzeyer, Johannes F. (57218106165); Dasoulas, George (57218102755); Hennequin, Romain (36504173400); Vazirgiannis, Michalis (7004248278)",57224852512; 57218106165; 57218102755; 36504173400; 7004248278,Modularity-aware graph autoencoders for joint community detection and link prediction,2022,Neural Networks,153,,,474,495,21,16,10.1016/j.neunet.2022.06.021,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85133930326&doi=10.1016%2fj.neunet.2022.06.021&partnerID=40&md5=2f4f7d96855219891111a308d701b964,"Deezer Research, Paris, France; LIX, École Polytechnique, Institut Polytechnique de Paris, Palaiseau, France; Athens University of Economics and Business (AUEB), Athens, Greece","Salha-Galvan G., Deezer Research, Paris, France, LIX, École Polytechnique, Institut Polytechnique de Paris, Palaiseau, France; Lutzeyer J.F., LIX, École Polytechnique, Institut Polytechnique de Paris, Palaiseau, France; Dasoulas G., LIX, École Polytechnique, Institut Polytechnique de Paris, Palaiseau, France; Hennequin R., Deezer Research, Paris, France; Vazirgiannis M., LIX, École Polytechnique, Institut Polytechnique de Paris, Palaiseau, France, Athens University of Economics and Business (AUEB), Athens, Greece","Graph autoencoders (GAE) and variational graph autoencoders (VGAE) emerged as powerful methods for link prediction. Their performances are less impressive on community detection problems where, according to recent and concurring experimental evaluations, they are often outperformed by simpler alternatives such as the Louvain method. It is currently still unclear to which extent one can improve community detection with GAE and VGAE, especially in the absence of node features. It is moreover uncertain whether one could do so while simultaneously preserving good performances on link prediction. In this paper, we show that jointly addressing these two tasks with high accuracy is possible. For this purpose, we introduce and theoretically study a community-preserving message passing scheme, doping our GAE and VGAE encoders by considering both the initial graph structure and modularity-based prior communities when computing embedding spaces. We also propose novel training and optimization strategies, including the introduction of a modularity-inspired regularizer complementing the existing reconstruction losses for joint link prediction and community detection. We demonstrate the empirical effectiveness of our approach, referred to as Modularity-Aware GAE and VGAE, through in-depth experimental validation on various real-world graphs. © 2022",Community detection; Graph autoencoders; Graph neural networks; Link prediction; Modularity; Node embedding,"Neural Networks, Computer; Embeddings; Forecasting; Graph structures; Message passing; Population dynamics; Auto encoders; Community detection; Detection problems; Embeddings; Graph autoencoder; Graph neural networks; Link prediction; Modularity; Node embedding; Performance; article; autoencoder; doping; embedding; prediction; theoretical study; Graph neural networks",Article,Final,All Open Access; Green Open Access,Scopus,2-s2.0-85133930326
96,Spinelli I.; Scardapane S.; Hussain A.; Uncini A.,"Spinelli, Indro (57217151886); Scardapane, Simone (55772102700); Hussain, Amir (19734290900); Uncini, Aurelio (7005621339)",57217151886; 55772102700; 19734290900; 7005621339,FairDrop: Biased Edge Dropout for Enhancing Fairness in Graph Representation Learning,2022,IEEE Transactions on Artificial Intelligence,3,3,,344,354,10,15,10.1109/TAI.2021.3133818,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85132958155&doi=10.1109%2fTAI.2021.3133818&partnerID=40&md5=bc9758f25d2b995a92d9631f3e3e57cc,"Sapienza University of Rome, Department of Information Engineering, Electronics and Telecommunications, Rome, 00184, Italy; Edinburgh Napier University, School of Computing, Edinburgh, EH10 5DT, United Kingdom","Spinelli I., Sapienza University of Rome, Department of Information Engineering, Electronics and Telecommunications, Rome, 00184, Italy; Scardapane S., Sapienza University of Rome, Department of Information Engineering, Electronics and Telecommunications, Rome, 00184, Italy; Hussain A., Edinburgh Napier University, School of Computing, Edinburgh, EH10 5DT, United Kingdom; Uncini A., Sapienza University of Rome, Department of Information Engineering, Electronics and Telecommunications, Rome, 00184, Italy","Graph representation learning has become a ubiquitous component in many scenarios, ranging from social network analysis to energy forecasting in smart grids. In several applications, ensuring the fairness of the node (or graph) representations with respect to some protected attributes is crucial for their correct deployment. Yet, fairness in graph deep learning remains underexplored, with few solutions available. In particular, the tendency of similar nodes to cluster on several real-world graphs (i.e., homophily) can dramatically worsen the fairness of these procedures. In this article, we propose a novel biased edge dropout algorithm (FairDrop) to counter-act homophily and improve fairness in graph representation learning. FairDrop can be plugged in easily on many existing algorithms, is efficient, adaptable, and can be combined with other fairness-inducing solutions. After describing the general algorithm, we demonstrate its application on two benchmark tasks, specifically, as a random walk model for producing node embeddings, and to a graph convolutional network for link prediction. We prove that the proposed algorithm can successfully improve the fairness of all models with only a small or negligible drop in accuracy, and compares favourably with existing state-of-the-art solutions. In an ablation study, we demonstrate that our algorithm can flexibly interpolate between biasing towards fairness and an unbiased edge dropout. Furthermore, to better evaluate the gains, we propose a new dyadic group definition to measure the bias of a link prediction task when paired with group-based fairness metrics. In particular, we extend the metric used to measure the bias in node embeddings by taking account of the graph structure. © 2020 IEEE.",Fairness; Graph embedding; Graph neural network; Graph representation learning; Link prediction,Benchmarking; Convolutional neural networks; Deep learning; Forecasting; Graph embeddings; Graph structures; Graph theory; Embeddings; Energy forecasting; Fairness; Graph embeddings; Graph neural networks; Graph representation; Graph representation learning; Homophily; Link prediction; Social Network Analysis; Graph neural networks,Article,Final,All Open Access; Green Open Access,Scopus,2-s2.0-85132958155
97,Lin L.; Wang H.,"Lin, Lu (57206479788); Wang, Hongning (48762142200)",57206479788; 48762142200,Graph Attention Networks over Edge Content-Based Channels,2020,Proceedings of the ACM SIGKDD International Conference on Knowledge Discovery and Data Mining,,,,1819,1827,8,15,10.1145/3394486.3403233,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85090407920&doi=10.1145%2f3394486.3403233&partnerID=40&md5=0593bcf5ef255784ec822b18285d2f90,"University of Virginia, Charlottesville, VA, United States","Lin L., University of Virginia, Charlottesville, VA, United States; Wang H., University of Virginia, Charlottesville, VA, United States","Edges play a crucial role in passing information on a graph, especially when they carry textual content reflecting semantics behind how nodes are linked and interacting with each other. In this paper, we propose a channel-aware attention mechanism enabled by edge text content when aggregating information from neighboring nodes; and we realize this mechanism in a graph autoencoder framework. Edge text content is encoded as low-dimensional mixtures of latent topics, which serve as semantic channels for topic-level information passing on edges. We embed nodes and topics in the same latent space to capture their mutual dependency when decoding the structural and textual information on graph. We evaluated the proposed model on Yelp user-item bipartite graph and StackOverflow user-user interaction graph. The proposed model outperformed a set of baselines on link prediction and content prediction tasks. Qualitative evaluations also demonstrated the descriptive power of the learnt node embeddings, showing its potential as an interpretable representation of graphs. © 2020 ACM.",graph neural networks; representation learning; topic modeling; variational auto-encoder,Data mining; Semantics; Attention mechanisms; Bipartite graphs; Interpretable representation; Mutual dependencies; Neighboring nodes; Prediction tasks; Qualitative evaluations; Textual information; Graph theory,Conference paper,Final,All Open Access; Bronze Open Access,Scopus,2-s2.0-85090407920
98,Alrahis L.; Patnaik S.; Hanif M.A.; Shafique M.; Sinanoglu O.,"Alrahis, Lilas (57202131710); Patnaik, Satwik (57210238553); Hanif, Muhammad Abdullah (57194855888); Shafique, Muhammad (17435669500); Sinanoglu, Ozgur (6701712277)",57202131710; 57210238553; 57194855888; 17435669500; 6701712277,UNTANGLE: Unlocking Routing and Logic Obfuscation Using Graph Neural Networks-based Link Prediction,2021,"IEEE/ACM International Conference on Computer-Aided Design, Digest of Technical Papers, ICCAD",2021-November,,,,,,15,10.1109/ICCAD51958.2021.9643476,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85121644628&doi=10.1109%2fICCAD51958.2021.9643476&partnerID=40&md5=288ecc0c76a5a6b2966cbe507d4cf5f1,"Division of Engineering, New York University, Abu Dhabi, United Arab Emirates; Electrical & Computer Engineering, Texas A&M University, College Station, TX, United States; Institute of Computer Engineering, Technische Universität Wien, Vienna, Austria","Alrahis L., Division of Engineering, New York University, Abu Dhabi, United Arab Emirates; Patnaik S., Electrical & Computer Engineering, Texas A&M University, College Station, TX, United States; Hanif M.A., Institute of Computer Engineering, Technische Universität Wien, Vienna, Austria; Shafique M., Division of Engineering, New York University, Abu Dhabi, United Arab Emirates; Sinanoglu O., Division of Engineering, New York University, Abu Dhabi, United Arab Emirates","Logic locking aims to prevent intellectual property (IP) piracy and unauthorized overproduction of integrated circuits (ICs). However, initial logic locking techniques were vulnerable to the Boolean satisfiability (SAT)-based attacks. In response, researchers proposed various SAT-resistant locking techniques such as point function-based locking and symmetric interconnection (SAT-hard) obfuscation. We focus on the latter since point function-based locking suffers from various structural vulnerabilities. The SAT-hard logic locking technique, InterLock [1], achieves a unified logic and routing obfuscation that thwarts state-of-the-art attacks on logic locking. In this work, we propose a novel link prediction-based attack, UNTANGLE, that successfully breaks InterLock in an oracle-less setting without having access to an activated IC (oracle). Since InterLock hides selected timing paths in key-controlled routing blocks, UNTANGLE reveals the gates and interconnections hidden in the routing blocks upon formulating this task as a link prediction problem. The intuition behind our approach is that ICs contain a large amount of repetition and reuse cores. Hence, UNTANGLE can infer the hidden timing paths by learning the composition of gates in the observed locked netlist or a circuit library leveraging graph neural networks. We show that circuits withstanding SAT-based and other attacks can be unlocked in seconds with 100% precision using UNTANGLE in an oracle-less setting. UNTANGLE is a generic attack platform (which we also open source [2]) that applies to multiplexer (MUX)-based obfuscation, as demonstrated through our experiments on ISCAS-85 and ITC-99 benchmarks locked using InterLock and random MUX-based locking. ©2021 IEEE",Graph neural networks; Link prediction; Logic locking; Oracle-less attacks; Routing obfuscation,Forecasting; Graph neural networks; Integrated circuits; Locks (fasteners); Network routing; Graph neural networks; Link prediction; Locking technique; Logic locking; Network-based; Oracle-less attack; Point-functions; Routing obfuscation; Routings; Satisfiability; Computer circuits,Conference paper,Final,All Open Access; Green Open Access,Scopus,2-s2.0-85121644628
99,Mei X.; Cai X.; Yang L.; Wang N.,"Mei, Xin (57219710183); Cai, Xiaoyan (55368428400); Yang, Libin (57198986816); Wang, Nanxin (57219708726)",57219710183; 55368428400; 57198986816; 57219708726,Relation-aware Heterogeneous Graph Transformer based drug repurposing[Formula presented],2022,Expert Systems with Applications,190,,116165,,,,15,10.1016/j.eswa.2021.116165,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85119361240&doi=10.1016%2fj.eswa.2021.116165&partnerID=40&md5=c144344c87aac931041e16f8cfee6da2,"School of Cyber Science and Technology, Northwestern Polytechnical University, Xi'an, Shaanxi, 710129, China; School of Automation, Northwestern Polytechnical University, Xi'an, Shaanxi, 710129, China","Mei X., School of Cyber Science and Technology, Northwestern Polytechnical University, Xi'an, Shaanxi, 710129, China; Cai X., School of Automation, Northwestern Polytechnical University, Xi'an, Shaanxi, 710129, China; Yang L., School of Cyber Science and Technology, Northwestern Polytechnical University, Xi'an, Shaanxi, 710129, China; Wang N., School of Cyber Science and Technology, Northwestern Polytechnical University, Xi'an, Shaanxi, 710129, China","Drug repurposing refers to discovery of new medical instructions for existing chemical drugs, which has great pharmaceutical significance. Recently, large-scale biological datasets are increasingly available, and many graph neural network (GNN) based methods for drug repurposing have been developed. These methods often deem drug repurposing as a link prediction problem, which mines features of biological data to identify drug–disease associations (i.e., drug–disease links). Due to heterogeneity of data, we need to deeply explore heterogeneous information of biological network for drug repurposing. In this paper, we propose a Relation-aware Heterogeneous Graph Transformer (RHGT) model to capture heterogeneous information for drug repurposing. We first construct a drug–gene–disease interactive network-based on biological data, and then propose a three-level network embedding model, which learns network embeddings at fine-grained subtype-level, node-level and coarse-grained edge-level, respectively. The output of subtype-level is the input of node-level and edge-level, and the output of node-level is the input of edge level. We get edge embeddings at edge-level, which integrates edge type embeddings and node embeddings. We deem that in this way, characteristics of drug–gene–disease interactive network can be captured more comprehensively. Finally, we identify drug–disease associations (i.e., drug–disease links) based on the relationship between drug–gene edge embeddings and gene–disease edge embeddings. Experimental results show that our model performs better than other state-of-the-art graph neural network methods, which validates effectiveness of the proposed model. © 2021 Elsevier Ltd",Drug repurposing; Graph neural network; Graph transformer; Heterogeneous network; Link prediction,Genes; Graph neural networks; Large dataset; Network embeddings; Biological data; Disease associations; Drug repurposing; Embeddings; Graph neural networks; Graph transformer; Heterogeneous graph; Link prediction; Network-based; Repurposing; Heterogeneous networks,Article,Final,,Scopus,2-s2.0-85119361240
100,Sarkar A.; Mehta N.; Rai P.,"Sarkar, Arindam (56258260600); Mehta, Nikhil (57215115389); Rai, Piyush (36768797700)",56258260600; 57215115389; 36768797700,Graph representation learning via ladder gamma variational autoencoders,2020,AAAI 2020 - 34th AAAI Conference on Artificial Intelligence,,,,5604,5611,7,15,,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85106580117&partnerID=40&md5=f80e4fc609686127d6248bc1150e8f5b,"Amazon, India; Duke University, United States; IIT Kanpur, India","Sarkar A., Amazon, India, IIT Kanpur, India; Mehta N., Duke University, United States, IIT Kanpur, India; Rai P., IIT Kanpur, India","We present a probabilistic framework for community discovery and link prediction for graph-structured data, based on a novel, gamma ladder variational autoencoder (VAE) architecture. We model each node in the graph via a deep hierarchy of gamma-distributed embeddings, and define each link probability via a nonlinear function of the bottom-most layer's embeddings of its associated nodes. In addition to leveraging the representational power of multiple layers of stochastic variables via the ladder VAE architecture, our framework offers the following benefits: (1) Unlike existing ladder VAE architectures based on real-valued latent variables, the gamma-distributed latent variables naturally result in non-negativity and sparsity of the learned embeddings, and facilitate their direct interpretation as membership of nodes into (possibly multiple) communities/topics; (2) A novel recognition model for our gamma ladder VAE architecture allows fast inference of node embeddings; and (3) The framework also extends naturally to incorporate node side information (features and/or labels). Our framework is also fairly modular and can leverage a wide variety of graph neural networks as the VAE encoder. We report both quantitative and qualitative results on several benchmark datasets and compare our model with several state-of-the-art methods. © 2020, Association for the Advancement of Artificial Intelligence (www.aaai.org). All rights reserved.",,Architecture; Embeddings; Ladders; Learning systems; Network architecture; Neural networks; Stochastic models; Stochastic systems; Community discoveries; Graph neural networks; Graph representation; Graph structured data; Nonlinear functions; Probabilistic framework; State-of-the-art methods; Stochastic variable; Graph structures,Conference paper,Final,,Scopus,2-s2.0-85106580117
101,Yin J.; Tang M.; Cao J.; You M.; Wang H.; Alazab M.,"Yin, Jiao (54884588500); Tang, MingJian (57215896761); Cao, Jinli (7403353999); You, Mingshan (57215898907); Wang, Hua (7501735520); Alazab, Mamoun (36661792200)",54884588500; 57215896761; 7403353999; 57215898907; 7501735520; 36661792200,Knowledge-Driven Cybersecurity Intelligence: Software Vulnerability Coexploitation Behavior Discovery,2023,IEEE Transactions on Industrial Informatics,19,4,,5593,5601,8,14,10.1109/TII.2022.3192027,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85135205750&doi=10.1109%2fTII.2022.3192027&partnerID=40&md5=39eb7659eb86818259ca1cfad719452b,"Chongqing University of Arts and Sciences, School of Artificial Intelligence, Chongqing, 402160, China; Victoria University, Institute for Sustainable Industries and Liveable Cities, Melbourne, 3083, VIC, Australia; Westpac Banking Corporation, Sydney, 2000, NSW, Australia; La Trobe University, Department of Computer Science and Information Technology, Melbourne, 3083, VIC, Australia; Charles Darwin University, College of Engineering, It and Environment, Casuarina, 0810, NT, Australia","Yin J., Chongqing University of Arts and Sciences, School of Artificial Intelligence, Chongqing, 402160, China, Victoria University, Institute for Sustainable Industries and Liveable Cities, Melbourne, 3083, VIC, Australia; Tang M., Westpac Banking Corporation, Sydney, 2000, NSW, Australia; Cao J., La Trobe University, Department of Computer Science and Information Technology, Melbourne, 3083, VIC, Australia; You M., Victoria University, Institute for Sustainable Industries and Liveable Cities, Melbourne, 3083, VIC, Australia; Wang H., Victoria University, Institute for Sustainable Industries and Liveable Cities, Melbourne, 3083, VIC, Australia; Alazab M., Charles Darwin University, College of Engineering, It and Environment, Casuarina, 0810, NT, Australia","Coexploitation behavior, referring to multiple software vulnerabilities being exploited jointly by one or more exploits, brings enormous challenges to the prevention and remediation of cyberattacks. Leveraging the latest advances in graph-driven intelligence, this article formulates vulnerability coexploitation behavior discovery as a link prediction problem between vulnerability entities within a vulnerability knowledge graph. We propose a modality-aware graph convolutional network (MAGCN) module to embed multimodality entity attributes and topological graph connectivity features into a unified lower dimensional feature space to boost link prediction performance. We further design a graph knowledge transfer learning (GKTL) strategy to transfer knowledge between subgraphs extracted from the same knowledge graph. Experimental results on a real-world dataset containing coexploitation incidents between 1995 and 2021 show that MAGCN achieved 81.34% on the F1 score when applying the GKTL strategy, superior to other graph neural network modules, such as GCN, GraphSAGE, EdgeGCN, and GINGCN. © 2005-2012 IEEE.",Coexploitation discovery; graph embedding; knowledge graph (KG); link prediction; transfer learning,Forecasting; Job analysis; Knowledge management; Network security; Topology; Australia; Co-exploitation discovery; Features extraction; Graph embeddings; Informatics; Knowledge graphs; Link prediction; Software; Task analysis; Transfer learning; Knowledge graph,Article,Final,,Scopus,2-s2.0-85135205750
102,Choong J.J.; Liu X.; Murata T.,"Choong, Jun Jin (56024204800); Liu, Xin (56948501900); Murata, Tsuyoshi (7402737180)",56024204800; 56948501900; 7402737180,Optimizing variational graph autoencoder for community detection with dual optimization,2020,Entropy,22,2,197,,,,14,10.3390/e22020197,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85080954943&doi=10.3390%2fe22020197&partnerID=40&md5=dfca548031399f60911e85b52d56d675,"Department of Computer Science, Tokyo Institute of Technology, Tokyo, 152-8552, Japan; National Institute of Advanced Industrial Science and Technology, Tokyo, 135-0064, Japan","Choong J.J., Department of Computer Science, Tokyo Institute of Technology, Tokyo, 152-8552, Japan; Liu X., National Institute of Advanced Industrial Science and Technology, Tokyo, 135-0064, Japan; Murata T., Department of Computer Science, Tokyo Institute of Technology, Tokyo, 152-8552, Japan","Variational Graph Autoencoder (VGAE) has recently gained traction for learning representations on graphs. Its inception has allowed models to achieve state-of-the-art performance for challenging tasks such as link prediction, rating prediction, and node clustering. However, a fundamental flaw exists in Variational Autoencoder (VAE)-based approaches. Specifically, merely minimizing the loss of VAE increases the deviation from its primary objective. Focusing on Variational Graph Autoencoder for Community Detection (VGAECD) we found that optimizing the loss using the stochastic gradient descent often leads to sub-optimal community structure especially when initialized poorly. We address this shortcoming by introducing a dual optimization procedure. This procedure aims to guide the optimization process and encourage learning of the primary objective. Additionally, we linearize the encoder to reduce the number of learning parameters. The outcome is a robust algorithm that outperforms its predecessor. © 2020 by the authors.",Graph neural network; Network embedding; Variational autoencoder; Variational inference,,Article,Final,All Open Access; Gold Open Access; Green Open Access,Scopus,2-s2.0-85080954943
103,Zhang W.; Jiang Y.; Li Y.; Sheng Z.; Shen Y.; Miao X.; Wang L.; Yang Z.; Cui B.,"Zhang, Wentao (57193707840); Jiang, Yuezihan (57226610259); Li, Yang (57221715937); Sheng, Zeang (57226605634); Shen, Yu (57223756506); Miao, Xupeng (57210122795); Wang, Liang (57205024145); Yang, Zhi (56101984100); Cui, Bin (57211734542)",57193707840; 57226610259; 57221715937; 57226605634; 57223756506; 57210122795; 57205024145; 56101984100; 57211734542,ROD: Reception-aware Online Distillation for Sparse Graphs,2021,Proceedings of the ACM SIGKDD International Conference on Knowledge Discovery and Data Mining,,,,2232,2242,10,14,10.1145/3447548.3467221,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85114922113&doi=10.1145%2f3447548.3467221&partnerID=40&md5=0c15dd97d60e153ed98158069fce174e,"School of Eecs and Key Laboratory of High Confidence Software Technologies, Peking University, Beijing, China; Center for Data Science, Peking University and National Engineering Laboratory for Big Data Analysis and Applications, Beijing, China; Alibaba Group, Beijing, China","Zhang W., School of Eecs and Key Laboratory of High Confidence Software Technologies, Peking University, Beijing, China; Jiang Y., School of Eecs and Key Laboratory of High Confidence Software Technologies, Peking University, Beijing, China, Alibaba Group, Beijing, China; Li Y., School of Eecs and Key Laboratory of High Confidence Software Technologies, Peking University, Beijing, China; Sheng Z., School of Eecs and Key Laboratory of High Confidence Software Technologies, Peking University, Beijing, China; Shen Y., School of Eecs and Key Laboratory of High Confidence Software Technologies, Peking University, Beijing, China; Miao X., School of Eecs and Key Laboratory of High Confidence Software Technologies, Peking University, Beijing, China; Wang L., Alibaba Group, Beijing, China; Yang Z., School of Eecs and Key Laboratory of High Confidence Software Technologies, Peking University, Beijing, China; Cui B., School of Eecs and Key Laboratory of High Confidence Software Technologies, Peking University, Beijing, China, Center for Data Science, Peking University and National Engineering Laboratory for Big Data Analysis and Applications, Beijing, China","Graph neural networks (GNNs) have been widely used in many graph-based tasks such as node classification, link prediction, and node clustering. However, GNNs gain their performance benefits mainly from performing the feature propagation and smoothing across the edges of the graph, thus requiring sufficient connectivity and label information for effective propagation. Unfortunately, many real-world networks are sparse in terms of both edges and labels, leading to sub-optimal performance of GNNs. Recent interest in this sparse problem has focused on the self-training approach, which expands supervised signals with pseudo labels. Nevertheless, the self-training approach inherently cannot realize the full potential of refining the learning performance on sparse graphs due to the unsatisfactory quality and quantity of pseudo labels. In this paper, we propose ROD, a novel reception-aware online knowledge distillation approach for sparse graph learning. We design three supervision signals for ROD: multi-scale reception-aware graph knowledge, task-based supervision, and rich distilled knowledge, allowing online knowledge transfer in a peer-teaching manner. To extract knowledge concealed in the multi-scale reception fields, ROD explicitly requires individual student models to preserve different levels of locality information. For a given task, each student would predict based on its reception-scale knowledge, while simultaneously a strong teacher is established on-the-fly by combining multi-scale knowledge. Our approach has been extensively evaluated on 9 datasets and a variety of graph-based tasks, including node classification, link prediction, and node clustering. The result demonstrates that ROD achieves state-of-art performance and is more robust for the graph sparsity. © 2021 ACM.",graph neural networks; online distillation; reception field,Backpropagation; Classification (of information); Distillation; Distilleries; Forecasting; Graph theory; Graphic methods; Knowledge management; Learning systems; Neural networks; Graph neural networks; Knowledge transfer; Learning performance; Performance benefits; Real-world networks; Self-training approaches; State-of-art performance; Sub-optimal performance; Data mining,Conference paper,Final,All Open Access; Green Open Access,Scopus,2-s2.0-85114922113
104,Liu X.; Li X.; Fiumara G.; De Meo P.,"Liu, Xiaoyang (57218313547); Li, Xiang (57890948800); Fiumara, Giacomo (57724695100); De Meo, Pasquale (6507520114)",57218313547; 57890948800; 57724695100; 6507520114,Link prediction approach combined graph neural network with capsule network,2023,Expert Systems with Applications,212,,118737,,,,14,10.1016/j.eswa.2022.118737,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85138067125&doi=10.1016%2fj.eswa.2022.118737&partnerID=40&md5=9e41d4863c724f7fd4af4fa3d8a6eec5,"School of Computer Science and Engineering, Chongqing University of Technology, Chongqing, 400054, China; MIFT Department, University of Messina, V.le F. Stagno D'Alcontres, 31, Messina, 98166, Italy; Department of Ancient and Modern Civilizations, University of Messina, V.le G. Palatucci, 25, Messina, 98166, Italy","Liu X., School of Computer Science and Engineering, Chongqing University of Technology, Chongqing, 400054, China; Li X., School of Computer Science and Engineering, Chongqing University of Technology, Chongqing, 400054, China; Fiumara G., MIFT Department, University of Messina, V.le F. Stagno D'Alcontres, 31, Messina, 98166, Italy; De Meo P., Department of Ancient and Modern Civilizations, University of Messina, V.le G. Palatucci, 25, Messina, 98166, Italy","Graph Neural Networks (GNNs, in short) are a powerful computational tool to jointly learn graph structure and node/edge features. They achieved an unprecedented accuracy in the link prediction problem, namely the task of predicting if two nodes are likely to be tied by an edge in the near future. However, GNNs capture node attributes as scalars and such a representation can be non-optimal. In this paper we propose a link prediction approach which combines GNN with Capsule Networks (CapsNet), a powerful deep learning framework that obtained high quality representations when applied to image processing. Our approach first applies a GNN to generate node embeddings. Then, it makes use of a conversion block with the purpose of transforming node embeddings into a node pair feature map (called edge feature map). Because of such a transformation, the link prediction problem is equivalent to a graph classification problem. Finally, our approach applies CapsNets to learn the feature representation of the edge feature map, so that the attributes of the node pairs are captured from different aspects. We evaluate the feasibility and effectiveness of our approach (called Graph Conversion Capsule Link, GCCL in short) on six networks without node attributes and three networks with node attribute. Experimental results show that in both conditions (with and without node attributes) our approach is significantly more accurate than the competitor methods, with an average accuracy improvement of about 20%. © 2022 Elsevier Ltd",Capsule network; Complex networks; Graph neural network; Link prediction,Deep learning; Embeddings; Forecasting; Graph neural networks; Graph structures; Graph theory; Image processing; Capsule network; Edge features; Embeddings; Feature map; Graph neural networks; Learn+; Link prediction; Node attribute; Node pairs; Prediction problem; Complex networks,Article,Final,,Scopus,2-s2.0-85138067125
105,Zeb A.; Haq A.U.; Chen J.; Lei Z.; Zhang D.,"Zeb, Adnan (57219714654); Haq, Anwar Ul (57214706022); Chen, Junde (57201793640); Lei, Zhenfeng (57193712873); Zhang, Defu (57198601752)",57219714654; 57214706022; 57201793640; 57193712873; 57198601752,Learning hyperbolic attention-based embeddings for link prediction in knowledge graphs,2021,Knowledge-Based Systems,229,,107369,,,,14,10.1016/j.knosys.2021.107369,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85112395704&doi=10.1016%2fj.knosys.2021.107369&partnerID=40&md5=64b9759ac38e908fd96afc345bfd2ff9,"School of Informatics, Xiamen University, Xiamen, 361005, Fujian, China; Department of Computer Science & IT, University of Malakand, Chakdara, 18800, KP, Pakistan","Zeb A., School of Informatics, Xiamen University, Xiamen, 361005, Fujian, China; Haq A.U., School of Informatics, Xiamen University, Xiamen, 361005, Fujian, China, Department of Computer Science & IT, University of Malakand, Chakdara, 18800, KP, Pakistan; Chen J., School of Informatics, Xiamen University, Xiamen, 361005, Fujian, China; Lei Z., School of Informatics, Xiamen University, Xiamen, 361005, Fujian, China; Zhang D., School of Informatics, Xiamen University, Xiamen, 361005, Fujian, China","Knowledge graph (KG) embedding methods aim to learn low-dimensional representations of entities and relations to predict new valid triples for KG completion. Most of the existing KG embedding models learn embeddings in Euclidean space, which cannot accurately capture hierarchical structures and complex properties of relations found in KGs. To this effect, a recent model MuRP, as a first hyperbolic method, learns the KG embeddings in hyperbolic space and outperforms existing Euclidean embedding models. However, MuRP treats the KG triples individually, and hence fails to capture the complex structural information inherent in the local vicinity of a node, leading to low-quality node embeddings. On the other hand, the recent hyperbolic graph neural network (HGNN) provides a way of learning high-quality hyperbolic node embeddings by capturing information from each node's neighborhood. However, HGNN ignores the relation features and treats all neighboring nodes with equal importance. To this end, we propose RHGNN, which extends HGNN by including the relation features and performing a hyperbolic attention-based neighborhood aggregation. We then combine RHGNN with MuRP into a novel encoder–decoder hyperbolic embedding learning framework (which we call HyperGEL) for KG completion. RHGNN gathers information from the neighboring nodes to generate rich hyperbolic node embeddings, and MuRP uses these embeddings to predict new triples. Experimental results show the proposed framework's effectiveness that consistently marks performance gains over several previous models on recent standard KG completion datasets. © 2021",Graph neural network; Hyperbolic graph neural network; Knowledge graph; Link prediction; Poincaré ball model,Complex networks; Embeddings; Embeddings; Graph embeddings; Graph neural networks; Hyperbolic graph neural network; Hyperbolic graphs; Knowledge graphs; Learn+; Link prediction; Neighbourhood; Poincare ball model; Forecasting,Article,Final,,Scopus,2-s2.0-85112395704
106,Alrahis L.; Patnaik S.; Shafique M.; Sinanoglu O.,"Alrahis, Lilas (57202131710); Patnaik, Satwik (57210238553); Shafique, Muhammad (17435669500); Sinanoglu, Ozgur (6701712277)",57202131710; 57210238553; 17435669500; 6701712277,MuxLink: Circumventing Learning-Resilient MUX-Locking Using Graph Neural Network-based Link Prediction,2022,"Proceedings of the 2022 Design, Automation and Test in Europe Conference and Exhibition, DATE 2022",,,,694,699,5,14,10.23919/DATE54114.2022.9774603,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85130832768&doi=10.23919%2fDATE54114.2022.9774603&partnerID=40&md5=e54936d20caae2630404e6426f989304,"New York University Abu Dhabi, Division of Engineering, United Arab Emirates; Texas A&m University, Electrical & Computer Engineering, College Station, TX, United States","Alrahis L., New York University Abu Dhabi, Division of Engineering, United Arab Emirates; Patnaik S., Texas A&m University, Electrical & Computer Engineering, College Station, TX, United States; Shafique M., New York University Abu Dhabi, Division of Engineering, United Arab Emirates; Sinanoglu O., New York University Abu Dhabi, Division of Engineering, United Arab Emirates","Logic locking has received considerable interest as a prominent technique for protecting the design intellectual property from untrusted entities, especially the foundry. Recently, machine learning (ML)-based attacks have questioned the security guarantees of logic locking, and have demonstrated considerable success in deciphering the secret key without relying on an oracle, hence, proving to be very useful for an adversary in the fab. Such ML-based attacks have triggered the development of learning-resilient locking techniques. The most advanced state-of-the-art deceptive MUX-based locking (D-MUX) and the symmetric MUX-based locking techniques have recently demonstrated resilience against existing ML-based attacks. Both defense techniques obfuscate the design by inserting key-controlled MUX logic, ensuring that all the secret inputs to the MUXes are equiprobable. In this work, we show that these techniques primarily introduce local and limited changes to the circuit without altering the global structure of the design. By leveraging this observation, we propose a novel graph neural network (GNN)-based link prediction attack, MuxLink, that successfully breaks both the D-MUX and symmetric MUX-locking techniques, relying only on the underlying structure of the locked design, i.e., in an oracle-less setting. Our trained GNN model learns the structure of the given circuit and the composition of gates around the non-obfuscated wires, thereby generating meaningful link embeddings that help decipher the secret inputs to the MUXes. The proposed MuxLink achieves key prediction accuracy and precision up to 100% on D-MUX and symmetric MUX-locked ISCAS-85 and ITC-99 benchmarks, fully unlocking the designs. We open-source MuxLink [1]. © 2022 EDAA.",Deceptive Logic Locking; Graph Neural Networks; Link Prediction; Machine Learning; Oracle-less Attack,Forecasting; Graph neural networks; Locks (fasteners); Machine learning; Deceptive logic locking; Graph neural networks; Link prediction; Locking technique; Machine-learning; MUX-Based; Network-based; Oracle-less attack; Secret key; Symmetrics; Computer circuits,Conference paper,Final,All Open Access; Green Open Access,Scopus,2-s2.0-85130832768
107,Li L.; Zhang X.; Ma Y.; Gao C.; Wang J.; Yu Y.; Yuan Z.; Ma Q.,"Li, LinYu (57911464800); Zhang, Xuan (55874528800); Ma, YuBin (58400598000); Gao, Chen (57216186887); Wang, Jishu (57253875400); Yu, Yong (56143501600); Yuan, Zihao (57912055500); Ma, Qiuying (57912266500)",57911464800; 55874528800; 58400598000; 57216186887; 57253875400; 56143501600; 57912055500; 57912266500,A knowledge graph completion model based on contrastive learning and relation enhancement method,2022,Knowledge-Based Systems,256,,109889,,,,14,10.1016/j.knosys.2022.109889,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85139012861&doi=10.1016%2fj.knosys.2022.109889&partnerID=40&md5=96884d74c9169235c433a6e74630eb71,"School of Software, Yunnan University, Yunnan, 650091, China; Yunnan Key Laboratory of Software Engineering, Yunnan, 650091, China; Engineering Research Center of Cyberspace, Yunnan, 650091, China; School of Information Science & Engineering, Yunnan University, Yunnan, 650091, China","Li L., School of Software, Yunnan University, Yunnan, 650091, China; Zhang X., School of Software, Yunnan University, Yunnan, 650091, China, Yunnan Key Laboratory of Software Engineering, Yunnan, 650091, China, Engineering Research Center of Cyberspace, Yunnan, 650091, China; Ma Y., School of Software, Yunnan University, Yunnan, 650091, China; Gao C., School of Information Science & Engineering, Yunnan University, Yunnan, 650091, China; Wang J., School of Information Science & Engineering, Yunnan University, Yunnan, 650091, China; Yu Y., School of Software, Yunnan University, Yunnan, 650091, China, Yunnan Key Laboratory of Software Engineering, Yunnan, 650091, China, Engineering Research Center of Cyberspace, Yunnan, 650091, China; Yuan Z., School of Software, Yunnan University, Yunnan, 650091, China; Ma Q., School of Software, Yunnan University, Yunnan, 650091, China","The rapid development in knowledge graph (KG) technology and its popularity in the field of artificial intelligence (AI) have significantly increased the support for similar KG-based applications. However, there is a concerning problem regarding KGs; most of them are often incomplete. This motivated us to study knowledge graph completion (KGC). Some recent studies have used graph neural networks (GNN) such as graph convolutional networks (GCN) to model graph-structured data, providing good results on KGC tasks. However, the edge weights in GCN models are controlled by degree, a measure that moderately ignores the differences among relation information. To address the above limitations and obtain better KGC, we propose a model based on graph attention networks (GATs) and contrastive learning (CL), called the CLGAT-KGC model. This model introduces the graph attention mechanism and adds different representations of entities under the same entity corresponding to different relations to enhance the entity-relation message function. Additionally, a new CL method is proposed under the CLGAT-KGC model to better learn the embedding of entities and relations in the KG domain. We have completely verified the effectiveness of this model through extensive experiments. © 2022 Elsevier B.V.",Contrastive learning; Graph attention network; Knowledge graph; Knowledge graph completion; Link prediction,Graph neural networks; Learning systems; Contrastive learning; Convolutional networks; Graph attention network; Graph neural networks; Graph-based; Knowledge graph completion; Knowledge graphs; Link prediction; Model-based OPC; Knowledge graph,Article,Final,,Scopus,2-s2.0-85139012861
108,Sun D.; Li D.; Ding Z.; Zhang X.; Tang J.,"Sun, Dengdi (22836691000); Li, Dashuang (57296037100); Ding, Zhuanlian (55781500500); Zhang, Xingyi (25654078600); Tang, Jin (24286986300)",22836691000; 57296037100; 55781500500; 25654078600; 24286986300,Dual-decoder graph autoencoder for unsupervised graph representation learning,2021,Knowledge-Based Systems,234,,107564,,,,14,10.1016/j.knosys.2021.107564,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85117144128&doi=10.1016%2fj.knosys.2021.107564&partnerID=40&md5=912e85d51e90af656100a25d6ce55728,"Key Laboratory of Intelligent Computing & Signal Processing (ICSP), Ministry of Education, School of Artificial Intelligence, Anhui University, Hefei, 230601, China; Anhui Provincial Key Laboratory of Multimodal Cognitive Computing, School of Computer Science and Technology, Anhui University, Hefei, 230601, China; School of Internet, Anhui University, Hefei, 230039, China","Sun D., Key Laboratory of Intelligent Computing & Signal Processing (ICSP), Ministry of Education, School of Artificial Intelligence, Anhui University, Hefei, 230601, China, Anhui Provincial Key Laboratory of Multimodal Cognitive Computing, School of Computer Science and Technology, Anhui University, Hefei, 230601, China; Li D., Anhui Provincial Key Laboratory of Multimodal Cognitive Computing, School of Computer Science and Technology, Anhui University, Hefei, 230601, China; Ding Z., School of Internet, Anhui University, Hefei, 230039, China; Zhang X., Key Laboratory of Intelligent Computing & Signal Processing (ICSP), Ministry of Education, School of Artificial Intelligence, Anhui University, Hefei, 230601, China, Anhui Provincial Key Laboratory of Multimodal Cognitive Computing, School of Computer Science and Technology, Anhui University, Hefei, 230601, China; Tang J., Anhui Provincial Key Laboratory of Multimodal Cognitive Computing, School of Computer Science and Technology, Anhui University, Hefei, 230601, China","Unsupervised graph representation learning is a challenging task that embeds graph data into a low-dimensional space without label guidance. Recently, graph autoencoders have been proven to be an effective way to solve this problem in some attributed networks. However, most existing graph autoencoder-based embedding algorithms only reconstruct the feature maps of nodes or the affinity matrix but do not fully leverage the latent information encoded in the low-dimensional representation. In this study, we propose a dual-decoder graph autoencoder model for attributed graph embedding. The proposed framework embeds the graph topological structure and node attributes into a compact representation, and then the two decoders are trained to reconstruct the node attributes and graph structures simultaneously. The experimental results on clustering and link prediction tasks strongly support the conclusion that the proposed model outperforms the state-of-the-art approaches. © 2021 Elsevier B.V.",Graph autoencoder; Graph clustering; Graph embedding; Graph neural networks; Graph representation learning,Decoding; Embeddings; Graph structures; Graph theory; Auto encoders; Graph autoencoder; Graph clustering; Graph data; Graph embeddings; Graph neural networks; Graph representation; Graph representation learning; Low-dimensional spaces; Node attribute; Graph neural networks,Article,Final,,Scopus,2-s2.0-85117144128
109,Ali M.; Berrendorf M.; Galkin M.; Thost V.; Ma T.; Tresp V.; Lehmann J.,"Ali, Mehdi (57211031203); Berrendorf, Max (57207581580); Galkin, Mikhail (56118894800); Thost, Veronika (55821112400); Ma, Tengfei (57194786822); Tresp, Volker (6603805670); Lehmann, Jens (35229806900)",57211031203; 57207581580; 56118894800; 55821112400; 57194786822; 6603805670; 35229806900,Improving Inductive Link Prediction Using Hyper-relational Facts,2021,Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics),12922 LNCS,,,74,92,18,13,10.1007/978-3-030-88361-4_5,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85116905779&doi=10.1007%2f978-3-030-88361-4_5&partnerID=40&md5=e15e05e281c2197dee98242581f695ee,"Smart Data Analytics Group, University of Bonn, Bonn, Germany; Fraunhofer Institute for Intelligent Analysis and Information Systems (IAIS), Sankt Augustin, Dresden, Germany; Ludwig-Maximilians-Universität München, Munich, Germany; Mila, McGill University, Montreal, Canada; IBM Research, MIT-IBM Watson AI Lab, Cambridge, United States; Siemens AG, Munich, Germany","Ali M., Smart Data Analytics Group, University of Bonn, Bonn, Germany, Fraunhofer Institute for Intelligent Analysis and Information Systems (IAIS), Sankt Augustin, Dresden, Germany; Berrendorf M., Ludwig-Maximilians-Universität München, Munich, Germany; Galkin M., Mila, McGill University, Montreal, Canada; Thost V., IBM Research, MIT-IBM Watson AI Lab, Cambridge, United States; Ma T., IBM Research, MIT-IBM Watson AI Lab, Cambridge, United States; Tresp V., Ludwig-Maximilians-Universität München, Munich, Germany, Siemens AG, Munich, Germany; Lehmann J., Smart Data Analytics Group, University of Bonn, Bonn, Germany, Fraunhofer Institute for Intelligent Analysis and Information Systems (IAIS), Sankt Augustin, Dresden, Germany","For many years, link prediction on knowledge graphs (KGs) has been a purely transductive task, not allowing for reasoning on unseen entities. Recently, increasing efforts are put into exploring semi- and fully inductive scenarios, enabling inference over unseen and emerging entities. Still, all these approaches only consider triple-based KGs, whereas their richer counterparts, hyper-relational KGs (e.g., Wikidata), have not yet been properly studied. In this work, we classify different inductive settings and study the benefits of employing hyper-relational KGs on a wide range of semi- and fully inductive link prediction tasks powered by recent advancements in graph neural networks. Our experiments on a novel set of benchmarks show that qualifiers over typed edges can lead to performance improvements of 6% of absolute gains (for the Hits@10 metric) compared to triple-only baselines. Our code is available at https://github.com/mali-git/hyper_relational_ilp. © 2021, Springer Nature Switzerland AG.",,Benchmarking; Forecasting; Absolute gain; Graph neural networks; Inductive link; Knowledge graphs; Link prediction; Performance; Prediction tasks; Knowledge graph,Conference paper,Final,All Open Access; Green Open Access,Scopus,2-s2.0-85116905779
110,Li Z.; Zhang Q.; Zhu F.; Li D.; Zheng C.; Zhang Y.,"Li, Zhifei (57211530031); Zhang, Qi (58109809000); Zhu, Fangfang (57204146124); Li, Duantengchuan (57224130334); Zheng, Chao (57329037400); Zhang, Yan (57193723911)",57211530031; 58109809000; 57204146124; 57224130334; 57329037400; 57193723911,Knowledge graph representation learning with simplifying hierarchical feature propagation,2023,Information Processing and Management,60,4,103348,,,,13,10.1016/j.ipm.2023.103348,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85151353602&doi=10.1016%2fj.ipm.2023.103348&partnerID=40&md5=1c4edd845bcfee70a1ea7314dc3d61bb,"School of Computer Science and Information Engineering, Hubei University, Hubei, Wuhan, 430062, China; School of Information Management, Central China Normal University, Hubei, Wuhan, 430072, China; Faculty of Artificial Intelligence in Education, Central China Normal University, Hubei, Wuhan, 430079, China; School of Computer Science, Wuhan University, Hubei, Wuhan, 430072, China","Li Z., School of Computer Science and Information Engineering, Hubei University, Hubei, Wuhan, 430062, China; Zhang Q., School of Information Management, Central China Normal University, Hubei, Wuhan, 430072, China; Zhu F., Faculty of Artificial Intelligence in Education, Central China Normal University, Hubei, Wuhan, 430079, China; Li D., School of Computer Science, Wuhan University, Hubei, Wuhan, 430072, China; Zheng C., School of Computer Science, Wuhan University, Hubei, Wuhan, 430072, China; Zhang Y., School of Computer Science and Information Engineering, Hubei University, Hubei, Wuhan, 430062, China","Graph neural networks (GNN) have emerged as a new state-of-the-art for learning knowledge graph representations. Although they have shown impressive performance in recent studies, how to efficiently and effectively aggregate neighboring features is not well designed. To tackle this challenge, we propose the simplifying heterogeneous graph neural network (SHGNet), a generic framework that discards the two standard operations in GNN, including the transformation matrix and nonlinear activation. SHGNet, in particular, adopts only the essential component of neighborhood aggregation in GNN and incorporates relation features into feature propagation. Furthermore, to capture complex structures, SHGNet utilizes a hierarchical aggregation architecture, including node aggregation and relation weighting. Thus, the proposed model can treat each relation differently and selectively aggregate informative features. SHGNet has been evaluated for link prediction tasks on three real-world benchmark datasets. The experimental results show that SHGNet significantly promotes efficiency while maintaining superior performance, outperforming all the existing models in 3 out of 4 metrics on NELL-995 and in 4 out of 4 metrics on FB15k-237 dataset. © 2023 Elsevier Ltd",Knowledge graph embedding; Knowledge graphs; Link prediction; Representation learning,Aggregates; Backpropagation; Graph neural networks; Linear transformations; Graph embeddings; Graph neural networks; Graph representation; Heterogeneous graph; Knowledge graph embedding; Knowledge graphs; Link prediction; Performance; Representation learning; Knowledge graph,Article,Final,,Scopus,2-s2.0-85151353602
111,He C.; Liu Y.; Li H.; Zhang H.; Mao Y.; Qin X.; Liu L.; Zhang X.,"He, Changxiang (23097637500); Liu, Yuru (57480338700); Li, Hao (57479925200); Zhang, Hui (57219360964); Mao, Yaping (55250368300); Qin, Xiaofei (36183547200); Liu, Lele (57191362226); Zhang, Xuedian (34874077100)",23097637500; 57480338700; 57479925200; 57219360964; 55250368300; 36183547200; 57191362226; 34874077100,Multi-type feature fusion based on graph neural network for drug-drug interaction prediction,2022,BMC Bioinformatics,23,1,224,,,,13,10.1186/s12859-022-04763-2,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85131818077&doi=10.1186%2fs12859-022-04763-2&partnerID=40&md5=f5bf33ca6f41ff4ad32d4a8c1180d1b9,"College of Science, University of Shanghai for Science and Technology, Shanghai, 200093, China; School of Optical-Electrical and Computer Engineering, University of Shanghai for Science and Technology, Shanghai, 200093, China; Institute of Interdisciplinary Integrative Medicine Research, Shanghai University of Traditional Chinese Medicine, Shanghai, 201203, China; School of Mathematics and Statistis, Qinghai Normal University, Xining, 810008, China","He C., College of Science, University of Shanghai for Science and Technology, Shanghai, 200093, China; Liu Y., College of Science, University of Shanghai for Science and Technology, Shanghai, 200093, China; Li H., School of Optical-Electrical and Computer Engineering, University of Shanghai for Science and Technology, Shanghai, 200093, China; Zhang H., Institute of Interdisciplinary Integrative Medicine Research, Shanghai University of Traditional Chinese Medicine, Shanghai, 201203, China; Mao Y., School of Mathematics and Statistis, Qinghai Normal University, Xining, 810008, China; Qin X., School of Optical-Electrical and Computer Engineering, University of Shanghai for Science and Technology, Shanghai, 200093, China; Liu L., College of Science, University of Shanghai for Science and Technology, Shanghai, 200093, China; Zhang X., School of Optical-Electrical and Computer Engineering, University of Shanghai for Science and Technology, Shanghai, 200093, China","Background: Drug-Drug interactions (DDIs) are a challenging problem in drug research. Drug combination therapy is an effective solution to treat diseases, but it can also cause serious side effects. Therefore, DDIs prediction is critical in pharmacology. Recently, researchers have been using deep learning techniques to predict DDIs. However, these methods only consider single information of the drug and have shortcomings in robustness and scalability. Results: In this paper, we propose a multi-type feature fusion based on graph neural network model (MFFGNN) for DDI prediction, which can effectively fuse the topological information in molecular graphs, the interaction information between drugs and the local chemical context in SMILES sequences. In MFFGNN, to fully learn the topological information of drugs, we propose a novel feature extraction module to capture the global features for the molecular graph and the local features for each atom of the molecular graph. In addition, in the multi-type feature fusion module, we use the gating mechanism in each graph convolution layer to solve the over-smoothing problem during information delivery. We perform extensive experiments on multiple real datasets. The results show that MFFGNN outperforms some state-of-the-art models for DDI prediction. Moreover, the cross-dataset experiment results further show that MFFGNN has good generalization performance. Conclusions: Our proposed model can efficiently integrate the information from SMILES sequences, molecular graphs and drug-drug interaction networks. We find that a multi-type feature fusion model can accurately predict DDIs. It may contribute to discovering novel DDIs. © 2022, The Author(s).",Gating mechanism; Graph neural network; Link prediction; Multi-type feature fusion,"Drug Interactions; Drug-Related Side Effects and Adverse Reactions; Gene Fusion; Humans; Neural Networks, Computer; Deep learning; Disease control; Drug interactions; Forecasting; Topology; Drug-drug interactions; Features fusions; Gating mechanisms; Graph neural networks; Interaction prediction; Link prediction; Molecular graphs; Multi-type feature fusion; Neural network model; Topological information; adverse drug reaction; drug interaction; gene fusion; human; Graph neural networks",Article,Final,All Open Access; Gold Open Access; Green Open Access,Scopus,2-s2.0-85131818077
112,Li Z.; Xing Y.; Huang J.; Wang H.; Gao J.; Yu G.,"Li, Zhao (57191700056); Xing, Yuying (57195491430); Huang, Jiaming (57202835599); Wang, Haobo (57214057405); Gao, Jianliang (55503957000); Yu, Guoxian (35175184400)",57191700056; 57195491430; 57202835599; 57214057405; 55503957000; 35175184400,Large-scale online multi-view graph neural network and applications,2021,Future Generation Computer Systems,116,,,145,155,10,13,10.1016/j.future.2020.10.018,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85095762066&doi=10.1016%2fj.future.2020.10.018&partnerID=40&md5=fd068830d604c24b7f2c8642d1bd4a15,"Alibaba Group, Hangzhou, 311121, China; College of Comp. Sci. and Tech., Zhejiang University, Hangzhou, 310027, China; Inf. Sci. and Eng., Central South University, Changsha, 410083, China; School of Software, Shandong University, Jinan, 250101, China","Li Z., Alibaba Group, Hangzhou, 311121, China; Xing Y., Alibaba Group, Hangzhou, 311121, China; Huang J., Alibaba Group, Hangzhou, 311121, China; Wang H., College of Comp. Sci. and Tech., Zhejiang University, Hangzhou, 310027, China; Gao J., Inf. Sci. and Eng., Central South University, Changsha, 410083, China; Yu G., School of Software, Shandong University, Jinan, 250101, China","Recently popularized Graph Neural Network (GNN) has been attaching great attention along with its successful industry applications. This paper focuses on two challenges traditional GNN frameworks face: (i) most of them are transductive and mainly concentrate on homogeneous networks considering single typed nodes and edges; (ii) they are difficult to handle the real-time changing network structures as well as scale to big graph data. To address these issues, a novel attention-based Heterogeneous Multi-view Graph Neural Network (aHMGNN) solution is introduced. aHMGNN models a more intricate heterogeneous multi-view network, where various node and edge types co-exist and each of these objects also contain specific attributes. It is end-to-end, and two stages are designed for node embeddings learning and multi-typed node and edge representations fusion, respectively. Experimental studies on large-scale spam detection and link prediction tasks clearly verify the efficiency and effectiveness of our proposed aHMGNN. Furthermore, we have implemented our approach in one of the largest e-commerce platforms which further verifies that aHMGNN is arguably promising and scalable in real-world applications. © 2020 Elsevier B.V.",Graph Neural Network; Heterogeneous; Multi-view; Online,Software engineering; Graph neural networks; Homogeneous network; Industry applications; Link prediction; Multi-views; Network structures; Real-world; Spam detection; Neural networks,Article,Final,,Scopus,2-s2.0-85095762066
113,Yu L.; Sun L.; Du B.; Liu C.; Lv W.; Xiong H.,"Yu, Le (57205581087); Sun, Leilei (55493029500); Du, Bowen (25930830100); Liu, Chuanren (50161977300); Lv, Weifeng (24329941700); Xiong, Hui (7201935465)",57205581087; 55493029500; 25930830100; 50161977300; 24329941700; 7201935465,Heterogeneous Graph Representation Learning With Relation Awareness,2023,IEEE Transactions on Knowledge and Data Engineering,35,6,,5935,5947,12,13,10.1109/TKDE.2022.3160208,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85126648622&doi=10.1109%2fTKDE.2022.3160208&partnerID=40&md5=4a6132ea03543206c07e430305230b02,"Sklsde, Bdbc Lab, Beihang University, Beijing, 100191, China; Department of Business Analytics and Statistics, University of Tennessee, Knoxville, 37996, TN, United States; Hong Kong University of Science and Technology (Guangzhou), Thrust of Artificial Intelligence Nansha, Guangdong, Guangzhou, 511400, China; Hong Kong University of Science and Technology, Department of Computer Science and Engineering, SAR, Hong Kong","Yu L., Sklsde, Bdbc Lab, Beihang University, Beijing, 100191, China; Sun L., Sklsde, Bdbc Lab, Beihang University, Beijing, 100191, China; Du B., Sklsde, Bdbc Lab, Beihang University, Beijing, 100191, China; Liu C., Department of Business Analytics and Statistics, University of Tennessee, Knoxville, 37996, TN, United States; Lv W., Sklsde, Bdbc Lab, Beihang University, Beijing, 100191, China; Xiong H., Hong Kong University of Science and Technology (Guangzhou), Thrust of Artificial Intelligence Nansha, Guangdong, Guangzhou, 511400, China, Hong Kong University of Science and Technology, Department of Computer Science and Engineering, SAR, Hong Kong","Representation learning on heterogeneous graphs aims to obtain meaningful node representations to facilitate various downstream tasks, such as node classification and link prediction. Existing heterogeneous graph learning methods are primarily developed by following the propagation mechanism of node representations. There are few efforts on studying the role of relations for improving the learning of more fine-grained node representations. Indeed, it is important to collaboratively learn the semantic representations of relations and discern node representations with respect to different relation types. To this end, in this paper, we propose a Relation-aware Heterogeneous Graph Neural Network, namely R-HGNN, to learn node representations on heterogeneous graphs at a fine-grained level by considering relation-aware characteristics. Specifically, a dedicated graph convolution component is first designed to learn unique node representations from each relation-specific graph separately. Then, a cross-relation message passing module is developed to improve the interactions of node representations across different relations. Also, the relation representations are learned in a layer-wise manner to capture relation semantics, which are used to guide the node representation learning process. Moreover, a semantic fusing module is presented to aggregate relation-aware node representations into a compact representation with the learned relation representations. Finally, we conduct extensive experiments on a variety of graph learning tasks, and experimental results demonstrate that our approach consistently outperforms existing methods among all the tasks. © 1989-2012 IEEE.",Heterogeneous graph; information fusion; relational graph; representation learning,Aggregates; Backpropagation; Convolution; Graph neural networks; Graph theory; Information fusion; Learning systems; Message passing; Semantic Web; Fine grained; Graph neural networks; Graph representation; Heterogeneous graph; Learn+; Neural-networks; Representation learning; Task analysis; Transformer; Semantics,Article,Final,All Open Access; Green Open Access,Scopus,2-s2.0-85126648622
114,Liu J.; Xu C.; Yin C.; Wu W.; Song Y.,"Liu, Jingxin (57212406706); Xu, Chang (55725660100); Yin, Chang (57188742224); Wu, Weiqiang (57208405674); Song, You (56136408100)",57212406706; 55725660100; 57188742224; 57208405674; 56136408100,K-Core Based Temporal Graph Convolutional Network for Dynamic Graphs,2022,IEEE Transactions on Knowledge and Data Engineering,34,8,,3841,3853,12,13,10.1109/TKDE.2020.3033829,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85134190834&doi=10.1109%2fTKDE.2020.3033829&partnerID=40&md5=7159efd2878d502b9425e24967518698,"Beihang University, School of Software, Beijing, 100191, China; HuaRong RongTong (Beijing) Technology Co., Ltd, Beijing, 100191, China; Credit Card Center, China Bohai Bank Co., Ltd., Tianjin, 300012, China","Liu J., Beihang University, School of Software, Beijing, 100191, China; Xu C., Beihang University, School of Software, Beijing, 100191, China; Yin C., HuaRong RongTong (Beijing) Technology Co., Ltd, Beijing, 100191, China; Wu W., Credit Card Center, China Bohai Bank Co., Ltd., Tianjin, 300012, China; Song Y., Beihang University, School of Software, Beijing, 100191, China","Graph representation learning is a fundamental task in various applications that strives to learn low-dimensional embeddings for nodes that can preserve graph topology information. However, many existing methods focus on static graphs while ignoring evolving graph patterns. Inspired by the success of graph convolutional networks(GCNs) in static graph embedding, we propose a novel k-core based temporal graph convolutional network, the CTGCN, to learn node representations for dynamic graphs. In contrast to previous dynamic graph embedding methods, CTGCN can preserve both local connective proximity and global structural similarity while simultaneously capturing graph dynamics. In the proposed framework, the traditional graph convolution is generalized into two phases, feature transformation and feature aggregation, which gives the CTGCN more flexibility and enables the CTGCN to learn connective and structural information under the same framework. Experimental results on 7 real-world graphs demonstrate that the CTGCN outperforms existing state-of-the-art graph embedding methods in several tasks, including link prediction and structural role classification. The source code of this work can be obtained from https://github.com/jhljx/CTGCN. © 1989-2012 IEEE.",Dynamic graph embedding; graph convolutional network; k-core; structural similarity,Graph embeddings; Graph neural networks; Graph theory; Graphic methods; Convolutional networks; Dynamic graph; Dynamic graph embedding; Embedding method; Graph convolutional network; Graph embeddings; K-cores; Learn+; Structural similarity; Temporal graphs; Convolution,Article,Final,All Open Access; Green Open Access,Scopus,2-s2.0-85134190834
115,Yang S.; Hu B.; Zhang Z.; Sun W.; Wang Y.; Zhou J.; Shan H.; Cao Y.; Ye B.; Fang Y.; Yu Q.,"Yang, Shuo (57220550276); Hu, Binbin (57194042110); Zhang, Zhiqiang (55721664700); Sun, Wang (57220545091); Wang, Yang (57217109421); Zhou, Jun (57199295167); Shan, Hongyu (57271905700); Cao, Yuetian (57271077300); Ye, Borui (57271905800); Fang, Yanming (57207568650); Yu, Quan (57207569110)",57220550276; 57194042110; 55721664700; 57220545091; 57217109421; 57199295167; 57271905700; 57271077300; 57271905800; 57207568650; 57207569110,Inductive Link Prediction with Interactive Structure Learning on Attributed Graph,2021,Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics),12976 LNAI,,,383,398,15,13,10.1007/978-3-030-86520-7_24,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85115676276&doi=10.1007%2f978-3-030-86520-7_24&partnerID=40&md5=3a71ee2c2b85a3d4ec19323574228b18,"Ant Group, Hangzhou, China","Yang S., Ant Group, Hangzhou, China; Hu B., Ant Group, Hangzhou, China; Zhang Z., Ant Group, Hangzhou, China; Sun W., Ant Group, Hangzhou, China; Wang Y., Ant Group, Hangzhou, China; Zhou J., Ant Group, Hangzhou, China; Shan H., Ant Group, Hangzhou, China; Cao Y., Ant Group, Hangzhou, China; Ye B., Ant Group, Hangzhou, China; Fang Y., Ant Group, Hangzhou, China; Yu Q., Ant Group, Hangzhou, China","Link prediction is one of the most important tasks in graph machine learning, which aims at predicting whether two nodes in a network have an edge. Real-world graphs typically contain abundant node and edge attributes, thus how to perform link prediction by simultaneously learning structure and attribute information from both interactions/paths between two associated nodes and local neighborhood among node’s ego subgraph is intractable. To address this issue, we develop a novel Path-aware Graph Neural Network (PaGNN) method for link prediction, which incorporates interaction and neighborhood information into graph neural networks via broadcasting and aggregating operations. And a cache strategy is developed to accelerate the inference process. Extensive experiments show a superior performance of our proposal over state-of-the-art methods on real-world link prediction tasks. © 2021, Springer Nature Switzerland AG.",,Forecasting; Graph theory; Machine learning; Attribute information; Attributed graphs; Graph neural networks; Inductive link; Interaction Path; Learning structure; Link prediction; Real-world graphs; Structure information; Structure-learning; Graph neural networks,Conference paper,Final,,Scopus,2-s2.0-85115676276
116,Di X.; Yu P.; Bu R.; Sun M.,"Di, Xinhan (57192372861); Yu, Pengqian (57190981818); Bu, Rui (57208439810); Sun, Mingchao (57208437839)",57192372861; 57190981818; 57208439810; 57208437839,Mutual Information Maximization in Graph Neural Networks,2020,Proceedings of the International Joint Conference on Neural Networks,,,9207076,,,,13,10.1109/IJCNN48605.2020.9207076,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85093873796&doi=10.1109%2fIJCNN48605.2020.9207076&partnerID=40&md5=a27663688f6f22364a5f579de1223d0b,"Ihome Corporation, Technique Center, China; IBM Research, Singapore; Alibaba Inc., China; Shangdong University, China","Di X., Ihome Corporation, Technique Center, China; Yu P., IBM Research, Singapore; Bu R., Alibaba Inc., China; Sun M., Shangdong University, China","A variety of graph neural networks (GNNs) frameworks for representation learning on graphs have been recently developed. These frameworks rely on aggregation and ITERATION scheme to learn the representation of nodes. However, information between nodes is inevitably lost in the scheme during learning. In order to reduce the loss, we extend the GNNs frameworks by exploring the aggregation and iteration scheme in the methodology of mutual information. We propose a new approach of enlarging the normal neighborhood in the aggregation of GNNs, which aims at maximizing mutual information. Based on a series of experiments conducted on several benchmark datasets, we show that the proposed approach improves the state-of-the-art performance for four types of graph tasks, including supervised and semi-supervised graph classification, graph link prediction and graph edge generation and classification. © 2020 IEEE.",convolution; graph theory; machine learning; mutual information; neural networks,Benchmarking; Classification (of information); Graph structures; Iterative methods; Benchmark datasets; Graph neural networks; Iteration schemes; Link prediction; Mutual information maximization; Mutual informations; Semi-supervised graphs; State-of-the-art performance; Neural networks,Conference paper,Final,All Open Access; Green Open Access,Scopus,2-s2.0-85093873796
117,Zhu R.; Tao Z.; Li Y.; Li S.,"Zhu, Ronghang (57226270251); Tao, Zhiqiang (57192061941); Li, Yaliang (56273199400); Li, Sheng (55812663300)",57226270251; 57192061941; 56273199400; 55812663300,Automated Graph Learning via Population Based Self-Tuning GCN,2021,SIGIR 2021 - Proceedings of the 44th International ACM SIGIR Conference on Research and Development in Information Retrieval,,,3463056,2096,2100,4,13,10.1145/3404835.3463056,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85111673876&doi=10.1145%2f3404835.3463056&partnerID=40&md5=c5a13603bd153804123546e204f119b0,"University of Georgia, Athens, GA, United States; Santa Clara University, Santa Clara, CA, United States; Alibaba Group, Bellevue, WA, United States","Zhu R., University of Georgia, Athens, GA, United States; Tao Z., Santa Clara University, Santa Clara, CA, United States; Li Y., Alibaba Group, Bellevue, WA, United States; Li S., University of Georgia, Athens, GA, United States","Owing to the remarkable capability of extracting effective graph embeddings, graph convolutional network (GCN) and its variants have been successfully applied to a broad range of tasks, such as node classification, link prediction, and graph classification. Traditional GCN models suffer from the issues of overfitting and oversmoothing, while some recent techniques like DropEdge could alleviate these issues and thus enable the development of deep GCN. However, training GCN models is non-trivial, as it is sensitive to the choice of hyperparameters such as dropout rate and learning weight decay, especially for deep GCN models. In this paper, we aim to automate the training of GCN models through hyperparameter optimization. To be specific, we propose a self-tuning GCN approach with an alternate training algorithm, and further extend our approach by incorporating the population based training scheme. Experimental results on three benchmark datasets demonstrate the effectiveness of our approaches on optimizing multi-layer GCN, compared with several representative baselines. © 2021 ACM.",graph learning; graph neural networks; hyperparameter optimization,Information retrieval; Benchmark datasets; Convolutional networks; Graph classification; Graph embeddings; Hyper-parameter optimizations; Link prediction; Training algorithms; Training schemes; Convolutional neural networks,Conference paper,Final,All Open Access; Green Open Access,Scopus,2-s2.0-85111673876
118,Hu X.; Chen H.; Liu S.; Jiang H.; Chu G.; Li R.,"Hu, Xinxin (57205423285); Chen, Hongchang (16506000800); Liu, Shuxin (55268517500); Jiang, Haocong (57837466100); Chu, Guanghan (57837057700); Li, Ran (57215050921)",57205423285; 16506000800; 55268517500; 57837466100; 57837057700; 57215050921,BTG: A Bridge to Graph machine learning in telecommunications fraud detection,2022,Future Generation Computer Systems,137,,,274,287,13,12,10.1016/j.future.2022.07.020,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85135707497&doi=10.1016%2fj.future.2022.07.020&partnerID=40&md5=e3cfdf1a1c02ca13afdcacd9cbd94893,"National Digital Switching System Engineering and Technological Research Center, Zhengzhou, 450002, China; Institute of Geospatial Information, Information Engineering University, Zhengzhou, 450001, China","Hu X., National Digital Switching System Engineering and Technological Research Center, Zhengzhou, 450002, China; Chen H., National Digital Switching System Engineering and Technological Research Center, Zhengzhou, 450002, China; Liu S., National Digital Switching System Engineering and Technological Research Center, Zhengzhou, 450002, China; Jiang H., National Digital Switching System Engineering and Technological Research Center, Zhengzhou, 450002, China; Chu G., Institute of Geospatial Information, Information Engineering University, Zhengzhou, 450001, China; Li R., National Digital Switching System Engineering and Technological Research Center, Zhengzhou, 450002, China","Telecommunications fraud runs rampant recently around the world. Therefore, how to effectively detect fraudsters has become an increasingly challenging problem. However, previous studies either assume that the samples are independent of each other and use non-graph methods, or use local subgraphs with good connectivity for graph-based anomaly detection. Few prior works have performed graph-based fraud detection on real-world Call Detail Records (CDR) meta data sets with sparse connectivity. To solve this problem, we propose an end-to-end telecommunications fraud detection framework named Bridge To Graph (BTG). BTG leverages the subscriber synergy behavior to reconstruct connectivity, which bridges the gap between sparse connectivity data and graph machine learning. Concretely, we extract multi-model features from meta data and perform Box–Cox transformation first. Then, aiming at the sparse connectivity of real-world CDR meta data, the graph is reconstructed through dimensionally selectable link prediction of node similarity. Finally, the reconstructed graph and node features are input into the graph machine learning module for node embedding representation learning and fraud node classification. Comprehensive experiments on the real-world telecommunications network CDR data set show that our proposed method outperforms the classic methods in many metrics. Beyond telecom fraud detection, our method can also be extended to anomaly detection scenarios with no graph or sparse connectivity graph. © 2022 Elsevier B.V.",Fraud detection; Graph construction; Graph neural network; Sparse graph; Subscriber behavior; Telecommunications,Anomaly detection; Clock and data recovery circuits (CDR circuits); Crime; Graph neural networks; Graph theory; Graphic methods; Machine learning; Call detail records; Fraud detection; Graph construction; Graph machine; Graph neural networks; Meta-data; Real-world; Sparse graphs; Subscriber behavior; Telecommunication fraud; Metadata,Article,Final,,Scopus,2-s2.0-85135707497
119,King I.J.; Huang H.H.,"King, Isaiah J. (58100915900); Huang, H. Howie (51964011300)",58100915900; 51964011300,EULER: Detecting Network Lateral Movement via Scalable Temporal Link Prediction,2022,"29th Annual Network and Distributed System Security Symposium, NDSS 2022",,,,,,,12,10.14722/ndss.2022.24107,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85180552842&doi=10.14722%2fndss.2022.24107&partnerID=40&md5=00b8dc04f860b8d99fee1053a02cdd2a,"George Washington University, United States","King I.J., George Washington University, United States; Huang H.H., George Washington University, United States","Lateral movement is a key stage of system compromise used by advanced persistent threats. Detecting it is no simple task. When network host logs are abstracted into discrete temporal graphs, the problem can be reframed as anomalous edge detection in an evolving network. Research in modern deep graph learning techniques has produced many creative and complicated models for this task. However, as is the case in many machine learning fields, the generality of models is of paramount importance for accuracy and scalability during training and inference. In this paper, we propose a formalized approach to this problem with a framework we call EULER. It consists of a model-agnostic graph neural network stacked upon a model-agnostic sequence encoding layer such as a recurrent neural network. Models built according to the EULER framework can easily distribute their graph convolutional layers across multiple machines for large performance improvements. Additionally, we demonstrate that EULER-based models are competitive, or better than many state-of-the-art approaches to anomalous link detection and prediction. As anomaly-based intrusion detection systems, EULER models can efficiently identify anomalous connections between entities with high precision and outperform other unsupervised techniques for anomalous lateral movement detection. © 2022 29th Annual Network and Distributed System Security Symposium, NDSS 2022. All Rights Reserved.",,Anomaly detection; Convolutional neural networks; Edge detection; Intrusion detection; Learning systems; Network security; Recurrent neural networks; Creatives; Evolving networks; Lateral movement; Learning fields; Learning techniques; Link prediction; Machine-learning; Network hosts; Simple++; Temporal graphs; Multilayer neural networks,Conference paper,Final,All Open Access; Bronze Open Access,Scopus,2-s2.0-85180552842
120,Gupta A.; Matta P.; Pant B.,"Gupta, Atika (57222723139); Matta, Priya (55649744700); Pant, Bhasker (35316278700)",57222723139; 55649744700; 35316278700,"Graph neural network: Current state of Art, challenges and applications",2021,Materials Today: Proceedings,46,,,10927,10932,5,12,10.1016/j.matpr.2021.01.950,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85116398383&doi=10.1016%2fj.matpr.2021.01.950&partnerID=40&md5=6f4da519dfcd0d05bee392e93caf3bc0,"Graphic Era Deemed to Be University, Graphic Era Hill University, Dehradun, India; Graphic Era Deemed to Be University, Dehradun, India","Gupta A., Graphic Era Deemed to Be University, Graphic Era Hill University, Dehradun, India; Matta P., Graphic Era Deemed to Be University, Dehradun, India; Pant B., Graphic Era Deemed to Be University, Dehradun, India","Several areas in science and engineering have the relationships between their underlying data which can be represented as graphs, for example, molecular chemistry, node prediction, link prediction, computer vision, pattern recognition, social networking and more. In this article, an approach to a model which can handle such type of data is elaborated, which is Graph Neural Networks (GNN). GNN encompasses the neural network technique to process the data which is represented as graphs. Due to its massive success, GNN has made its way into many applications and is a popular architecture to work upon. This paper explains the graph neural networks, its area of applications and its day-to-day use in our daily lives. Some of the very common application is a social networking site which is on our hands regularly, and another could be the recommendation system which recommends us friends, or the products of our interest based on our pat choices and preferences. This paper also demonstrates the basic challenges encountered while implementing GNN. This paper will be a great help to those researchers who are keen to work in the domain of GNN. © 2021 Elsevier Ltd. All rights reserved.",Applications; Graph domain; Graph neural network; Heterogenous graphs; Social networking sites,Arts computing; Pattern recognition; Social networking (online); 'current; AS graph; Graph domain; Graph neural networks; Heterogenous graph; Link prediction; Molecular chemistry; Science and engineering; Social networking site; Social-networking; Graph neural networks,Conference paper,Final,,Scopus,2-s2.0-85116398383
121,Mei G.; Pan L.; Liu S.,"Mei, Guangxu (57215610421); Pan, Li (55729410100); Liu, Shijun (35302723000)",57215610421; 55729410100; 35302723000,Heterogeneous graph embedding by aggregating meta-path and meta-structure through attention mechanism,2022,Neurocomputing,468,,,276,285,9,12,10.1016/j.neucom.2021.10.001,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85118103382&doi=10.1016%2fj.neucom.2021.10.001&partnerID=40&md5=9f90f8530e5086f3f4c0bc3afbf36dae,"School of Software, Shandong University, Jinan, China","Mei G., School of Software, Shandong University, Jinan, China; Pan L., School of Software, Shandong University, Jinan, China; Liu S., School of Software, Shandong University, Jinan, China","Heterogeneous information networks embedding, which is a promising technique to learn low-dimensional representations for nodes with different types, has obtained very high interests recently. Plenty of graph neural networks models have been proposed for heterogeneous graph embedding. However, there are two limitations in existing models: (1) despite the complex structures of heterogeneous nodes, almost all these models are mainly based on meta-paths; (2) the different importance of different structures are neglected in most models. To address these problems, we propose a meta-path and meta-structure integrated heterogeneous graph neural network through attention mechanisms (PSHGAN). PSHGAN first maps features of heterogeneous nodes into the same space. Then, PSHGAN learns the weights of two nodes at each end of the meta-path or meta-structure by a local attention mechanism. Finally, PSHGAN learns weights of meta-paths and meta-structures by a global attention mechanism and aggregates the nodes representations. Extensive experiments are conducted on real-world benchmark datasets and show that our proposed model outperforms the state-of-the-art models in the node classification and link prediction tasks. Moreover, we make comprehensive analysis on the impacts of meta-structures on the performance of classification training with meta-paths. © 2021 Elsevier B.V.",Attention mechanism; Graph neural network; Heterogeneous information network; Meta-structure; Network embedding,Classification (of information); Embeddings; Graph embeddings; Graph theory; Information services; Attention mechanisms; Graph embeddings; Graph neural networks; Heterogeneous graph; Heterogeneous information; Heterogeneous information network; Information networks; Learn+; Metastructures; Network embedding; article; attention; embedding; prediction; Graph neural networks; Network embeddings,Article,Final,,Scopus,2-s2.0-85118103382
122,Xiao Y.; Yao L.; Pei Q.; Wang X.; Yang J.; Sheng Q.Z.,"Xiao, Yang (57187414200); Yao, Lina (54406102800); Pei, Qingqi (15763462800); Wang, Xianzhi (36189130500); Yang, Jian (35304034500); Sheng, Quan Z. (57208669610)",57187414200; 54406102800; 15763462800; 36189130500; 35304034500; 57208669610,MGNN: Mutualistic Graph Neural Network for Joint Friend and Item Recommendation,2020,IEEE Intelligent Systems,35,5,9078079,7,17,10,12,10.1109/MIS.2020.2988925,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85084079380&doi=10.1109%2fMIS.2020.2988925&partnerID=40&md5=ce793c4f41507e82cb1c1c72e2b9617c,"Xidian University, China; University of New South Wales, Australia; University of Technology Sydney, Australia; Macquarie University, Australia","Xiao Y., Xidian University, China; Yao L., University of New South Wales, Australia; Pei Q., Xidian University, China; Wang X., University of Technology Sydney, Australia; Yang J., Macquarie University, Australia; Sheng Q.Z., Macquarie University, Australia","Many social studies and practical cases suggest that people's consumption behaviors and social behaviors are not isolated but interrelated in social network services. However, most existing research either predicts users' consumption preferences or recommends friends to users without dealing with them simultaneously. We propose a holistic approach to predict users' preferences on friends and items jointly and thereby make better recommendations. To this end, we design a graph neural network that incorporates a mutualistic mechanism to model the mutual reinforcement relationship between users' consumption behaviors and social behaviors. Our experiments on the two-real world datasets demonstrate the effectiveness of our approach in both social recommendation and link prediction. © 2001-2011 IEEE.",Graph Neural Networks; Joint Recommendation; Mutualistic Model; Social Networks,Behavioral research; Graph neural networks; Holistic approach; Link prediction; Mutual reinforcement; Real-world datasets; Social behavior; Social network services; Social study; Neural networks,Article,Final,All Open Access; Green Open Access,Scopus,2-s2.0-85084079380
123,Shanthamallu U.S.; Thiagarajan J.J.; Spanias A.,"Shanthamallu, Uday Shankar (57202322515); Thiagarajan, Jayaraman J. (25929725600); Spanias, Andreas (7006177932)",57202322515; 25929725600; 7006177932,Uncertainty-Matching Graph Neural Networks to Defend Against Poisoning Attacks,2021,"35th AAAI Conference on Artificial Intelligence, AAAI 2021",11A,,,9524,9532,8,11,,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85119149534&partnerID=40&md5=714b9778522426e7e4e48d5076c9e55a,"Arizona State University, United States; Lawrence Livermore National Labs, United States","Shanthamallu U.S., Arizona State University, United States; Thiagarajan J.J., Lawrence Livermore National Labs, United States; Spanias A., Arizona State University, United States","Graph Neural Networks (GNNs), a generalization of neural networks to graph-structured data, are often implemented using message passes between entities of a graph. While GNNs are effective for node classification, link prediction and graph classification, they are vulnerable to adversarial attacks, i.e., a small perturbation to the structure can lead to a non-trivial performance degradation. In this work, we propose Uncertainty Matching GNN (UM-GNN), that is aimed at improving the robustness of GNN models, particularly against poisoning attacks to the graph structure, by leveraging epistemic uncertainties from the message passing framework. More specifically, we propose to build a surrogate predictor that does not directly access the graph structure, but systematically extracts reliable knowledge from a standard GNN through a novel uncertainty-matching strategy. Interestingly, this uncoupling makes UM-GNN immune to evasion attacks by design, and achieves significantly improved robustness against poisoning attacks. Using empirical studies with standard benchmarks and a suite of global and target attacks, we demonstrate the effectiveness of UM-GNN, when compared to existing baselines including the state-of-the-art robust GCN. Copyright © 2021, Association for the Advancement of Artificial Intelligence (www.aaai.org). All rights reserved.",,Graph neural networks; Message passing; Uncertainty analysis; Generalisation; Graph neural networks; Graph structured data; Graph structures; Link prediction; Matching graph; Matchings; Neural-networks; Poisoning attacks; Uncertainty; Graphic methods,Conference paper,Final,,Scopus,2-s2.0-85119149534
124,Ji Y.; Yin M.; Yang H.; Zhou J.; Zheng V.W.; Shi C.; Fang Y.,"Ji, Yugang (57201549637); Yin, Mingyang (57218124329); Yang, Hongxia (57054215300); Zhou, Jingren (7405548577); Zheng, Vincent W. (23037782800); Shi, Chuan (55447999200); Fang, Yuan (55469295200)",57201549637; 57218124329; 57054215300; 7405548577; 23037782800; 55447999200; 55469295200,Accelerating Large-Scale Heterogeneous Interaction Graph Embedding Learning via Importance Sampling,2021,ACM Transactions on Knowledge Discovery from Data,15,1,10,,,,11,10.1145/3418684,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85099332826&doi=10.1145%2f3418684&partnerID=40&md5=893736b5aab545227aa8e58f8f20b221,"Beijing University of Posts and Telecommunications, Xitucheng Road, Beijing, China; Alibaba Group, Wengyi Road, Hangzhou, China; Advanced Digital Sciences Center, Create Tower, Singapore; Singapore Management University, Victoria Street, Singapore","Ji Y., Beijing University of Posts and Telecommunications, Xitucheng Road, Beijing, China; Yin M., Alibaba Group, Wengyi Road, Hangzhou, China; Yang H., Alibaba Group, Wengyi Road, Hangzhou, China; Zhou J., Alibaba Group, Wengyi Road, Hangzhou, China; Zheng V.W., Advanced Digital Sciences Center, Create Tower, Singapore; Shi C., Beijing University of Posts and Telecommunications, Xitucheng Road, Beijing, China; Fang Y., Singapore Management University, Victoria Street, Singapore","In real-world problems, heterogeneous entities are often related to each other through multiple interactions, forming a Heterogeneous Interaction Graph (HIG). While modeling HIGs to deal with fundamental tasks, graph neural networks present an attractive opportunity that can make full use ofthe heterogeneity and rich semantic information by aggregating and propagating information from different types of neighborhoods. However, learning on such complex graphs, often with millions or billions of nodes, edges, and various attributes, could suffer from expensive time cost and high memory consumption. In this article, we attempt to accelerate representation learning on large-scale HIGs by adopting the importance sampling of heterogeneous neighborhoods in a batch-wise manner, which naturally fits with most batch-based optimizations. Distinct from traditional homogeneous strategies neglecting semantic types of nodes and edges, to handle the rich heterogeneous semantics within HIGs, we devise both type-dependent and type-fusion samplers where the former respectively samples neighborhoods of each type and the latter jointly samples from candidates of all types. Furthermore,to overcome the imbalance between the down-sampled and the original information, we respectively propose heterogeneous estimators including the self-normalized and the adaptive estimators to improvethe robustness of our sampling strategies. Finally, we evaluate the performance of our models for node classification and link prediction on five real-world datasets, respectively. The empirical results demonstrate that our approach performs significantly better than other state-of-the-art alternatives, and is able to reduce the number of edges in computation by up to 93%, the memory cost by up to 92% and the time cost by up to 86%. © 2020 ACM.",Heterogeneous interaction graphs; importance sampling; large-scale graphs; type-dependent sampler; type-fusion sampler,Classification (of information); Embeddings; Neural networks; Semantics; Adaptive estimators; Graph neural networks; Heterogeneous interactions; Multiple interactions; Real-world datasets; Real-world problem; Sampling strategies; Semantic information; Importance sampling,Article,Final,All Open Access; Green Open Access,Scopus,2-s2.0-85099332826
125,Carchiolo V.; Cavallo C.; Grassia M.; Malgeri M.; Mangioni G.,"Carchiolo, Vincenza (7003828229); Cavallo, Christian (57504892100); Grassia, Marco (57203899835); Malgeri, Michele (6602120041); Mangioni, Giuseppe (6602212145)",7003828229; 57504892100; 57203899835; 6602120041; 6602212145,Link Prediction in Time Varying Social Networks,2022,Information (Switzerland),13,3,123,,,,11,10.3390/info13030123,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85126589602&doi=10.3390%2finfo13030123&partnerID=40&md5=dfab0c3778081261b88c0dd062a6458e,"DIEEI-Dipartimento di Ingegneria Elettrica, Elettronica Informatica, Universitá degli Studi di Catania, Catania, I95125, Italy","Carchiolo V., DIEEI-Dipartimento di Ingegneria Elettrica, Elettronica Informatica, Universitá degli Studi di Catania, Catania, I95125, Italy; Cavallo C., DIEEI-Dipartimento di Ingegneria Elettrica, Elettronica Informatica, Universitá degli Studi di Catania, Catania, I95125, Italy; Grassia M., DIEEI-Dipartimento di Ingegneria Elettrica, Elettronica Informatica, Universitá degli Studi di Catania, Catania, I95125, Italy; Malgeri M., DIEEI-Dipartimento di Ingegneria Elettrica, Elettronica Informatica, Universitá degli Studi di Catania, Catania, I95125, Italy; Mangioni G., DIEEI-Dipartimento di Ingegneria Elettrica, Elettronica Informatica, Universitá degli Studi di Catania, Catania, I95125, Italy","Predicting new links in complex networks can have a large societal impact. In fact, many complex systems can be modeled through networks, and the meaning of the links depend on the system itself. For instance, in social networks, where the nodes are users, links represent relationships (such as acquaintance, friendship, etc.), whereas in information spreading networks, nodes are users and content and links represent interactions, diffusion, etc. However, while many approaches involve machine learning-based algorithms, just the most recent ones account for the topology of the network, e.g., geometric deep learning techniques to learn on graphs, and most of them do not account for the temporal dynamics in the network but train on snapshots of the system at a given time. In this paper, we aim to explore Temporal Graph Networks (TGN), a Graph Representation Learning-based approach that natively supports dynamic graphs and assigns to each event (link) a timestamp. In particular, we investigate how the TGN behaves when trained under different temporal granularity or with various event aggregation techniques when learning the inductive and transductive link prediction problem on real social networks such as Twitter, Wikipedia, Yelp, and Reddit. We find that initial setup affects the temporal granularity of the data, but the impact depends on the specific social network. For instance, we note that the train batch size has a strong impact on Twitter, Wikipedia, and Yelp, while it does not matter on Reddit. © 2022 by the authors. Licensee MDPI, Basel, Switzerland.",Deep learning; Geometric deep learning; Information spreading; Link prediction; Social networks,Deep learning; Forecasting; Graph neural networks; Social networking (online); Time varying networks; Topology; Deep learning; Geometric deep learning; Graph networks; Information spreading; Link prediction; Social network; Temporal granularity; Temporal graphs; Time varying; Wikipedia; Complex networks,Article,Final,All Open Access; Gold Open Access,Scopus,2-s2.0-85126589602
126,Chen J.; Gong Z.; Wang W.; Wang C.; Xu Z.; Lv J.; Li X.; Wu K.; Liu W.,"Chen, Junyang (57209837328); Gong, Zhiguo (7201949170); Wang, Wei (56948620800); Wang, Cong (57209930195); Xu, Zhenghua (57210108252); Lv, Jianming (8385897200); Li, Xueliang (57192162137); Wu, Kaishun (22982222400); Liu, Weiwen (57202889283)",57209837328; 7201949170; 56948620800; 57209930195; 57210108252; 8385897200; 57192162137; 22982222400; 57202889283,Adversarial Caching Training: Unsupervised Inductive Network Representation Learning on Large-Scale Graphs,2022,IEEE Transactions on Neural Networks and Learning Systems,33,12,,7079,7090,11,11,10.1109/TNNLS.2021.3084195,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85143180761&doi=10.1109%2fTNNLS.2021.3084195&partnerID=40&md5=b416d124facbe29d51b5d5c9e3521358,"Shenzhen University, College of Computer Science and Software Engineering, Shenzhen, 518060, China; University of Macau, State Key Laboratory of Internet of Things for Smart City, Department of Computer Information Science, Macao; Sun Yat-sen University, School of Intelligent Systems Engineering, Guangzhou, 510275, China; The Hong Kong Polytechnic University, Department of Computing, Hong Kong; Hebei University of Technology, State Key Laboratory of Reliability and Intelligence of Electrical Equipment, Tianjin, 300401, China; South China University of Technology, School of Computer Science and Engineering, Guangzhou, 510006, China; The Chinese University of Hong Kong, Department of Computer Science and Engineering, Hong Kong","Chen J., Shenzhen University, College of Computer Science and Software Engineering, Shenzhen, 518060, China; Gong Z., University of Macau, State Key Laboratory of Internet of Things for Smart City, Department of Computer Information Science, Macao; Wang W., Sun Yat-sen University, School of Intelligent Systems Engineering, Guangzhou, 510275, China; Wang C., The Hong Kong Polytechnic University, Department of Computing, Hong Kong; Xu Z., Hebei University of Technology, State Key Laboratory of Reliability and Intelligence of Electrical Equipment, Tianjin, 300401, China; Lv J., South China University of Technology, School of Computer Science and Engineering, Guangzhou, 510006, China; Li X., Shenzhen University, College of Computer Science and Software Engineering, Shenzhen, 518060, China; Wu K., Shenzhen University, College of Computer Science and Software Engineering, Shenzhen, 518060, China; Liu W., The Chinese University of Hong Kong, Department of Computer Science and Engineering, Hong Kong","Network representation learning (NRL) has far-reaching effects on data mining research, showing its importance in many real-world applications. NRL, also known as network embedding, aims at preserving graph structures in a low-dimensional space. These learned representations can be used for subsequent machine learning tasks, such as vertex classification, link prediction, and data visualization. Recently, graph convolutional network (GCN)-based models, e.g., GraphSAGE, have drawn a lot of attention for their success in inductive NRL. When conducting unsupervised learning on large-scale graphs, some of these models employ negative sampling (NS) for optimization, which encourages a target vertex to be close to its neighbors while being far from its negative samples. However, NS draws negative vertices through a random pattern or based on the degrees of vertices. Thus, the generated samples could be either highly relevant or completely unrelated to the target vertex. Moreover, as the training goes, the gradient of NS objective calculated with the inner product of the unrelated negative samples and the target vertex may become zero, which will lead to learning inferior representations. To address these problems, we propose an adversarial training method tailored for unsupervised inductive NRL on large networks. For efficiently keeping track of high-quality negative samples, we design a caching scheme with sampling and updating strategies that has a wide exploration of vertex proximity while considering training costs. Besides, the proposed method is adaptive to various existing GCN-based models without significantly complicating their optimization process. Extensive experiments show that our proposed method can achieve better performance compared with the state-of-the-art models. © 2012 IEEE.",Adversarial learning; graph neural network; inductive learning; negative sampling (NS); network embedding,Data mining; Data visualization; Graph neural networks; Personnel training; Adversarial learning; Convolutional networks; Graph neural networks; Inductive learning; Large-scales; Negative samples; Negative sampling; Network embedding; Network representation; Network-based modeling; article; attention; feature learning (machine learning); Network embeddings,Article,Final,,Scopus,2-s2.0-85143180761
127,Shumovskaia V.; Fedyanin K.; Sukharev I.; Berestnev D.; Panov M.,"Shumovskaia, Valentina (57219763094); Fedyanin, Kirill (57219588844); Sukharev, Ivan (57219757625); Berestnev, Dmitry (57219757907); Panov, Maxim (50861971900)",57219763094; 57219588844; 57219757625; 57219757907; 50861971900,Linking bank clients using graph neural networks powered by rich transactional data: Extended abstract,2020,"Proceedings - 2020 IEEE 7th International Conference on Data Science and Advanced Analytics, DSAA 2020",,,9260069,787,788,1,11,10.1109/DSAA49011.2020.00117,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85097973745&doi=10.1109%2fDSAA49011.2020.00117&partnerID=40&md5=486365c13bec6a2d8aee9d2b9bca6270,"Sberbank, Risk Modeling Research, Moscow, Russian Federation; Skolkovo Institute of Science and Technology (Skoltech), Moscow, Russian Federation","Shumovskaia V., Sberbank, Risk Modeling Research, Moscow, Russian Federation; Fedyanin K., Sberbank, Risk Modeling Research, Moscow, Russian Federation; Sukharev I., Skolkovo Institute of Science and Technology (Skoltech), Moscow, Russian Federation; Berestnev D., Skolkovo Institute of Science and Technology (Skoltech), Moscow, Russian Federation; Panov M., Skolkovo Institute of Science and Technology (Skoltech), Moscow, Russian Federation","Each day bank clients conduct numerous operations, such as purchasing goods or transferring money to other clients. These interactions can be interpreted as a graph dynamically changing over time. This work focuses on the task of predicting new interactions in the network of bank clients and treats it as a link prediction problem. We propose an architecture for the graph convolutional network to efficiently solve the link prediction problem for this type of data. Our model uses recurrent neural networks to leverage the time-series data in both nodes and edges and effectively scales to the graphs with millions of nodes. We evaluate the model on the data provided for several years by a large European bank. The obtained results show that the model outperforms the existing approaches. The current paper is an extended abstract for the work [5]. © 2020 IEEE.",Credit scoring; Graph neural network; Link prediction; Recurrent neural network; Transactional data,Advanced Analytics; Convolutional neural networks; Forecasting; Convolutional networks; Extended abstracts; Graph neural networks; Link prediction; Model use; Time-series data; Transactional data; Recurrent neural networks,Conference paper,Final,,Scopus,2-s2.0-85097973745
128,Huang H.; Song Y.; Wu Y.; Shi J.; Xie X.; Jin H.,"Huang, Hong (57149409900); Song, Yu (57221161135); Wu, Yao (57221579760); Shi, Jia (57220587414); Xie, Xia (35729832500); Jin, Hai (56434989100)",57149409900; 57221161135; 57221579760; 57220587414; 35729832500; 56434989100,Multitask Representation Learning with Multiview Graph Convolutional Networks,2022,IEEE Transactions on Neural Networks and Learning Systems,33,3,,983,995,12,11,10.1109/TNNLS.2020.3036825,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85097426558&doi=10.1109%2fTNNLS.2020.3036825&partnerID=40&md5=20418a2d57def7158508829c0b49339f,"National Engineering Research Center for Big Data Technology, Huazhong University of Science and Technology, Wuhan, China","Huang H., National Engineering Research Center for Big Data Technology, Huazhong University of Science and Technology, Wuhan, China; Song Y., National Engineering Research Center for Big Data Technology, Huazhong University of Science and Technology, Wuhan, China; Wu Y., National Engineering Research Center for Big Data Technology, Huazhong University of Science and Technology, Wuhan, China; Shi J., National Engineering Research Center for Big Data Technology, Huazhong University of Science and Technology, Wuhan, China; Xie X., National Engineering Research Center for Big Data Technology, Huazhong University of Science and Technology, Wuhan, China; Jin H., National Engineering Research Center for Big Data Technology, Huazhong University of Science and Technology, Wuhan, China","Link prediction and node classification are two important downstream tasks of network representation learning. Existing methods have achieved acceptable results but they perform these two tasks separately, which requires a lot of duplication of work and ignores the correlations between tasks. Besides, conventional models suffer from the identical treatment of information of multiple views, thus they fail to learn robust representation for downstream tasks. To this end, we tackle link prediction and node classification problems simultaneously via multitask multiview learning in this article. We first explain the feasibility and advantages of multitask multiview learning for these two tasks. Then we propose a novel model named MT-MVGCN to perform link prediction and node classification tasks simultaneously. More specifically, we design a multiview graph convolutional network to extract abundant information of multiple views in a network, which is shared by different tasks. We further apply two attention mechanisms: view the attention mechanism and task attention mechanism to make views and tasks adjust the view fusion process. Moreover, view reconstruction can be introduced as an auxiliary task to boost the performance of the proposed model. Experiments on real-world network data sets demonstrate that our model is efficient yet effective, and outperforms advanced baselines in these two tasks. © 2012 IEEE.",Data mining; graph neural networks (GNNs); multitask learning; representation learning,Convolution; Forecasting; Attention mechanisms; Classification tasks; Conventional models; Convolutional networks; Link prediction; Multi-view learning; Network representation; Real-world networks; article; attention; drug combination; feasibility study; feature learning (machine learning); prediction; Convolutional neural networks,Article,Final,All Open Access; Green Open Access,Scopus,2-s2.0-85097426558
129,Zheng D.; Wang M.; Gan Q.; Song X.; Zhang Z.; Karypis G.,"Zheng, Da (55342815200); Wang, Minjie (57218844057); Gan, Quan (57218845402); Song, Xiang (57220896162); Zhang, Zheng (58847371600); Karypis, George (15069396800)",55342815200; 57218844057; 57218845402; 57220896162; 58847371600; 15069396800,Scalable Graph Neural Networks with Deep Graph Library,2021,WSDM 2021 - Proceedings of the 14th ACM International Conference on Web Search and Data Mining,,,,1141,1142,1,11,10.1145/3437963.3441663,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85103042567&doi=10.1145%2f3437963.3441663&partnerID=40&md5=54feaf60dc6f311f5344db1c1bd635f6,"AWS AI, United States; AWS Shanghai AI Lab, China","Zheng D., AWS AI, United States; Wang M., AWS Shanghai AI Lab, China; Gan Q., AWS Shanghai AI Lab, China; Song X., AWS Shanghai AI Lab, China; Zhang Z., AWS Shanghai AI Lab, China; Karypis G., AWS AI, United States","Learning from graph and relational data plays a major role in many applications including social network analysis, marketing, e-commerce, information retrieval, knowledge modeling, medical and biological sciences, engineering, and others. Recently, Graph Neural Networks (GNNs) have emerged as a promising new learning framework capable of bringing the power of deep representation learning to graph and relational data. This ever-growing body of research has shown that GNNs achieve state-of-the-art performance for problems such as link prediction, fraud detection, target-ligand binding activity prediction, knowledge-graph completion, and product recommendations. In practice, many of the real-world graphs are very large. It is urgent to have scalable solutions to train GNN on large graphs efficiently. The objective of this tutorial is twofold. First, it will provide an overview of the theory behind GNNs, discuss the types of problems that GNNs are well suited for, and introduce some of the most widely used GNN model architectures and problems/applications that are designed to solve. Second, it will introduce the Deep Graph Library (DGL), a scalable GNN framework that simplifies the development of efficient GNN-based training and inference programs at a large scale. To make things concrete, the tutorial will cover state-of-the-art training methods to scale GNN to large graphs and provide hands-on sessions to show how to use DGL to perform scalable training in different settings (multi-GPU training and distributed training). This hands-on part will start with basic graph applications (e.g., node classification and link prediction) to set up the context and move on to train GNNs on large graphs. It will provide tutorials to demonstrate how to apply the techniques in DGL to train GNNs for real-world applications. © 2021 ACM.",deep graph library; graph neural networks; scalability,Data mining; Deep learning; Forecasting; Graphic methods; Information retrieval; Knowledge representation; Search engines; Websites; Biological science; Graph neural networks; Learning frameworks; Ligand binding activity; Model architecture; Product recommendation; Real-world graphs; State-of-the-art performance; Neural networks,Conference paper,Final,,Scopus,2-s2.0-85103042567
130,Han H.; Zhao T.; Yang C.; Zhang H.; Liu Y.; Wang X.; Shi C.,"Han, Hui (57224541234); Zhao, Tianyu (57807987300); Yang, Cheng (57001472900); Zhang, Hongyi (57945704200); Liu, Yaoqi (57945783300); Wang, Xiao (56454481700); Shi, Chuan (55447999200)",57224541234; 57807987300; 57001472900; 57945704200; 57945783300; 56454481700; 55447999200,OpenHGNN: An Open Source Toolkit for Heterogeneous Graph Neural Network,2022,"International Conference on Information and Knowledge Management, Proceedings",,,,3993,3997,4,11,10.1145/3511808.3557664,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85140832587&doi=10.1145%2f3511808.3557664&partnerID=40&md5=05e8de5ccca458fe3adb7f4b828de410,"Beijing University of Posts and Telecommunications, Beijing, China; Peng Cheng Laboratory, Beijing, China","Han H., Beijing University of Posts and Telecommunications, Beijing, China; Zhao T., Beijing University of Posts and Telecommunications, Beijing, China; Yang C., Beijing University of Posts and Telecommunications, Beijing, China, Peng Cheng Laboratory, Beijing, China; Zhang H., Beijing University of Posts and Telecommunications, Beijing, China; Liu Y., Beijing University of Posts and Telecommunications, Beijing, China; Wang X., Beijing University of Posts and Telecommunications, Beijing, China, Peng Cheng Laboratory, Beijing, China; Shi C., Beijing University of Posts and Telecommunications, Beijing, China, Peng Cheng Laboratory, Beijing, China","Heterogeneous Graph Neural Networks (HGNNs), as a kind of powerful graph representation learning methods on heterogeneous graphs, have attracted increasing attention of many researchers. Although, several existing libraries have supported HGNNs, they just provide the most basic models and operators. Building and benchmarking various downstream tasks on HGNNs is still painful and time consuming with them. In this paper, we will introduce OpenHGNN, an open-source toolkit for HGNNs. OpenHGNN defines a unified and standard pipeline for training and testing, which can allow users to run a model on a specific dataset with just one command line. OpenHGNN has integrated 20+ mainstream HGNNs and 20+ heterogeneous graph datasets, which can be used for various advanced tasks, such as node classification, link prediction, and recommendation. In addition, thanks to the modularized design of OpenHGNN, it can be extended to meet users' customized needs. We also release several novel and useful tools and features, including leaderboard, autoML, design space, and visualization, to provide users with better usage experiences. OpenHGNN is an open-source project, and the source code is available at https://github.com/BUPT-GAMMA/OpenHGNN. © 2022 ACM.",frameworks; heterogeneous graph neural networks; heterogeneous graph representation learning,Classification (of information); Learning systems; Open source software; Open systems; Statistical tests; Down-stream; Framework; Graph neural networks; Graph representation; Heterogeneous graph; Heterogeneous graph neural network; Heterogeneous graph representation learning; Learning methods; Open-source; Graph neural networks,Conference paper,Final,,Scopus,2-s2.0-85140832587